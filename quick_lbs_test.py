#!/usr/bin/env python3
"""
å¿«é€ŸLBSæƒé‡æµ‹è¯•è„šæœ¬

ç®€å•æµ‹è¯•å·²ä¼˜åŒ–çš„LBSæƒé‡åœ¨ä¸åŒå¸§ä¸Šçš„é‡å»ºè´¨é‡
"""

import numpy as np
import time
from pathlib import Path
from Skinning import InverseMeshCanonicalizer

def quick_lbs_test():
    """å¿«é€Ÿæµ‹è¯•LBSæƒé‡è´¨é‡"""
    
    print("ğŸ” å¿«é€ŸLBSæƒé‡æµ‹è¯•")
    print("=" * 50)
    
    # é…ç½®è·¯å¾„
    skeleton_data_dir = "output/skeleton_prediction"
    mesh_folder_path = "D:/Code/VVEditor/Rafa_Approves_hd_4k"
    weights_path = "output/skinning_weights_fast.npz"
    reference_frame = 5
    
    # åˆå§‹åŒ–
    print("æ­£åœ¨åˆå§‹åŒ–...")
    canonicalizer = InverseMeshCanonicalizer(
        skeleton_data_dir=skeleton_data_dir,
        reference_frame_idx=reference_frame
    )
    
    # åŠ è½½ç½‘æ ¼å’Œæƒé‡
    canonicalizer.load_mesh_sequence(mesh_folder_path)
    
    if not canonicalizer.load_skinning_weights(weights_path):
        print("âŒ æ— æ³•åŠ è½½æƒé‡æ–‡ä»¶")
        return
    
    print(f"âœ… æˆåŠŸåŠ è½½æƒé‡: {canonicalizer.skinning_weights.shape}")
    
    # é€‰æ‹©æµ‹è¯•å¸§
    total_frames = len(canonicalizer.mesh_files)
    if total_frames <= 15:
        test_frames = list(range(total_frames))
    else:
        # é€‰æ‹©ä»£è¡¨æ€§å¸§
        test_frames = [0, 1, 2]  # å¼€å§‹
        test_frames.extend([total_frames//4, total_frames//2, 3*total_frames//4])  # ä¸­é—´
        test_frames.extend([total_frames-3, total_frames-2, total_frames-1])  # ç»“æŸ
        # ç§»é™¤å‚è€ƒå¸§ï¼Œé¿å…é‡å¤
        if reference_frame in test_frames:
            test_frames.remove(reference_frame)
        test_frames = sorted(test_frames)
    
    print(f"æµ‹è¯•å¸§: {test_frames}")
    print(f"å‚è€ƒå¸§: {reference_frame}")
    
    # æµ‹è¯•æ¯ä¸€å¸§
    print(f"\nğŸ§ª å¼€å§‹æµ‹è¯• {len(test_frames)} å¸§:")
    print("å¸§å·   è·ç¦»å‚è€ƒ  å¹³å‡è¯¯å·®    æœ€å¤§è¯¯å·®    RMSE      æ—¶é—´(s)")
    print("-" * 60)
    
    results = []
    total_start_time = time.time()
    
    for frame_idx in test_frames:
        if frame_idx >= total_frames:
            continue
            
        # æµ‹è¯•å•å¸§
        frame_result = test_single_frame_reconstruction(canonicalizer, frame_idx)
        if frame_result:
            results.append(frame_result)
            
            # è¾“å‡ºç»“æœ
            distance = abs(frame_idx - reference_frame)
            print(f"{frame_idx:3d}    {distance:4d}     {frame_result['mean_error']:.6f}  "
                  f"{frame_result['max_error']:.6f}  {frame_result['rmse']:.6f}  "
                  f"{frame_result['time']:.3f}")
    
    total_time = time.time() - total_start_time
    
    # è®¡ç®—æ€»ä½“ç»Ÿè®¡
    if results:
        all_mean_errors = [r['mean_error'] for r in results]
        all_max_errors = [r['max_error'] for r in results]
        all_rmse = [r['rmse'] for r in results]
        all_times = [r['time'] for r in results]
        
        print("-" * 60)
        print(f"ğŸ“Š æ€»ä½“ç»Ÿè®¡ (åŸºäº {len(results)} å¸§):")
        print(f"å¹³å‡é‡å»ºè¯¯å·®: {np.mean(all_mean_errors):.6f} Â± {np.std(all_mean_errors):.6f}")
        print(f"æœ€å¤§è¯¯å·®èŒƒå›´: [{np.min(all_max_errors):.6f}, {np.max(all_max_errors):.6f}]")
        print(f"å¹³å‡RMSE: {np.mean(all_rmse):.6f}")
        print(f"å¹³å‡å¤„ç†æ—¶é—´: {np.mean(all_times):.3f}s")
        print(f"æ€»æµ‹è¯•æ—¶é—´: {total_time:.2f}s")
        print(f"ä¼°è®¡å¸§ç‡: {len(results)/np.sum(all_times):.1f} FPS")
        
        # åˆ†æè¯¯å·®ä¸è·ç¦»çš„å…³ç³»
        distances = [abs(r['frame_idx'] - reference_frame) for r in results]
        correlation = np.corrcoef(distances, all_mean_errors)[0, 1]
        print(f"è¯¯å·®ä¸è·ç¦»å‚è€ƒå¸§çš„ç›¸å…³æ€§: {correlation:.3f}")
        
        # è´¨é‡è¯„ä¼°
        avg_error = np.mean(all_mean_errors)
        if avg_error < 0.01:
            quality = "ä¼˜ç§€"
        elif avg_error < 0.02:
            quality = "è‰¯å¥½"
        elif avg_error < 0.05:
            quality = "ä¸€èˆ¬"
        else:
            quality = "éœ€è¦æ”¹è¿›"
        
        print(f"\nğŸ¯ è´¨é‡è¯„ä¼°: {quality} (å¹³å‡è¯¯å·®: {avg_error:.6f})")
        
        # ä¿å­˜ç®€å•ç»“æœ
        save_simple_results(results, canonicalizer, "output/lbs_quick_test_results.txt")
        
    else:
        print("âŒ æ²¡æœ‰æˆåŠŸæµ‹è¯•ä»»ä½•å¸§")

def test_single_frame_reconstruction(canonicalizer, frame_idx):
    """æµ‹è¯•å•å¸§é‡å»º"""
    try:
        import open3d as o3d
        
        # åŠ è½½ç›®æ ‡ç½‘æ ¼
        target_mesh = o3d.io.read_triangle_mesh(str(canonicalizer.mesh_files[frame_idx]))
        target_vertices = np.asarray(target_mesh.vertices)
        
        # å½’ä¸€åŒ–
        if frame_idx not in canonicalizer.frame_normalization_params:
            canonicalizer.frame_normalization_params[frame_idx] = \
                canonicalizer.compute_mesh_normalization_params(target_mesh)
        
        target_vertices_norm = canonicalizer.normalize_mesh_vertices(
            target_vertices, 
            canonicalizer.frame_normalization_params[frame_idx]
        )
        
        rest_vertices_norm = canonicalizer.normalize_mesh_vertices(
            canonicalizer.rest_pose_vertices, 
            canonicalizer.frame_normalization_params[canonicalizer.reference_frame_idx]
        )
        
        # è®¡ç®—ç›¸å¯¹å˜æ¢
        target_transforms = canonicalizer.transforms[frame_idx]
        rest_transforms = canonicalizer.transforms[canonicalizer.reference_frame_idx]
        
        relative_transforms = np.zeros_like(target_transforms)
        for j in range(canonicalizer.num_joints):
            if np.linalg.det(rest_transforms[j][:3, :3]) > 1e-6:
                rest_inv = np.linalg.inv(rest_transforms[j])
                relative_transforms[j] = target_transforms[j] @ rest_inv
            else:
                relative_transforms[j] = np.eye(4)
        
        # LBSé‡å»º
        start_time = time.time()
        predicted_vertices = canonicalizer.apply_lbs_transform(
            rest_vertices_norm, 
            canonicalizer.skinning_weights, 
            relative_transforms
        )
        lbs_time = time.time() - start_time
        
        # è®¡ç®—è¯¯å·®
        vertex_errors = np.linalg.norm(predicted_vertices - target_vertices_norm, axis=1)
        
        return {
            'frame_idx': frame_idx,
            'mean_error': float(np.mean(vertex_errors)),
            'max_error': float(np.max(vertex_errors)),
            'min_error': float(np.min(vertex_errors)),
            'std_error': float(np.std(vertex_errors)),
            'rmse': float(np.sqrt(np.mean(vertex_errors**2))),
            'time': lbs_time,
            'num_vertices': len(vertex_errors)
        }
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¸§ {frame_idx} å¤±è´¥: {e}")
        return None

def save_simple_results(results, canonicalizer, output_path):
    """ä¿å­˜ç®€å•çš„æµ‹è¯•ç»“æœ"""
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write("LBSæƒé‡å¿«é€Ÿæµ‹è¯•ç»“æœ\n")
        f.write("=" * 50 + "\n\n")
        f.write(f"æƒé‡çŸ©é˜µå½¢çŠ¶: {canonicalizer.skinning_weights.shape}\n")
        f.write(f"å‚è€ƒå¸§: {canonicalizer.reference_frame_idx}\n")
        f.write(f"æµ‹è¯•å¸§æ•°: {len(results)}\n\n")
        
        f.write("è¯¦ç»†ç»“æœ:\n")
        f.write("å¸§å·\tè·ç¦»å‚è€ƒ\tå¹³å‡è¯¯å·®\tæœ€å¤§è¯¯å·®\tRMSE\t\tæ—¶é—´(s)\n")
        f.write("-" * 70 + "\n")
        
        for result in results:
            distance = abs(result['frame_idx'] - canonicalizer.reference_frame_idx)
            f.write(f"{result['frame_idx']}\t{distance}\t\t{result['mean_error']:.6f}\t"
                   f"{result['max_error']:.6f}\t{result['rmse']:.6f}\t{result['time']:.3f}\n")
        
        # æ€»ä½“ç»Ÿè®¡
        all_mean_errors = [r['mean_error'] for r in results]
        all_times = [r['time'] for r in results]
        
        f.write("\næ€»ä½“ç»Ÿè®¡:\n")
        f.write(f"å¹³å‡é‡å»ºè¯¯å·®: {np.mean(all_mean_errors):.6f}\n")
        f.write(f"è¯¯å·®æ ‡å‡†å·®: {np.std(all_mean_errors):.6f}\n")
        f.write(f"å¹³å‡å¤„ç†æ—¶é—´: {np.mean(all_times):.3f}s\n")
        f.write(f"ä¼°è®¡å¸§ç‡: {len(results)/np.sum(all_times):.1f} FPS\n")
    
    print(f"ğŸ“„ ç»“æœå·²ä¿å­˜: {output_path}")

def test_specific_frames():
    """æµ‹è¯•ç‰¹å®šå¸§ï¼ˆç”¨äºè°ƒè¯•ï¼‰"""
    print("ğŸ” æµ‹è¯•ç‰¹å®šå¸§")
    
    # é…ç½®
    skeleton_data_dir = "output/skeleton_prediction"
    mesh_folder_path = "D:/Code/VVEditor/Rafa_Approves_hd_4k"
    weights_path = "output/skinning_weights_fast.npz"
    reference_frame = 5
    
    # è¦æµ‹è¯•çš„ç‰¹å®šå¸§
    test_frames = [0, 10, 20, 30, 40]  # ä¿®æ”¹ä¸ºä½ æƒ³æµ‹è¯•çš„å¸§
    
    # åˆå§‹åŒ–
    canonicalizer = InverseMeshCanonicalizer(
        skeleton_data_dir=skeleton_data_dir,
        reference_frame_idx=reference_frame
    )
    
    canonicalizer.load_mesh_sequence(mesh_folder_path)
    
    if not canonicalizer.load_skinning_weights(weights_path):
        print("âŒ æ— æ³•åŠ è½½æƒé‡æ–‡ä»¶")
        return
    
    print(f"æµ‹è¯•ç‰¹å®šå¸§: {test_frames}")
    
    for frame_idx in test_frames:
        if frame_idx >= len(canonicalizer.mesh_files):
            print(f"âš ï¸  å¸§ {frame_idx} è¶…å‡ºèŒƒå›´")
            continue
            
        result = test_single_frame_reconstruction(canonicalizer, frame_idx)
        if result:
            print(f"å¸§ {frame_idx}: å¹³å‡è¯¯å·®={result['mean_error']:.6f}, "
                  f"æœ€å¤§è¯¯å·®={result['max_error']:.6f}, æ—¶é—´={result['time']:.3f}s")

if __name__ == "__main__":
    # é€‰æ‹©è¿è¡Œæ¨¡å¼
    import sys
    
    if len(sys.argv) > 1 and sys.argv[1] == "specific":
        test_specific_frames()
    else:
        quick_lbs_test()
