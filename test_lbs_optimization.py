#!/usr/bin/env python3
"""
æµ‹è¯•LBSæƒé‡ä¼˜åŒ–åŠŸèƒ½

è¿™ä¸ªè„šæœ¬ä¸“é—¨æµ‹è¯•Linear Blend Skinningæƒé‡ä¼˜åŒ–ï¼Œ
é€šè¿‡æœ€å°åŒ– ||V_target - LBS(V_rest, weights, transforms)||Â² æ¥æ±‚è§£æœ€ä¼˜æƒé‡
"""

import numpy as np
import sys
from pathlib import Path
import matplotlib.pyplot as plt
from Skinning import InverseMeshCanonicalizer

def test_lbs_optimization():
    """
    æµ‹è¯•LBSæƒé‡ä¼˜åŒ–åŠŸèƒ½
    """
    print("=" * 80)
    print("Linear Blend Skinning (LBS) æƒé‡ä¼˜åŒ–æµ‹è¯•")
    print("=" * 80)
    
    # é…ç½®è·¯å¾„
    skeleton_data_dir = "output/skeleton_prediction"
    mesh_folder_path = "D:/Code/VVEditor/Rafa_Approves_hd_4k"
    weights_output_path = "output/skinning_weights_test.npz"
    
    # æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨
    if not Path(skeleton_data_dir).exists():
        print(f"é”™è¯¯: éª¨éª¼æ•°æ®ç›®å½•ä¸å­˜åœ¨: {skeleton_data_dir}")
        return False
    
    if not Path(mesh_folder_path).exists():
        print(f"é”™è¯¯: ç½‘æ ¼æ•°æ®ç›®å½•ä¸å­˜åœ¨: {mesh_folder_path}")
        return False
    
    try:
        # åˆ›å»ºç»Ÿä¸€åŒ–å™¨
        print("1. åˆå§‹åŒ–InverseMeshCanonicalizer...")
        canonicalizer = InverseMeshCanonicalizer(
            skeleton_data_dir=skeleton_data_dir,
            reference_frame_idx=5  # ä½¿ç”¨ç¬¬5å¸§ä½œä¸ºreference frame
        )
        
        # åŠ è½½ç½‘æ ¼åºåˆ—
        print("2. åŠ è½½ç½‘æ ¼åºåˆ—...")
        canonicalizer.load_mesh_sequence(mesh_folder_path)
        
        print(f"   - éª¨éª¼å¸§æ•°: {canonicalizer.num_frames}")
        print(f"   - å…³èŠ‚æ•°: {canonicalizer.num_joints}")
        print(f"   - ç½‘æ ¼æ–‡ä»¶æ•°: {len(canonicalizer.mesh_files)}")
        print(f"   - Reference frame: {canonicalizer.reference_frame_idx}")
        print(f"   - Reference meshé¡¶ç‚¹æ•°: {len(canonicalizer.reference_mesh.vertices)}")
        
        # å¼€å§‹LBSæƒé‡ä¼˜åŒ–
        print("\n3. å¼€å§‹LBSæƒé‡ä¼˜åŒ–...")
        print("   ä¼˜åŒ–ç›®æ ‡: minimize ||V_target - LBS(V_rest, weights, transforms)||Â²")
        
        skinning_weights = canonicalizer.optimize_reference_frame_skinning(
            regularization_lambda=0.005,  # è¾ƒå°çš„æ­£åˆ™åŒ–ç³»æ•°
            max_iter=200  # å‡å°‘è¿­ä»£æ¬¡æ•°ç”¨äºæµ‹è¯•
        )
        
        if skinning_weights is None:
            print("âŒ LBSæƒé‡ä¼˜åŒ–å¤±è´¥ï¼")
            return False
        
        print("âœ… LBSæƒé‡ä¼˜åŒ–æˆåŠŸå®Œæˆï¼")
        print(f"   - æƒé‡çŸ©é˜µå½¢çŠ¶: {skinning_weights.shape}")
        
        # åˆ†ææƒé‡ç‰¹æ€§
        print("\n4. åˆ†ææƒé‡ç‰¹æ€§...")
        analyze_skinning_weights(skinning_weights)
        
        # ä¿å­˜æƒé‡
        print("\n5. ä¿å­˜æƒé‡...")
        canonicalizer.save_skinning_weights(weights_output_path)
        
        # éªŒè¯æƒé‡æ•ˆæœ
        print("\n6. éªŒè¯æƒé‡æ•ˆæœ...")
        validation_results = canonicalizer.validate_skinning_weights(
            test_frames=list(range(0, min(canonicalizer.num_frames, 20), 3))
        )
        
        if validation_results:
            print("âœ… éªŒè¯å®Œæˆï¼")
            
            # ç»˜åˆ¶è¯¯å·®åˆ†æå›¾
            plot_validation_results(validation_results)
            
            # è¯¯å·®é˜ˆå€¼æ£€æŸ¥
            avg_error = validation_results['average_error']
            if avg_error < 0.01:
                print("ğŸ‰ ä¼˜ç§€ï¼å¹³å‡é‡å»ºè¯¯å·® < 0.01")
            elif avg_error < 0.05:
                print("ğŸ‘ è‰¯å¥½ï¼å¹³å‡é‡å»ºè¯¯å·® < 0.05")
            elif avg_error < 0.1:
                print("âš ï¸  ä¸€èˆ¬ï¼Œå¹³å‡é‡å»ºè¯¯å·® < 0.1")
            else:
                print("âŒ è¾ƒå·®ï¼Œå¹³å‡é‡å»ºè¯¯å·® >= 0.1")
        
        # æµ‹è¯•åŠ è½½æƒé‡
        print("\n7. æµ‹è¯•æƒé‡åŠ è½½...")
        new_canonicalizer = InverseMeshCanonicalizer(
            skeleton_data_dir=skeleton_data_dir,
            reference_frame_idx=5
        )
        
        if new_canonicalizer.load_skinning_weights(weights_output_path):
            print("âœ… æƒé‡åŠ è½½æµ‹è¯•æˆåŠŸï¼")
        else:
            print("âŒ æƒé‡åŠ è½½æµ‹è¯•å¤±è´¥ï¼")
        
        print("\n" + "=" * 80)
        print("LBSæƒé‡ä¼˜åŒ–æµ‹è¯•å®Œæˆï¼")
        print("=" * 80)
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return False

def analyze_skinning_weights(weights):
    """
    åˆ†æskinningæƒé‡çš„ç‰¹æ€§
    
    Args:
        weights: æƒé‡çŸ©é˜µ [V, J]
    """
    num_vertices, num_joints = weights.shape
    
    # è®¡ç®—ç¨€ç–åº¦
    non_zero_threshold = 0.01
    non_zero_weights = weights > non_zero_threshold
    sparsity = np.mean(non_zero_weights)
    
    # æ¯ä¸ªé¡¶ç‚¹çš„å½±å“å…³èŠ‚æ•°
    influences_per_vertex = np.sum(non_zero_weights, axis=1)
    
    # æ¯ä¸ªå…³èŠ‚å½±å“çš„é¡¶ç‚¹æ•°
    vertices_per_joint = np.sum(non_zero_weights, axis=0)
    
    # æƒé‡åˆ†å¸ƒç»Ÿè®¡
    weight_stats = {
        'mean': np.mean(weights),
        'std': np.std(weights),
        'min': np.min(weights),
        'max': np.max(weights)
    }
    
    print(f"   æƒé‡çŸ©é˜µåˆ†æ:")
    print(f"   - é¡¶ç‚¹æ•°: {num_vertices}")
    print(f"   - å…³èŠ‚æ•°: {num_joints}")
    print(f"   - ç¨€ç–åº¦: {sparsity:.3f} (æƒé‡ > {non_zero_threshold})")
    print(f"   - å¹³å‡æ¯é¡¶ç‚¹å—å½±å“å…³èŠ‚æ•°: {np.mean(influences_per_vertex):.2f}")
    print(f"   - å½±å“å…³èŠ‚æ•°åˆ†å¸ƒ: min={np.min(influences_per_vertex)}, max={np.max(influences_per_vertex)}")
    print(f"   - å¹³å‡æ¯å…³èŠ‚å½±å“é¡¶ç‚¹æ•°: {np.mean(vertices_per_joint):.2f}")
    print(f"   - æƒé‡ç»Ÿè®¡: mean={weight_stats['mean']:.4f}, std={weight_stats['std']:.4f}")
    print(f"   - æƒé‡èŒƒå›´: [{weight_stats['min']:.4f}, {weight_stats['max']:.4f}]")

def plot_validation_results(validation_results):
    """
    ç»˜åˆ¶éªŒè¯ç»“æœå›¾è¡¨
    
    Args:
        validation_results: éªŒè¯ç»“æœå­—å…¸
    """
    try:
        import matplotlib.pyplot as plt
        
        frame_indices = list(validation_results['frame_errors'].keys())
        mean_errors = [validation_results['frame_errors'][idx]['mean_error'] 
                      for idx in frame_indices]
        std_errors = [validation_results['frame_errors'][idx]['std_error'] 
                     for idx in frame_indices]
        
        plt.figure(figsize=(12, 8))
        
        # å­å›¾1: è¯¯å·®è¶‹åŠ¿
        plt.subplot(2, 2, 1)
        plt.plot(frame_indices, mean_errors, 'b-o', label='Mean Error')
        plt.fill_between(frame_indices, 
                        [m - s for m, s in zip(mean_errors, std_errors)],
                        [m + s for m, s in zip(mean_errors, std_errors)],
                        alpha=0.3, label='Â±1 Std')
        plt.xlabel('Frame Index')
        plt.ylabel('Reconstruction Error')
        plt.title('LBS Reconstruction Error vs Frame')
        plt.legend()
        plt.grid(True, alpha=0.3)
        
        # å­å›¾2: è¯¯å·®åˆ†å¸ƒ
        plt.subplot(2, 2, 2)
        plt.hist(mean_errors, bins=10, alpha=0.7, edgecolor='black')
        plt.xlabel('Mean Error')
        plt.ylabel('Frequency')
        plt.title('Error Distribution')
        plt.grid(True, alpha=0.3)
        
        # å­å›¾3: è¯¯å·®ç»Ÿè®¡
        plt.subplot(2, 2, 3)
        stats = ['Average', 'Min', 'Max']
        values = [validation_results['average_error'],
                 validation_results['min_error'],
                 validation_results['max_error']]
        colors = ['blue', 'green', 'red']
        
        bars = plt.bar(stats, values, color=colors, alpha=0.7)
        plt.ylabel('Error Value')
        plt.title('Error Statistics')
        plt.grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, value in zip(bars, values):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,
                    f'{value:.4f}', ha='center', va='bottom')
        
        # å­å›¾4: å¸§è·ç¦»vsè¯¯å·®
        plt.subplot(2, 2, 4)
        reference_frame = 5  # å‡è®¾reference frameæ˜¯5
        frame_distances = [abs(idx - reference_frame) for idx in frame_indices]
        plt.scatter(frame_distances, mean_errors, c='red', alpha=0.7)
        plt.xlabel('Distance from Reference Frame')
        plt.ylabel('Mean Error')
        plt.title('Error vs Distance from Reference')
        plt.grid(True, alpha=0.3)
        
        # æ·»åŠ è¶‹åŠ¿çº¿
        if len(frame_distances) > 1:
            z = np.polyfit(frame_distances, mean_errors, 1)
            p = np.poly1d(z)
            plt.plot(sorted(frame_distances), p(sorted(frame_distances)), "r--", alpha=0.8, label='Trend')
            plt.legend()
        
        plt.tight_layout()
        
        # ä¿å­˜å›¾è¡¨
        output_path = "output/lbs_validation_results.png"
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        print(f"   éªŒè¯ç»“æœå›¾è¡¨å·²ä¿å­˜: {output_path}")
        
        # å¯é€‰ï¼šæ˜¾ç¤ºå›¾è¡¨
        # plt.show()
        
    except ImportError:
        print("   è­¦å‘Š: matplotlibä¸å¯ç”¨ï¼Œè·³è¿‡å›¾è¡¨ç»˜åˆ¶")
    except Exception as e:
        print(f"   è­¦å‘Š: ç»˜åˆ¶å›¾è¡¨æ—¶å‡ºé”™: {e}")

def compare_methods():
    """
    æ¯”è¾ƒä¸åŒæ–¹æ³•çš„æ•ˆæœï¼ˆå¦‚æœéœ€è¦ï¼‰
    """
    print("=" * 80)
    print("æ–¹æ³•æ¯”è¾ƒï¼ˆå¯é€‰åŠŸèƒ½ï¼‰")
    print("=" * 80)
    print("è¿™é‡Œå¯ä»¥å®ç°:")
    print("1. LBSæ–¹æ³• vs éª¨éª¼é©±åŠ¨æ–¹æ³• vs ç‰¹å¾åŒ¹é…æ–¹æ³•çš„æ¯”è¾ƒ")
    print("2. ä¸åŒæ­£åˆ™åŒ–å‚æ•°çš„æ•ˆæœæ¯”è¾ƒ")
    print("3. ä¸åŒåˆå§‹åŒ–æ–¹æ³•çš„æ•ˆæœæ¯”è¾ƒ")
    print("4. ä¸åŒreference frameé€‰æ‹©çš„å½±å“")

if __name__ == "__main__":
    print("å¼€å§‹LBSæƒé‡ä¼˜åŒ–æµ‹è¯•...")
    
    success = test_lbs_optimization()
    
    if success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        
        # å¯é€‰ï¼šè¿è¡Œæ¯”è¾ƒæµ‹è¯•
        user_input = input("\næ˜¯å¦è¿è¡Œæ–¹æ³•æ¯”è¾ƒï¼Ÿ(y/n): ").strip().lower()
        if user_input == 'y':
            compare_methods()
    else:
        print("\nâŒ æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
        sys.exit(1)
