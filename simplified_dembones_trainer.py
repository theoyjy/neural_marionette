#!/usr/bin/env python3
"""
ç®€åŒ–çš„DemBonesé‡è®­ç»ƒè„šæœ¬ - ä¸“æ³¨æ ¸å¿ƒåŠŸèƒ½
åŸºäºadvanced_skeleton_unifier.pyçš„ç»Ÿä¸€æ‹“æ‰‘ç»“æœä¼˜åŒ–éª¨éª¼æƒé‡
"""

import os
import pickle
import numpy as np

class SimplifiedDemBonesTrainer:
    def __init__(self, unified_data_path):
        """åˆå§‹åŒ–ç®€åŒ–çš„DemBonesè®­ç»ƒå™¨"""
        self.unified_data_path = unified_data_path
        self.load_unified_data()
        
    def load_unified_data(self):
        """åŠ è½½é«˜çº§ç»Ÿä¸€æ•°æ®"""
        print("ğŸ”„ åŠ è½½é«˜çº§ç»Ÿä¸€æ•°æ®...")
        with open(self.unified_data_path, 'rb') as f:
            data = pickle.load(f)
            
        self.unified_meshes = data['unified_vertices']  # (157, 32140, 3)
        self.bone_transforms = data['bone_transforms']  # (157, 24, 4, 4)
        self.heat_diffusion_weights = data['heat_diffusion_weights']  # (32140, 24)
        self.triangles = data['triangles']  # (40000, 3)
        self.rest_pose = data['rest_pose']  # (32140, 3)
        self.joints = data['joints']  # (24, 3)
        self.parents = data['parents']  # (24,)
        
        print(f"âœ… åŠ è½½å®Œæˆ:")
        print(f"   ç»Ÿä¸€ç½‘æ ¼: {self.unified_meshes.shape}")
        print(f"   éª¨éª¼å˜æ¢: {self.bone_transforms.shape}")
        print(f"   Heatæƒé‡: {self.heat_diffusion_weights.shape}")
        
    def optimize_skinning_weights_iterative(self, max_iterations=200):
        """è¿­ä»£ä¼˜åŒ–è’™çš®æƒé‡"""
        print("ğŸ”¥ å¼€å§‹è¿­ä»£ä¼˜åŒ–è’™çš®æƒé‡...")
        
        # åˆå§‹åŒ–æƒé‡
        current_weights = self.heat_diffusion_weights.copy()
        
        num_frames, num_vertices, _ = self.unified_meshes.shape
        num_bones = self.bone_transforms.shape[1]
        
        for iteration in range(max_iterations):
            # 1. ä¸ºæ¯ä¸ªé¡¶ç‚¹ä¼˜åŒ–æƒé‡
            new_weights = np.zeros_like(current_weights)
            
            for vertex_idx in range(num_vertices):
                if vertex_idx % 5000 == 0:
                    print(f"   è¿­ä»£ {iteration+1}/{max_iterations}, é¡¶ç‚¹ {vertex_idx}/{num_vertices}")
                
                # è®¡ç®—è¯¥é¡¶ç‚¹çš„æœ€ä¼˜æƒé‡
                vertex_weights = self.optimize_single_vertex_weights(
                    vertex_idx, current_weights[vertex_idx]
                )
                new_weights[vertex_idx] = vertex_weights
                
            # 2. è®¡ç®—æƒé‡å˜åŒ–
            weight_change = np.linalg.norm(new_weights - current_weights)
            
            print(f"   è¿­ä»£ {iteration+1}: æƒé‡å˜åŒ– = {weight_change:.8f}")
            
            # 3. æ›´æ–°æƒé‡
            current_weights = new_weights
            
            # 4. æ”¶æ•›æ£€æŸ¥
            if weight_change < 1e-6:
                print(f"âœ… åœ¨ç¬¬{iteration+1}æ¬¡è¿­ä»£æ”¶æ•›")
                break
                
        return current_weights
        
    def optimize_single_vertex_weights(self, vertex_idx, initial_weights):
        """ä¼˜åŒ–å•ä¸ªé¡¶ç‚¹çš„æƒé‡"""
        num_frames = self.unified_meshes.shape[0]
        num_bones = self.bone_transforms.shape[1]
        
        # ç›®æ ‡ä½ç½®ï¼ˆæ‰€æœ‰å¸§ä¸­è¯¥é¡¶ç‚¹çš„ä½ç½®ï¼‰
        target_positions = self.unified_meshes[:, vertex_idx, :]  # (num_frames, 3)
        rest_position = self.rest_pose[vertex_idx]  # (3,)
        
        # æ„å»ºçº¿æ€§æ–¹ç¨‹ç»„ Aw = b
        # æ¯å¸§äº§ç”Ÿ3ä¸ªæ–¹ç¨‹ï¼ˆx, y, zåæ ‡ï¼‰
        A = np.zeros((num_frames * 3, num_bones))
        b = np.zeros(num_frames * 3)
        
        for frame in range(num_frames):
            # è¯¥å¸§çš„ç›®æ ‡ä½ç½®
            target_pos = target_positions[frame]
            
            # æ„å»ºè¯¥å¸§çš„æ–¹ç¨‹
            for bone in range(num_bones):
                # åº”ç”¨éª¨éª¼å˜æ¢åˆ°restä½ç½®
                rest_homo = np.append(rest_position, 1.0)
                transform = self.bone_transforms[frame, bone]
                transformed_pos = (transform @ rest_homo)[:3]
                
                # å¡«å…¥ç³»æ•°çŸ©é˜µ
                row_start = frame * 3
                A[row_start:row_start+3, bone] = transformed_pos
                
            # å¡«å…¥å³ä¾§å‘é‡
            b[row_start:row_start+3] = target_pos
            
        # æ·»åŠ å½’ä¸€åŒ–çº¦æŸ: sum(weights) = 1
        A_constrained = np.vstack([A, np.ones((1, num_bones))])
        b_constrained = np.append(b, 1.0)
        
        # æ±‚è§£æœ€å°äºŒä¹˜é—®é¢˜
        try:
            weights, residual, rank, s = np.linalg.lstsq(
                A_constrained, b_constrained, rcond=None
            )
            
            # ç¡®ä¿æƒé‡éè´Ÿ
            weights = np.maximum(weights, 0)
            
            # é‡æ–°å½’ä¸€åŒ–
            weight_sum = np.sum(weights)
            if weight_sum > 1e-8:
                weights /= weight_sum
            else:
                # å¦‚æœæƒé‡å’Œä¸º0ï¼Œä½¿ç”¨åˆå§‹æƒé‡
                weights = initial_weights / (np.sum(initial_weights) + 1e-8)
                
        except np.linalg.LinAlgError:
            # æ±‚è§£å¤±è´¥ï¼Œä½¿ç”¨åˆå§‹æƒé‡
            weights = initial_weights / (np.sum(initial_weights) + 1e-8)
            
        return weights
        
    def compute_reconstruction_error(self, weights):
        """è®¡ç®—é‡å»ºè¯¯å·®"""
        print("ğŸ” è®¡ç®—é‡å»ºè¯¯å·®...")
        
        total_error = 0
        num_frames, num_vertices, _ = self.unified_meshes.shape
        
        for frame in range(num_frames):
            # é‡å»ºè¯¥å¸§çš„ç½‘æ ¼
            reconstructed = self.reconstruct_mesh_frame(frame, weights)
            
            # è®¡ç®—è¯¯å·®
            target = self.unified_meshes[frame]
            frame_error = np.linalg.norm(reconstructed - target, axis=1)
            total_error += np.mean(frame_error)
            
        avg_error = total_error / num_frames
        print(f"   å¹³å‡é‡å»ºè¯¯å·®: {avg_error:.6f}")
        
        return avg_error
        
    def reconstruct_mesh_frame(self, frame_idx, weights):
        """é‡å»ºæŒ‡å®šå¸§çš„ç½‘æ ¼"""
        num_vertices = self.rest_pose.shape[0]
        num_bones = weights.shape[1]
        
        reconstructed = np.zeros((num_vertices, 3))
        
        for vertex_idx in range(num_vertices):
            rest_pos = self.rest_pose[vertex_idx]
            rest_homo = np.append(rest_pos, 1.0)
            
            # åŠ æƒéª¨éª¼å˜æ¢
            final_pos = np.zeros(3)
            for bone in range(num_bones):
                weight = weights[vertex_idx, bone]
                if weight > 1e-6:
                    transform = self.bone_transforms[frame_idx, bone]
                    transformed = (transform @ rest_homo)[:3]
                    final_pos += weight * transformed
                    
            reconstructed[vertex_idx] = final_pos
            
        return reconstructed
        
    def refine_weights_with_regularization(self, weights, lambda_smooth=0.1):
        """ä½¿ç”¨æ­£åˆ™åŒ–ç²¾ç»†è°ƒæ•´æƒé‡"""
        print("ğŸ¯ åº”ç”¨æƒé‡å¹³æ»‘æ­£åˆ™åŒ–...")
        
        # æ„å»ºé‚»æ¥å…³ç³»ï¼ˆç®€åŒ–ç‰ˆï¼‰
        adjacency = self.build_simple_adjacency()
        
        # å¹³æ»‘åŒ–æƒé‡
        refined_weights = weights.copy()
        
        for bone in range(weights.shape[1]):
            bone_weights = weights[:, bone]
            
            # æ‹‰æ™®æ‹‰æ–¯å¹³æ»‘
            smoothed = bone_weights.copy()
            for vertex in range(len(bone_weights)):
                neighbors = adjacency[vertex]
                if len(neighbors) > 0:
                    neighbor_avg = np.mean([bone_weights[n] for n in neighbors])
                    smoothed[vertex] = (1 - lambda_smooth) * bone_weights[vertex] + lambda_smooth * neighbor_avg
                    
            refined_weights[:, bone] = smoothed
            
        # é‡æ–°å½’ä¸€åŒ–
        weight_sums = np.sum(refined_weights, axis=1, keepdims=True)
        weight_sums = np.maximum(weight_sums, 1e-8)
        refined_weights /= weight_sums
        
        return refined_weights
        
    def build_simple_adjacency(self):
        """æ„å»ºç®€åŒ–çš„é¡¶ç‚¹é‚»æ¥å…³ç³»"""
        print("   æ„å»ºé¡¶ç‚¹é‚»æ¥å…³ç³»...")
        
        num_vertices = self.rest_pose.shape[0]
        adjacency = [[] for _ in range(num_vertices)]
        
        # ä»ä¸‰è§’å½¢æ„å»ºé‚»æ¥å…³ç³»
        for triangle in self.triangles:
            v0, v1, v2 = triangle
            adjacency[v0].extend([v1, v2])
            adjacency[v1].extend([v0, v2])
            adjacency[v2].extend([v0, v1])
            
        # å»é‡
        for i in range(num_vertices):
            adjacency[i] = list(set(adjacency[i]))
            
        return adjacency
        
    def save_optimized_results(self, optimized_weights, output_dir):
        """ä¿å­˜ä¼˜åŒ–ç»“æœ"""
        os.makedirs(output_dir, exist_ok=True)
        
        # 1. ä¿å­˜ä¼˜åŒ–æƒé‡
        weights_path = os.path.join(output_dir, "optimized_skinning_weights.npy")
        np.save(weights_path, optimized_weights)
        
        # 2. ä¿å­˜å®Œæ•´ç»“æœ
        results = {
            'optimized_weights': optimized_weights,
            'heat_diffusion_weights': self.heat_diffusion_weights,
            'bone_transforms': self.bone_transforms,
            'unified_meshes': self.unified_meshes,
            'rest_pose': self.rest_pose,
            'triangles': self.triangles,
            'joints': self.joints,
            'parents': self.parents,
        }
        
        results_path = os.path.join(output_dir, "dembones_optimized_results.pkl")
        with open(results_path, 'wb') as f:
            pickle.dump(results, f)
            
        print(f"âœ… ä¼˜åŒ–ç»“æœå·²ä¿å­˜:")
        print(f"   æƒé‡æ–‡ä»¶: {weights_path}")
        print(f"   å®Œæ•´ç»“æœ: {results_path}")
        
        return results_path
        
    def run_optimization(self, output_dir):
        """è¿è¡Œå®Œæ•´çš„æƒé‡ä¼˜åŒ–æµç¨‹"""
        print("ğŸš€ å¯åŠ¨DemBonesæƒé‡ä¼˜åŒ–æµç¨‹...")
        
        # 1. è®¡ç®—åˆå§‹è¯¯å·®
        initial_error = self.compute_reconstruction_error(self.heat_diffusion_weights)
        print(f"ğŸ“Š åˆå§‹é‡å»ºè¯¯å·®: {initial_error:.6f}")
        
        # 2. è¿­ä»£ä¼˜åŒ–æƒé‡
        optimized_weights = self.optimize_skinning_weights_iterative(max_iterations=50)
        
        # 3. åº”ç”¨æ­£åˆ™åŒ–
        refined_weights = self.refine_weights_with_regularization(optimized_weights)
        
        # 4. è®¡ç®—æœ€ç»ˆè¯¯å·®
        final_error = self.compute_reconstruction_error(refined_weights)
        print(f"ğŸ“Š æœ€ç»ˆé‡å»ºè¯¯å·®: {final_error:.6f}")
        print(f"ğŸ“ˆ è¯¯å·®æ”¹å–„: {((initial_error - final_error) / initial_error * 100):.2f}%")
        
        # 5. ä¿å­˜ç»“æœ
        results_path = self.save_optimized_results(refined_weights, output_dir)
        
        print("ğŸ‰ DemBonesæƒé‡ä¼˜åŒ–å®Œæˆï¼")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {results_path}")
        
        return results_path, {
            'initial_error': initial_error,
            'final_error': final_error,
            'improvement_percent': (initial_error - final_error) / initial_error * 100
        }

def main():
    """ä¸»å‡½æ•°"""
    # è¾“å…¥è·¯å¾„
    unified_data_path = r"D:\Code\VVEditor\Rafa_Approves_hd_4k\generated_skeletons\advanced_unified_results.pkl"
    
    # è¾“å‡ºè·¯å¾„
    output_dir = r"D:\Code\VVEditor\Rafa_Approves_hd_4k\generated_skeletons\dembones_optimized"
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(unified_data_path):
        print(f"âŒ æ‰¾ä¸åˆ°ç»Ÿä¸€æ•°æ®æ–‡ä»¶: {unified_data_path}")
        return
        
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = SimplifiedDemBonesTrainer(unified_data_path)
    
    # è¿è¡Œä¼˜åŒ–
    results_path, metrics = trainer.run_optimization(output_dir)
    
    print(f"\nğŸ¯ ä¼˜åŒ–å®Œæˆ!")
    print(f"ğŸ“Š æ€§èƒ½æå‡: {metrics['improvement_percent']:.2f}%")
    print(f"ğŸ“ ç»“æœæ–‡ä»¶: {results_path}")

if __name__ == "__main__":
    main()
