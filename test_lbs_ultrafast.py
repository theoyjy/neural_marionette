#!/usr/bin/env python3
"""
è¶…å¿«é€ŸLBSæƒé‡ä¼˜åŒ–æµ‹è¯• - ä¸“é—¨é’ˆå¯¹å¤§ç½‘æ ¼ä¼˜åŒ–
"""

import numpy as np
import sys
from pathlib import Path
from Skinning import InverseMeshCanonicalizer

def test_fast_lbs():
    """
    è¶…å¿«é€ŸLBSæµ‹è¯• - ä½¿ç”¨æœ€å°åŒ–çš„è®¡ç®—
    """
    print("=" * 80)
    print("è¶…å¿«é€ŸLBSæƒé‡ä¼˜åŒ–æµ‹è¯•")
    print("=" * 80)
    
    skeleton_data_dir = "output/skeleton_prediction"
    mesh_folder_path = "D:/Code/VVEditor/Rafa_Approves_hd_4k"
    
    try:
        canonicalizer = InverseMeshCanonicalizer(
            skeleton_data_dir=skeleton_data_dir,
            reference_frame_idx=0
        )
        
        canonicalizer.load_mesh_sequence(mesh_folder_path)
        
        # è®¾ç½®rest pose
        canonicalizer.rest_pose_vertices = np.asarray(canonicalizer.reference_mesh.vertices)
        canonicalizer.rest_pose_transforms = canonicalizer.transforms[0]
        
        print(f"ç½‘æ ¼é¡¶ç‚¹æ•°: {len(canonicalizer.rest_pose_vertices)}")
        print(f"å…³èŠ‚æ•°: {canonicalizer.num_joints}")
        
        # æç®€ç‰ˆæœ¬ï¼šåªä½¿ç”¨å¾ˆå°‘çš„é¡¶ç‚¹å’Œå¾ˆå°‘çš„è¿­ä»£
        test_frame = 1
        print(f"\næµ‹è¯•å¸§ {test_frame} (æç®€ç‰ˆ)...")
        
        # ä¿®æ”¹ä¼˜åŒ–å‡½æ•°ä½¿å…¶æ›´å¿«
        weights, loss_history = canonicalizer.optimize_skinning_weights_for_frame(
            test_frame, 
            max_iter=20,  # æå°‘çš„è¿­ä»£
            regularization_lambda=0.01,
            init_method='distance_based'
        )
        
        print(f"\nâœ… æç®€ä¼˜åŒ–å®Œæˆï¼")
        print(f"æƒé‡çŸ©é˜µå½¢çŠ¶: {weights.shape}")
        print(f"æœ€ç»ˆæŸå¤±: {loss_history[0]:.6f}")
        
        # å¿«é€Ÿåˆ†æ
        non_zero_weights = weights > 0.01
        sparsity = np.mean(non_zero_weights)
        influences_per_vertex = np.sum(non_zero_weights, axis=1)
        
        print(f"\næƒé‡åˆ†æ:")
        print(f"ç¨€ç–åº¦: {sparsity:.3f}")
        print(f"å¹³å‡æ¯é¡¶ç‚¹å—å½±å“å…³èŠ‚æ•°: {np.mean(influences_per_vertex):.2f}")
        
        # ä¿å­˜ç»“æœ
        canonicalizer.skinning_weights = weights
        canonicalizer.save_skinning_weights("output/skinning_weights_fast.npz")
        print(f"æƒé‡å·²ä¿å­˜åˆ°: output/skinning_weights_fast.npz")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def test_minimal_validation():
    """
    æœ€å°åŒ–éªŒè¯æµ‹è¯•
    """
    print("=" * 80)
    print("æœ€å°åŒ–éªŒè¯æµ‹è¯•")
    print("=" * 80)
    
    skeleton_data_dir = "output/skeleton_prediction"
    mesh_folder_path = "D:/Code/VVEditor/Rafa_Approves_hd_4k"
    
    try:
        canonicalizer = InverseMeshCanonicalizer(
            skeleton_data_dir=skeleton_data_dir,
            reference_frame_idx=0
        )
        
        canonicalizer.load_mesh_sequence(mesh_folder_path)
        
        # å°è¯•åŠ è½½å·²ä¿å­˜çš„æƒé‡
        if canonicalizer.load_skinning_weights("output/skinning_weights_fast.npz"):
            print("æˆåŠŸåŠ è½½å·²ä¿å­˜çš„æƒé‡")
            
            # å¿«é€ŸéªŒè¯
            validation_results = canonicalizer.validate_skinning_weights(test_frames=[1])
            
            if validation_results:
                avg_error = validation_results['average_error']
                print(f"éªŒè¯ç»“æœ: å¹³å‡è¯¯å·® = {avg_error:.6f}")
                
                if avg_error < 0.1:
                    print("âœ… æƒé‡è´¨é‡å¯æ¥å—")
                else:
                    print("âš ï¸ æƒé‡è´¨é‡éœ€è¦æ”¹è¿›")
            
            return True
        else:
            print("æ— æ³•åŠ è½½æƒé‡æ–‡ä»¶")
            return False
        
    except Exception as e:
        print(f"âŒ éªŒè¯å¤±è´¥: {e}")
        return False

def create_simple_baseline_weights():
    """
    åˆ›å»ºç®€å•çš„åŸºå‡†æƒé‡ï¼ˆä¸è¿›è¡Œå¤æ‚ä¼˜åŒ–ï¼‰
    """
    print("=" * 80)
    print("åˆ›å»ºç®€å•åŸºå‡†æƒé‡")
    print("=" * 80)
    
    skeleton_data_dir = "output/skeleton_prediction"
    mesh_folder_path = "D:/Code/VVEditor/Rafa_Approves_hd_4k"
    
    try:
        canonicalizer = InverseMeshCanonicalizer(
            skeleton_data_dir=skeleton_data_dir,
            reference_frame_idx=0
        )
        
        canonicalizer.load_mesh_sequence(mesh_folder_path)
        
        # è®¾ç½®rest pose
        rest_vertices = np.asarray(canonicalizer.reference_mesh.vertices)
        canonicalizer.rest_pose_vertices = rest_vertices
        canonicalizer.rest_pose_transforms = canonicalizer.transforms[0]
        
        print(f"åˆ›å»ºåŸºäºè·ç¦»çš„ç®€å•æƒé‡...")
        
        # è®¡ç®—å½’ä¸€åŒ–
        rest_norm_params = canonicalizer.frame_normalization_params[0]
        rest_vertices_norm = canonicalizer.normalize_mesh_vertices(rest_vertices, rest_norm_params)
        
        # è·å–å…³èŠ‚ç‚¹
        keypoints = canonicalizer.keypoints[0, :, :3]
        
        # è®¡ç®—è·ç¦»æƒé‡
        distances = np.linalg.norm(rest_vertices_norm[:, None, :] - keypoints[None, :, :], axis=2)
        weights = np.exp(-distances**2 / (2 * 0.1**2))
        weights = weights / (np.sum(weights, axis=1, keepdims=True) + 1e-8)
        
        # ç¨€ç–åŒ–æƒé‡ï¼ˆåªä¿ç•™å‰3ä¸ªæœ€å¼ºçš„å…³èŠ‚ï¼‰
        for i in range(len(weights)):
            top_3_indices = np.argsort(weights[i])[-3:]
            sparse_weights = np.zeros(canonicalizer.num_joints)
            sparse_weights[top_3_indices] = weights[i][top_3_indices]
            sparse_weights = sparse_weights / (np.sum(sparse_weights) + 1e-8)
            weights[i] = sparse_weights
        
        canonicalizer.skinning_weights = weights
        
        print(f"åŸºå‡†æƒé‡åˆ›å»ºå®Œæˆ:")
        print(f"æƒé‡çŸ©é˜µå½¢çŠ¶: {weights.shape}")
        
        # åˆ†ææƒé‡
        non_zero_weights = weights > 0.01
        sparsity = np.mean(non_zero_weights)
        influences_per_vertex = np.sum(non_zero_weights, axis=1)
        
        print(f"ç¨€ç–åº¦: {sparsity:.3f}")
        print(f"å¹³å‡æ¯é¡¶ç‚¹å—å½±å“å…³èŠ‚æ•°: {np.mean(influences_per_vertex):.2f}")
        
        # ä¿å­˜åŸºå‡†æƒé‡
        canonicalizer.save_skinning_weights("output/skinning_weights_baseline.npz")
        
        # å¿«é€ŸéªŒè¯åŸºå‡†æƒé‡
        print(f"\néªŒè¯åŸºå‡†æƒé‡...")
        validation_results = canonicalizer.validate_skinning_weights(test_frames=[1, 2])
        
        if validation_results:
            avg_error = validation_results['average_error']
            print(f"åŸºå‡†æƒé‡å¹³å‡è¯¯å·®: {avg_error:.6f}")
            
            for frame_idx, frame_result in validation_results['frame_errors'].items():
                print(f"  å¸§ {frame_idx}: {frame_result['mean_error']:.6f}")
        
        return True
        
    except Exception as e:
        print(f"âŒ åˆ›å»ºåŸºå‡†æƒé‡å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    print("é€‰æ‹©æµ‹è¯•æ¨¡å¼:")
    print("1. è¶…å¿«é€ŸLBSä¼˜åŒ–æµ‹è¯•")
    print("2. éªŒè¯å·²ä¿å­˜çš„æƒé‡")
    print("3. åˆ›å»ºç®€å•åŸºå‡†æƒé‡")
    
    try:
        choice = input("è¯·è¾“å…¥é€‰æ‹© (1/2/3): ").strip()
        
        if choice == "2":
            success = test_minimal_validation()
        elif choice == "3":
            success = create_simple_baseline_weights()
        else:
            success = test_fast_lbs()
        
        if success:
            print("\nğŸ‰ æµ‹è¯•æˆåŠŸå®Œæˆï¼")
        else:
            print("\nâŒ æµ‹è¯•å¤±è´¥")
            sys.exit(1)
            
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­æµ‹è¯•")
    except Exception as e:
        print(f"\næµ‹è¯•å‡ºé”™: {e}")
        sys.exit(1)
