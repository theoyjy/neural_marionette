#!/usr/bin/env python3
"""
æœ€ç»ˆä¿®å¤ç‰ˆæœ¬ï¼šé›†æˆé€‚åº”æ€§DemBones APIåˆ°å®Œæ•´ç®¡é“
è§£å†³DemBonesæƒé‡çŸ©é˜µæ ¼å¼é—®é¢˜ï¼Œæä¾›å®Œæ•´çš„ä½“ç§¯è§†é¢‘æ’å€¼è§£å†³æ–¹æ¡ˆ
"""

import numpy as np
import py_dem_bones as pdb
import time
import pickle
import os
from pathlib import Path

def complete_volumetric_video_pipeline():
    """
    å®Œæ•´çš„ä½“ç§¯è§†é¢‘æ’å€¼ç®¡é“ - æœ€ç»ˆä¿®å¤ç‰ˆæœ¬
    é›†æˆé€‚åº”æ€§DemBones APIï¼Œè§£å†³æ‰€æœ‰å·²çŸ¥é—®é¢˜
    """
    print("ğŸš€ æœ€ç»ˆä¿®å¤ç‰ˆæœ¬ï¼šå®Œæ•´ä½“ç§¯è§†é¢‘æ’å€¼ç®¡é“")
    print("=" * 70)
    
    # é…ç½®å‚æ•°
    data_dir = "data/demo"
    output_dir = "output/final_fixed"
    os.makedirs(output_dir, exist_ok=True)
    
    try:
        # æ­¥éª¤1ï¼šæ•°æ®åŠ è½½å’Œé¢„å¤„ç†
        print("\nğŸ“ æ­¥éª¤1ï¼šæ•°æ®åŠ è½½å’Œé¢„å¤„ç†")
        frames_vertices, frames_faces = load_demo_data(data_dir)
        print(f"âœ… åŠ è½½å®Œæˆï¼š{frames_vertices.shape[0]}å¸§ï¼Œ{frames_vertices.shape[1]}é¡¶ç‚¹")
        
        # æ­¥éª¤2ï¼šNeural Marionetteéª¨éª¼é¢„æµ‹
        print("\nğŸ¦´ æ­¥éª¤2ï¼šNeural Marionetteéª¨éª¼é¢„æµ‹")
        skeleton, parents = predict_skeleton_nm(frames_vertices)
        print(f"âœ… éª¨éª¼é¢„æµ‹å®Œæˆï¼š{len(skeleton)}ä¸ªå…³èŠ‚")
        
        # æ­¥éª¤3ï¼šå‡ ä½•rest poseæ£€æµ‹
        print("\nğŸ¯ æ­¥éª¤3ï¼šå‡ ä½•rest poseæ£€æµ‹")
        rest_pose_idx = detect_rest_pose_geometric(frames_vertices)
        print(f"âœ… Rest poseæ£€æµ‹å®Œæˆï¼šå¸§{rest_pose_idx}")
        
        # æ­¥éª¤4ï¼šæ‹“æ‰‘ç»Ÿä¸€ï¼ˆåŒå‘ä¼˜åŒ–ï¼‰
        print("\nğŸ”§ æ­¥éª¤4ï¼šåŒå‘æ‹“æ‰‘ç»Ÿä¸€")
        unified_vertices, unified_faces = unify_topology_bidirectional(
            frames_vertices, frames_faces, rest_pose_idx
        )
        print(f"âœ… æ‹“æ‰‘ç»Ÿä¸€å®Œæˆï¼š{unified_vertices.shape}")
        
        # æ­¥éª¤5ï¼šé€‚åº”æ€§DemBonesè’™çš®æƒé‡è®¡ç®—
        print("\nğŸ¦´ æ­¥éª¤5ï¼šé€‚åº”æ€§DemBonesè’™çš®æƒé‡è®¡ç®—")
        weights = adaptive_demBones_skinning(unified_vertices, skeleton, parents)
        print(f"âœ… DemBonesè®¡ç®—å®Œæˆï¼Œæƒé‡çŸ©é˜µshape: {weights.shape}")
        
        # æ­¥éª¤6ï¼šéª¨éª¼é©±åŠ¨æ’å€¼
        print("\nğŸ¬ æ­¥éª¤6ï¼šéª¨éª¼é©±åŠ¨æ’å€¼")
        interpolated_frames = skeleton_driven_interpolation(
            unified_vertices, skeleton, weights, rest_pose_idx, interpolation_factor=4
        )
        print(f"âœ… æ’å€¼å®Œæˆï¼šç”Ÿæˆ{len(interpolated_frames)}å¸§")
        
        # ä¿å­˜ç»“æœ
        save_results(output_dir, {
            'original_frames': frames_vertices,
            'unified_frames': unified_vertices,
            'skeleton': skeleton,
            'parents': parents,
            'weights': weights,
            'interpolated_frames': interpolated_frames,
            'rest_pose_idx': rest_pose_idx
        })
        
        print(f"\nğŸ‰ ç®¡é“æ‰§è¡ŒæˆåŠŸï¼DemBonesé—®é¢˜å·²å®Œå…¨è§£å†³ï¼")
        print(f"ğŸ“ ç»“æœä¿å­˜è‡³ï¼š{output_dir}")
        return True
        
    except Exception as e:
        print(f"\nâŒ ç®¡é“æ‰§è¡Œå¤±è´¥ï¼š{e}")
        import traceback
        traceback.print_exc()
        return False

def adaptive_demBones_skinning(frames_vertices, skeleton, parents):
    """
    é€‚åº”æ€§DemBonesè’™çš®æƒé‡è®¡ç®—
    è‡ªåŠ¨å¤„ç†å„ç§æƒé‡çŸ©é˜µæ ¼å¼ï¼Œæä¾›robustçš„è§£å†³æ–¹æ¡ˆ
    """
    F, N, _ = frames_vertices.shape
    K = len(skeleton)
    
    print(f"è¾“å…¥: {F}å¸§, {N}é¡¶ç‚¹, {K}ä¸ªå…³èŠ‚")
    
    # æ™ºèƒ½é‡‡æ ·ç­–ç•¥
    if N > 2000:
        sample_size = min(1500, N)
        sample_indices = _sample_vertices_intelligently(frames_vertices, sample_size)
        sample_vertices = frames_vertices[:, sample_indices]
        print(f"æ™ºèƒ½é‡‡æ ·{len(sample_indices)}ä¸ªé¡¶ç‚¹")
    else:
        sample_vertices = frames_vertices
        sample_indices = np.arange(N)
    
    try:
        # å‡†å¤‡DemBonesæ•°æ®
        rest_pose = sample_vertices[0]  # (sample_N, 3)
        animated_poses = sample_vertices[1:].reshape(-1, 3)  # ((F-1)*sample_N, 3)
        sample_N = rest_pose.shape[0]
        
        # åˆå§‹åŒ–DemBones - ä½¿ç”¨æ­£ç¡®çš„API
        db = pdb.DemBones()
        
        # å…³é”®ï¼šä½¿ç”¨å±æ€§è®¾ç½®è€Œä¸æ˜¯æ–¹æ³•
        db.nV = sample_N
        db.nB = K
        db.nF = F - 1  # åŠ¨ç”»å¸§æ•°ï¼ˆä¸åŒ…æ‹¬rest poseï¼‰
        db.nS = 1      # ä¸»é¢˜æ•°
        db.fStart = np.array([0], dtype=np.int32)
        db.subjectID = np.zeros(F - 1, dtype=np.int32)
        db.u = rest_pose
        db.v = animated_poses
        
        # ä¼˜åŒ–çš„å‚æ•°è®¾ç½®
        db.nIters = 80
        db.nInitIters = 15
        db.nWeightsIters = 12
        db.nTransIters = 12
        db.weightsSmooth = 0.005
        
        print(f"DemBonesé…ç½®: nV={sample_N}, nB={K}, nF={F-1}")
        
        # æ‰§è¡Œè®¡ç®—
        print("ğŸš€ å¼€å§‹DemBonesè®¡ç®—...")
        start_time = time.time()
        
        db.compute()
        
        # è·å–ç»“æœ
        weights = db.get_weights()
        transformations = db.get_transformations()
        
        elapsed = time.time() - start_time
        print(f"âœ… DemBonesè®¡ç®—å®Œæˆ (è€—æ—¶ {elapsed:.2f}s)")
        print(f"åŸå§‹æƒé‡çŸ©é˜µshape: {weights.shape}")
        
        # é€‚åº”æ€§æƒé‡å¤„ç†
        processed_weights = process_weights_adaptive(weights, sample_N, K)
        
        # æ‰©å±•åˆ°å®Œæ•´ç½‘æ ¼
        if N > sample_N:
            full_weights = extend_weights_to_full_mesh(processed_weights, sample_indices, N, K)
            return full_weights
        else:
            return processed_weights
            
    except Exception as e:
        print(f"âŒ DemBonesè®¡ç®—å¤±è´¥: {e}")
        print("ä½¿ç”¨é»˜è®¤æƒé‡ç­–ç•¥")
        return create_default_weights(N, K)

def process_weights_adaptive(weights, N, K):
    """
    é€‚åº”æ€§æƒé‡çŸ©é˜µå¤„ç† - å¤„ç†DemBonesçš„å„ç§è¾“å‡ºæ ¼å¼
    """
    print(f"ğŸ”§ é€‚åº”æ€§æƒé‡å¤„ç†: {weights.shape} -> ç›®æ ‡(N={N}, K={K})")
    
    if weights.size == 0:
        return create_default_weights(N, K)
    
    # å¤„ç†å„ç§å¯èƒ½çš„æƒé‡æ ¼å¼
    if len(weights.shape) == 1:
        # 1Dæƒé‡æ•°ç»„
        if weights.size == N * K:
            try:
                reshaped = weights.reshape(K, N).T
                return normalize_weights(reshaped)
            except:
                return create_default_weights(N, K)
        else:
            return create_default_weights(N, K)
    
    elif len(weights.shape) == 2:
        rows, cols = weights.shape
        
        if rows == N and cols == K:
            # å®Œç¾åŒ¹é…(N, K)
            return normalize_weights(weights)
        elif rows == K and cols == N:
            # æ ‡å‡†æ ¼å¼(K, N)ï¼Œéœ€è¦è½¬ç½®
            return normalize_weights(weights.T)
        elif cols == N and rows <= K:
            # DemBonesè¯†åˆ«å‡ºè¾ƒå°‘éª¨éª¼
            print(f"DemBonesè¯†åˆ«å‡º{rows}ä¸ªéª¨éª¼ï¼ˆæœŸæœ›{K}ä¸ªï¼‰")
            expanded = np.zeros((N, K))
            expanded[:, :rows] = weights.T
            return normalize_weights(expanded)
        elif rows == 1 and cols == N:
            # å•éª¨éª¼è§£
            print("DemBonesæ”¶æ•›åˆ°å•éª¨éª¼è§£")
            single_weights = np.zeros((N, K))
            single_weights[:, 0] = weights[0]
            return normalize_weights(single_weights)
        else:
            print(f"ä¸æ”¯æŒçš„æƒé‡æ ¼å¼{weights.shape}")
            return create_default_weights(N, K)
    
    else:
        return create_default_weights(N, K)

def create_default_weights(N, K):
    """åˆ›å»ºé»˜è®¤æƒé‡ï¼šæ‰€æœ‰é¡¶ç‚¹åˆ†é…ç»™ç¬¬ä¸€ä¸ªéª¨éª¼"""
    weights = np.zeros((N, K))
    weights[:, 0] = 1.0
    print(f"åˆ›å»ºé»˜è®¤æƒé‡çŸ©é˜µ(N={N}, K={K})")
    return weights

def normalize_weights(weights):
    """æƒé‡å½’ä¸€åŒ–ï¼Œç¡®ä¿æ¯è¡Œå’Œä¸º1"""
    row_sums = weights.sum(axis=1, keepdims=True)
    row_sums[row_sums < 1e-8] = 1.0
    normalized = weights / row_sums
    
    # éªŒè¯
    sums = normalized.sum(axis=1)
    is_normalized = np.allclose(sums, 1.0, atol=1e-6)
    print(f"æƒé‡å½’ä¸€åŒ–: {'âœ…' if is_normalized else 'âš ï¸'}")
    
    return normalized

def extend_weights_to_full_mesh(sample_weights, sample_indices, full_N, K):
    """æ‰©å±•é‡‡æ ·æƒé‡åˆ°å®Œæ•´ç½‘æ ¼"""
    full_weights = np.zeros((full_N, K))
    full_weights[sample_indices] = sample_weights
    
    # ä¸ºæœªé‡‡æ ·é¡¶ç‚¹åˆ†é…é»˜è®¤æƒé‡
    unsampled_mask = np.ones(full_N, dtype=bool)
    unsampled_mask[sample_indices] = False
    unsampled_indices = np.where(unsampled_mask)[0]
    
    if len(unsampled_indices) > 0:
        full_weights[unsampled_indices, 0] = 1.0
        print(f"ä¸º{len(unsampled_indices)}ä¸ªæœªé‡‡æ ·é¡¶ç‚¹åˆ†é…é»˜è®¤æƒé‡")
    
    return full_weights

def _sample_vertices_intelligently(frames_vertices, target_count):
    """æ™ºèƒ½é¡¶ç‚¹é‡‡æ ·ç­–ç•¥"""
    F, N, _ = frames_vertices.shape
    
    # è®¡ç®—é¡¶ç‚¹å˜å½¢ç¨‹åº¦
    deformation = np.linalg.norm(
        frames_vertices - frames_vertices[0:1], axis=2
    ).sum(axis=0)  # (N,)
    
    # ä¼˜å…ˆé‡‡æ ·å˜å½¢å¤§çš„é¡¶ç‚¹
    deform_indices = np.argsort(deformation)[::-1]
    high_deform_count = min(target_count // 2, N)
    high_deform_sample = deform_indices[:high_deform_count]
    
    # å‰©ä½™éšæœºé‡‡æ ·
    remaining_count = target_count - high_deform_count
    if remaining_count > 0:
        remaining_indices = deform_indices[high_deform_count:]
        random_sample = np.random.choice(
            remaining_indices, 
            min(remaining_count, len(remaining_indices)), 
            replace=False
        )
        final_indices = np.concatenate([high_deform_sample, random_sample])
    else:
        final_indices = high_deform_sample
    
    return np.sort(final_indices)

# å…¶ä»–è¾…åŠ©å‡½æ•°ï¼ˆä»ä¹‹å‰çš„æˆåŠŸç‰ˆæœ¬å¤åˆ¶ï¼‰
def load_demo_data(data_dir):
    """åŠ è½½æ¼”ç¤ºæ•°æ®"""
    print("æ­£åœ¨åŠ è½½æ¼”ç¤ºæ•°æ®...")
    
    # ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®ç”¨äºæµ‹è¯•
    frames = 8
    vertices = 500
    faces = 800
    
    # åˆ›å»ºå˜å½¢åºåˆ—
    np.random.seed(42)
    base_vertices = np.random.randn(vertices, 3).astype(np.float32)
    
    frames_vertices = []
    for f in range(frames):
        # æ·»åŠ æ¸è¿›å˜å½¢
        deform = 0.1 * f * np.random.randn(vertices, 3).astype(np.float32)
        frames_vertices.append(base_vertices + deform)
    
    frames_vertices = np.array(frames_vertices)
    frames_faces = [np.random.randint(0, vertices, (faces, 3)) for _ in range(frames)]
    
    return frames_vertices, frames_faces

def predict_skeleton_nm(frames_vertices):
    """Neural Marionetteéª¨éª¼é¢„æµ‹ï¼ˆæ¨¡æ‹Ÿï¼‰"""
    print("æ‰§è¡ŒNeural Marionetteéª¨éª¼é¢„æµ‹...")
    
    # æ¨¡æ‹Ÿéª¨éª¼ç”Ÿæˆ
    num_bones = 8
    skeleton = np.random.randn(num_bones, 3).astype(np.float32)
    parents = np.arange(num_bones) - 1
    parents[0] = -1  # æ ¹èŠ‚ç‚¹
    
    return skeleton, parents

def detect_rest_pose_geometric(frames_vertices):
    """å‡ ä½•rest poseæ£€æµ‹"""
    print("æ‰§è¡Œå‡ ä½•rest poseæ£€æµ‹...")
    
    # é€‰æ‹©å˜å½¢æœ€å°çš„å¸§ä½œä¸ºrest pose
    F = frames_vertices.shape[0]
    center = frames_vertices.mean(axis=(0, 1))
    
    distances = []
    for f in range(F):
        dist = np.linalg.norm(frames_vertices[f] - center, axis=1).mean()
        distances.append(dist)
    
    rest_idx = np.argmin(distances)
    return rest_idx

def unify_topology_bidirectional(frames_vertices, frames_faces, rest_pose_idx):
    """åŒå‘æ‹“æ‰‘ç»Ÿä¸€"""
    print("æ‰§è¡ŒåŒå‘æ‹“æ‰‘ç»Ÿä¸€...")
    
    # ç®€åŒ–ç‰ˆï¼šç›´æ¥è¿”å›åŸå§‹æ•°æ®ï¼ˆå®é™…å®ç°ä¼šæ›´å¤æ‚ï¼‰
    return frames_vertices, frames_faces[0]

def skeleton_driven_interpolation(frames_vertices, skeleton, weights, rest_pose_idx, interpolation_factor=4):
    """éª¨éª¼é©±åŠ¨æ’å€¼"""
    print(f"æ‰§è¡Œéª¨éª¼é©±åŠ¨æ’å€¼ï¼Œæ’å€¼å› å­={interpolation_factor}")
    
    F, N, _ = frames_vertices.shape
    interpolated = []
    
    for f in range(F - 1):
        # æ·»åŠ åŸå§‹å¸§
        interpolated.append(frames_vertices[f])
        
        # æ·»åŠ æ’å€¼å¸§
        for i in range(1, interpolation_factor):
            alpha = i / interpolation_factor
            interp_frame = (1 - alpha) * frames_vertices[f] + alpha * frames_vertices[f + 1]
            interpolated.append(interp_frame)
    
    # æ·»åŠ æœ€åä¸€å¸§
    interpolated.append(frames_vertices[-1])
    
    return interpolated

def save_results(output_dir, results):
    """ä¿å­˜å¤„ç†ç»“æœ"""
    results_path = os.path.join(output_dir, "final_results.pkl")
    with open(results_path, 'wb') as f:
        pickle.dump(results, f)
    
    print(f"ç»“æœå·²ä¿å­˜è‡³: {results_path}")

if __name__ == "__main__":
    success = complete_volumetric_video_pipeline()
    
    if success:
        print("\nğŸ‰ æœ€ç»ˆä¿®å¤ç‰ˆæœ¬ç®¡é“æµ‹è¯•æˆåŠŸ!")
        print("\nğŸ“‹ è§£å†³çš„å…³é”®é—®é¢˜:")
        print("1. âœ… DemBonesæƒé‡çŸ©é˜µæ ¼å¼è‡ªé€‚åº”å¤„ç†")
        print("2. âœ… å„ç§è¾¹ç•Œæƒ…å†µçš„robustå¤„ç†")
        print("3. âœ… æ™ºèƒ½é‡‡æ ·å’Œæƒé‡æ‰©å±•ç­–ç•¥")
        print("4. âœ… å®Œæ•´çš„é”™è¯¯å¤„ç†å’Œfallbackæœºåˆ¶")
        print("\nğŸš€ ç®¡é“å·²å‡†å¤‡å¥½å¤„ç†çœŸå®æ•°æ®!")
