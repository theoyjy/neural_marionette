#!/usr/bin/env python3
"""
å®Œæ•´çš„ä½“ç§¯è§†é¢‘æ’å€¼ç®¡é“ - æœ€ç»ˆç‰ˆæœ¬
=================================

åŠŸèƒ½ï¼š
1. åŠ è½½æ–‡ä»¶å¤¹ä¸­çš„.objæ–‡ä»¶ï¼Œæ¯å¸§é€šè¿‡voxelåŒ–åäº¤ç»™NeuralMarionetteé¢„æµ‹skeleton
2. è‡ªåŠ¨æ£€æµ‹æœ€ä½³rest poseï¼ŒåŸºäºskeletonè¿›è¡Œç½‘æ ¼æ‹“æ‰‘ç»Ÿä¸€
3. ä½¿ç”¨ä¿®å¤åçš„DemBonesè¿›è¡Œè’™çš®æƒé‡é¢„æµ‹
4. ç”Ÿæˆä»»æ„ä¸¤å¸§ä¹‹é—´çš„æŒ‡å®šæ•°é‡æ’å€¼

ä½¿ç”¨æ–¹æ³•ï¼š
python complete_vv_pipeline.py <folder_path> --start_frame 0 --end_frame 10 --num_interp 5
"""

import argparse
import os
import glob
import time
import pickle
import numpy as np
import torch
import open3d as o3d
import threading
import queue
from copy import deepcopy
from scipy.spatial.transform import Rotation, Slerp
from scipy.spatial import cKDTree

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from model.neural_marionette import NeuralMarionette
from utils.dataset_utils import voxelize
import subprocess
import tempfile
import struct

# å¯¼å…¥GenerateSkelçš„å‡½æ•°
from GenerateSkel import (
    load_voxel_from_mesh, 
    process_single_mesh,
    sanitize_parents,
    draw_skeleton,
    _as_colmajor,
    _as_rowmajor
)

class CompleteVVPipeline:
    """å®Œæ•´çš„ä½“ç§¯è§†é¢‘æ’å€¼ç®¡é“"""
    
    def __init__(self, folder_path, output_dir=None):
        self.folder_path = folder_path
        self.output_dir = output_dir or os.path.join(folder_path, 'vv_complete_output')
        os.makedirs(self.output_dir, exist_ok=True)
        
        # åŠ è½½NeuralMarionette
        self._load_neural_marionette()
        
        # ç®¡é“æ•°æ®
        self.all_mesh_data = []
        self.rest_pose_idx = None
        self.unified_vertices = None
        self.skinning_weights = None
        self.bone_transforms = None
        self.parents = None
        
    def _load_neural_marionette(self):
        """åŠ è½½é¢„è®­ç»ƒçš„NeuralMarionetteç½‘ç»œ"""
        exp_dir = 'pretrained/aist'
        opt_path = os.path.join(exp_dir, 'opt.pickle')
        with open(opt_path, 'rb') as f:
            self.opt = pickle.load(f)
        self.opt.Ttot = 1

        ckpt_path = os.path.join(exp_dir, 'aist_pretrained.pth')
        checkpoint = torch.load(ckpt_path)
        self.network = NeuralMarionette(self.opt).cuda()
        self.network.load_state_dict(checkpoint)
        self.network.eval()
        self.network.anneal(1)
        
        print("âœ“ NeuralMarionette loaded successfully")
    
    def step1_process_frames(self, start_frame=0, end_frame=None):
        """
        æ­¥éª¤1ï¼šå¤„ç†æŒ‡å®šèŒƒå›´çš„å¸§ï¼Œæå–skeletonæ•°æ®
        """
        print(f"\n=== æ­¥éª¤1ï¼šå¤„ç†å¸§æ•°æ® ({start_frame} åˆ° {end_frame}) ===")
        
        obj_files = sorted(glob.glob(os.path.join(self.folder_path, "*.obj")))
        if not obj_files:
            raise ValueError(f"åœ¨ {self.folder_path} ä¸­æœªæ‰¾åˆ°.objæ–‡ä»¶")
        
        # ç¡®å®šå¤„ç†èŒƒå›´
        if end_frame is None or end_frame >= len(obj_files):
            end_frame = len(obj_files) - 1
        
        selected_files = obj_files[start_frame:end_frame+1]
        print(f"å¤„ç† {len(selected_files)} ä¸ªæ–‡ä»¶")
        
        # å¤„ç†æ¯ä¸ªmeshæ–‡ä»¶
        for i, obj_file in enumerate(selected_files):
            print(f"å¤„ç† {i+1}/{len(selected_files)}: {os.path.basename(obj_file)}")
            
            try:
                mesh_data = process_single_mesh(obj_file, self.network, self.opt, self.output_dir)
                self.all_mesh_data.append(mesh_data)
                
                if i < 3:  # åªæ˜¾ç¤ºå‰3ä¸ªçš„è¯¦ç»†ä¿¡æ¯
                    joints_world = (mesh_data['joints'] + 1) * 0.5 * mesh_data['blen'] + mesh_data['bmin']
                    print(f"  âœ“ {len(mesh_data['pts_raw'])} é¡¶ç‚¹, {len(mesh_data['joints'])} å…³èŠ‚")
                    
            except Exception as e:
                print(f"  âŒ å¤„ç† {obj_file} å¤±è´¥: {e}")
                continue
        
        if not self.all_mesh_data:
            raise RuntimeError("æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•mesh")
        
        print(f"âœ“ æˆåŠŸå¤„ç† {len(self.all_mesh_data)} å¸§")
        return len(self.all_mesh_data)
    
    def step2_detect_rest_pose(self):
        """
        æ­¥éª¤2ï¼šè‡ªåŠ¨æ£€æµ‹æœ€ä½³rest pose
        åŸºäºç½‘æ ¼å’Œéª¨éª¼çš„å‡ ä½•ç‰¹æ€§ï¼Œä¸ä¾èµ–è¯­ä¹‰å…³èŠ‚
        """
        print("\n=== æ­¥éª¤2ï¼šæ£€æµ‹æœ€ä½³Rest Pose (åŸºäºå‡ ä½•ç‰¹æ€§) ===")
        
        scores = []
        
        for i, data in enumerate(self.all_mesh_data):
            joints = data['joints']  # å½’ä¸€åŒ–åæ ‡
            mesh_vertices = data['pts_norm']
            parents = sanitize_parents(data['parents'])
            R_rotations = data['R']  # æ—‹è½¬çŸ©é˜µ
            
            # æŒ‡æ ‡1ï¼šéª¨éª¼ç»“æ„ç¨³å®šæ€§ï¼ˆéª¨é•¿å˜åŒ–å°ï¼‰
            bone_lengths = []
            for j in range(len(joints)):
                if parents[j] >= 0:
                    bone_length = np.linalg.norm(joints[j] - joints[parents[j]])
                    bone_lengths.append(bone_length)
            
            if bone_lengths:
                bone_length_std = np.std(bone_lengths)
                bone_length_mean = np.mean(bone_lengths)
                bone_stability = 1.0 / (bone_length_std / (bone_length_mean + 1e-6) + 0.01)  # å˜å¼‚ç³»æ•°å€’æ•°
            else:
                bone_stability = 0
            
            # æŒ‡æ ‡2ï¼šå…³èŠ‚åˆ†å¸ƒå‡åŒ€æ€§ï¼ˆå…³èŠ‚åœ¨ç©ºé—´ä¸­åˆ†å¸ƒå‡åŒ€ï¼‰
            if len(joints) > 1:
                joint_center = joints.mean(axis=0)
                joint_distances = np.linalg.norm(joints - joint_center, axis=1)
                joint_spread = np.std(joint_distances)  # åˆ†å¸ƒæ ‡å‡†å·®
                joint_coverage = np.ptp(joints, axis=0).mean()  # è¦†ç›–èŒƒå›´
                distribution_score = joint_spread * joint_coverage  # æ—¢è¦åˆ†æ•£åˆè¦è¦†ç›–èŒƒå›´å¤§
            else:
                distribution_score = 0
            
            # æŒ‡æ ‡3ï¼šæ—‹è½¬çŸ©é˜µæ¥è¿‘å•ä½çŸ©é˜µï¼ˆminimal rotationï¼‰
            rotation_deviations = []
            for R in R_rotations:
                deviation = np.linalg.norm(R - np.eye(3), 'fro')  # FrobeniusèŒƒæ•°
                rotation_deviations.append(deviation)
            
            avg_rotation_deviation = np.mean(rotation_deviations)
            rotation_minimality = 1.0 / (avg_rotation_deviation + 0.1)  # åå·®è¶Šå°è¶Šå¥½
            
            # æŒ‡æ ‡4ï¼šç½‘æ ¼ç´§å‡‘æ€§å’Œä¸­å¿ƒæ€§
            mesh_center = mesh_vertices.mean(axis=0)
            mesh_bounds = mesh_vertices.max(axis=0) - mesh_vertices.min(axis=0)
            mesh_compactness = 1.0 / (np.prod(mesh_bounds) + 1e-6)  # ä½“ç§¯è¶Šå°è¶Šç´§å‡‘
            
            # å…³èŠ‚-ç½‘æ ¼ä¸­å¿ƒå¯¹é½
            if len(joints) > 0:
                joint_center = joints.mean(axis=0)
                center_alignment = 1.0 / (np.linalg.norm(joint_center - mesh_center) + 0.1)
            else:
                center_alignment = 0
            
            # æŒ‡æ ‡5ï¼šéª¨éª¼å±‚æ¬¡ç»“æ„è´¨é‡
            # æ£€æŸ¥parentå…³ç³»çš„åˆç†æ€§
            hierarchy_score = 0
            for j in range(len(joints)):
                if parents[j] >= 0:
                    parent_pos = joints[parents[j]]
                    child_pos = joints[j]
                    # å¥½çš„å±‚æ¬¡ç»“æ„ä¸­ï¼Œå­å…³èŠ‚ä¸åº”è¯¥ç¦»æ ¹éƒ¨å¤ªè¿œ
                    distance_to_parent = np.linalg.norm(child_pos - parent_pos)
                    hierarchy_score += 1.0 / (distance_to_parent + 0.1)
            
            hierarchy_score = hierarchy_score / max(1, len(joints))
            
            # ç»„åˆåŠ æƒå¾—åˆ† - æ›´æ³¨é‡å‡ ä½•ç‰¹æ€§è€Œä¸æ˜¯è¯­ä¹‰
            score = (
                3.0 * bone_stability +          # éª¨éª¼ç¨³å®šæ€§æœ€é‡è¦
                2.0 * rotation_minimality +     # æœ€å°æ—‹è½¬å¾ˆé‡è¦
                1.5 * distribution_score +      # å…³èŠ‚åˆ†å¸ƒ
                1.0 * center_alignment +        # ä¸­å¿ƒå¯¹é½
                1.0 * hierarchy_score +         # å±‚æ¬¡ç»“æ„
                0.5 * mesh_compactness          # ç½‘æ ¼ç´§å‡‘æ€§
            )
            
            scores.append(score)
            print(f"  å¸§ {i:2d}: éª¨é•¿ç¨³å®š={bone_stability:.3f}, æ—‹è½¬æœ€å°={rotation_minimality:.3f}, "
                  f"å…³èŠ‚åˆ†å¸ƒ={distribution_score:.3f}, ä¸­å¿ƒå¯¹é½={center_alignment:.3f}, "
                  f"å±‚æ¬¡={hierarchy_score:.3f}, æ€»åˆ†={score:.3f}")
        
        # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„å¸§
        self.rest_pose_idx = np.argmax(scores)
        rest_data = self.all_mesh_data[self.rest_pose_idx]
        
        print(f"âœ“ åŸºäºå‡ ä½•ç‰¹æ€§é€‰æ‹©å¸§ {self.rest_pose_idx} ä½œä¸ºrest pose: {rest_data['base_name']}")
        print(f"  å«æœ‰ {len(rest_data['pts_raw'])} é¡¶ç‚¹, {len(rest_data['joints'])} å…³èŠ‚")
        print(f"  å‡ ä½•å¾—åˆ†: {scores[self.rest_pose_idx]:.3f}")
        
        return self.rest_pose_idx
    
    def step3_unify_mesh_topology(self):
        """
        æ­¥éª¤3ï¼šåŸºäºéª¨éª¼ç»“æ„çš„ç½‘æ ¼æ‹“æ‰‘ç»Ÿä¸€
        ä»rest poseå¼€å§‹å‘ä¸¤è¾¹è¿›è¡Œremapï¼Œä¿è¯æ›´å¥½çš„æ—¶é—´ä¸€è‡´æ€§
        """
        print("\n=== æ­¥éª¤3ï¼šåŸºäºéª¨éª¼çš„ç½‘æ ¼æ‹“æ‰‘ç»Ÿä¸€ (ä»rest poseå‘ä¸¤è¾¹) ===")
        
        if self.rest_pose_idx is None:
            raise RuntimeError("å¿…é¡»å…ˆæ£€æµ‹rest pose")
        
        template_data = self.all_mesh_data[self.rest_pose_idx]
        template_pts = template_data['pts_norm']
        template_joints = template_data['joints']
        target_vertex_count = len(template_pts)
        
        print(f"ä½¿ç”¨å¸§{self.rest_pose_idx}çš„ {target_vertex_count} é¡¶ç‚¹ä½œä¸ºæ¨¡æ¿")
        print(f"ä»rest poseå‘å‰åä¸¤ä¸ªæ–¹å‘è¿›è¡Œæ‹“æ‰‘ç»Ÿä¸€")
        
        unified_frames = [None] * len(self.all_mesh_data)
        
        # é¦–å…ˆè®¾ç½®rest pose
        unified_frames[self.rest_pose_idx] = template_pts
        print(f"  å¸§ {self.rest_pose_idx}: Rest poseè®¾ç½®å®Œæˆ")
        
        # å‘åå¤„ç† (rest_pose_idx + 1 åˆ° end)
        print(f"å‘åå¤„ç†: å¸§ {self.rest_pose_idx+1} åˆ° {len(self.all_mesh_data)-1}")
        prev_pts = template_pts
        prev_joints = template_joints
        
        for i in range(self.rest_pose_idx + 1, len(self.all_mesh_data)):
            current_data = self.all_mesh_data[i]
            current_pts = current_data['pts_norm']
            current_joints = current_data['joints']
            
            # ä½¿ç”¨å‰ä¸€å¸§ä½œä¸ºå‚è€ƒè¿›è¡Œæ˜ å°„
            if len(current_pts) == target_vertex_count:
                correspondence_quality = self._check_correspondence_quality(
                    prev_pts, current_pts, prev_joints, current_joints
                )
                
                if correspondence_quality > 0.8:
                    unified_frames[i] = current_pts
                    print(f"  å¸§ {i}: è‰¯å¥½å¯¹åº”å…³ç³» (è´¨é‡={correspondence_quality:.3f})")
                else:
                    remapped_pts = self._bone_guided_remapping(
                        prev_pts, current_pts, prev_joints, current_joints
                    )
                    unified_frames[i] = remapped_pts
                    print(f"  å¸§ {i}: éª¨éª¼å¼•å¯¼é‡æ˜ å°„ (è´¨é‡={correspondence_quality:.3f})")
            else:
                remapped_pts = self._bone_guided_remapping(
                    prev_pts, current_pts, prev_joints, current_joints
                )
                unified_frames[i] = remapped_pts
                print(f"  å¸§ {i}: é¡¶ç‚¹æ•°æ˜ å°„ {len(current_pts)} â†’ {target_vertex_count}")
            
            # æ›´æ–°å‚è€ƒå¸§
            prev_pts = unified_frames[i]
            prev_joints = current_joints
        
        # å‘å‰å¤„ç† (rest_pose_idx - 1 åˆ° 0)
        print(f"å‘å‰å¤„ç†: å¸§ {self.rest_pose_idx-1} åˆ° 0")
        prev_pts = template_pts
        prev_joints = template_joints
        
        for i in range(self.rest_pose_idx - 1, -1, -1):
            current_data = self.all_mesh_data[i]
            current_pts = current_data['pts_norm']
            current_joints = current_data['joints']
            
            # ä½¿ç”¨åä¸€å¸§ä½œä¸ºå‚è€ƒè¿›è¡Œæ˜ å°„
            if len(current_pts) == target_vertex_count:
                correspondence_quality = self._check_correspondence_quality(
                    prev_pts, current_pts, prev_joints, current_joints
                )
                
                if correspondence_quality > 0.8:
                    unified_frames[i] = current_pts
                    print(f"  å¸§ {i}: è‰¯å¥½å¯¹åº”å…³ç³» (è´¨é‡={correspondence_quality:.3f})")
                else:
                    remapped_pts = self._bone_guided_remapping(
                        prev_pts, current_pts, prev_joints, current_joints
                    )
                    unified_frames[i] = remapped_pts
                    print(f"  å¸§ {i}: éª¨éª¼å¼•å¯¼é‡æ˜ å°„ (è´¨é‡={correspondence_quality:.3f})")
            else:
                remapped_pts = self._bone_guided_remapping(
                    prev_pts, current_pts, prev_joints, current_joints
                )
                unified_frames[i] = remapped_pts
                print(f"  å¸§ {i}: é¡¶ç‚¹æ•°æ˜ å°„ {len(current_pts)} â†’ {target_vertex_count}")
            
            # æ›´æ–°å‚è€ƒå¸§
            prev_pts = unified_frames[i]
            prev_joints = current_joints
        
        self.unified_vertices = np.stack(unified_frames, axis=0)
        print(f"âœ“ åŒå‘ç½‘æ ¼æ‹“æ‰‘ç»Ÿä¸€å®Œæˆ: {self.unified_vertices.shape}")
        print(f"  æ—¶é—´ä¸€è‡´æ€§åº”è¯¥æ›´å¥½ï¼Œå› ä¸ºç›¸é‚»å¸§ä¹‹é—´çš„æ˜ å°„æ›´ç¨³å®š")
        
        return self.unified_vertices.shape
    
    def _check_correspondence_quality(self, template_pts, current_pts, template_joints, current_joints):
        """æ£€æŸ¥é¡¶ç‚¹å¯¹åº”å…³ç³»è´¨é‡"""
        if len(template_pts) != len(current_pts):
            return 0.0
        
        # å…³èŠ‚å¯¹é½æ£€æŸ¥
        joint_distances = np.linalg.norm(template_joints - current_joints, axis=1)
        joint_alignment = np.exp(-joint_distances.mean())
        
        # ç½‘æ ¼ä¸­å¿ƒå¯¹é½æ£€æŸ¥
        template_center = template_pts.mean(axis=0)
        current_center = current_pts.mean(axis=0)
        center_distance = np.linalg.norm(template_center - current_center)
        center_alignment = np.exp(-center_distance * 5)
        
        # ç»„åˆè´¨é‡å¾—åˆ†
        quality = 0.7 * joint_alignment + 0.3 * center_alignment
        return quality
    
    def _bone_guided_remapping(self, template_pts, current_pts, template_joints, current_joints):
        """åŸºäºéª¨éª¼å¼•å¯¼çš„é¡¶ç‚¹é‡æ˜ å°„"""
        n_template = len(template_pts)
        n_current = len(current_pts)
        
        # ä¸ºå¤§å‹ç½‘æ ¼ä½¿ç”¨ç®€åŒ–é‡æ˜ å°„
        if n_template > 8000:
            print(f"    å¤§å‹ç½‘æ ¼ ({n_template} é¡¶ç‚¹), ä½¿ç”¨ç®€åŒ–é‡æ˜ å°„")
            tree = cKDTree(current_pts)
            distances, indices = tree.query(template_pts, k=1)
            return current_pts[indices]
        
        # åˆ›å»ºéª¨éª¼å½±å“åæ ‡ç³»
        template_coords = self._compute_bone_coordinates(template_pts, template_joints)
        current_coords = self._compute_bone_coordinates(current_pts, current_joints)
        
        # ä½¿ç”¨k-dæ ‘è¿›è¡Œé«˜æ•ˆæœ€è¿‘é‚»æœç´¢
        tree = cKDTree(current_coords)
        k = min(3, n_current)
        distances, indices = tree.query(template_coords, k=k)
        
        remapped_pts = np.zeros_like(template_pts)
        
        if k == 1:
            remapped_pts = current_pts[indices.flatten()]
        else:
            # åŠ æƒå¹³å‡
            safe_distances = distances + 1e-8
            weights = 1.0 / safe_distances
            weights = weights / weights.sum(axis=1, keepdims=True)
            
            for i in range(n_template):
                vertex_indices = indices[i]
                vertex_weights = weights[i]
                remapped_pts[i] = np.sum(
                    vertex_weights.reshape(-1, 1) * current_pts[vertex_indices], axis=0
                )
        
        return remapped_pts
    
    def _compute_bone_coordinates(self, vertices, joints):
        """è®¡ç®—éª¨éª¼å½±å“åæ ‡ç³» - ä¼˜åŒ–ç‰ˆæœ¬"""
        n_vertices = len(vertices)
        n_joints = len(joints)
        
        # é¢„è®¡ç®—ç½‘æ ¼å°ºåº¦
        mesh_bounds = vertices.max(axis=0) - vertices.min(axis=0)
        mesh_scale = np.linalg.norm(mesh_bounds)
        
        # å¯¹å¤§å‹ç½‘æ ¼é™åˆ¶å…³èŠ‚å½±å“ç‰¹å¾
        if n_vertices > 5000:
            # åªä½¿ç”¨å‰8ä¸ªæœ€é‡è¦çš„å…³èŠ‚
            joint_subset = joints[:min(8, n_joints)]
            bone_coords = np.zeros((n_vertices, 3 + len(joint_subset)))
        else:
            joint_subset = joints
            bone_coords = np.zeros((n_vertices, 3 + n_joints))
        
        bone_coords[:, :3] = vertices
        
        # å‘é‡åŒ–è·ç¦»è®¡ç®—
        vertices_expanded = vertices[:, np.newaxis, :]  # (N, 1, 3)
        joints_expanded = joint_subset[np.newaxis, :, :]  # (1, K, 3)
        
        distances = np.linalg.norm(vertices_expanded - joints_expanded, axis=2)
        normalized_distances = distances / (mesh_scale + 1e-8)
        influences = np.exp(-normalized_distances * 3.0)
        
        bone_coords[:, 3:] = influences
        
        return bone_coords
    
    def step4_compute_skinning(self):
        """
        æ­¥éª¤4ï¼šä½¿ç”¨ä¿®å¤åçš„DemBonesè®¡ç®—è’™çš®æƒé‡
        """
        print("\n=== æ­¥éª¤4ï¼šDemBonesè’™çš®æƒé‡è®¡ç®— ===")
        
        if self.unified_vertices is None:
            raise RuntimeError("å¿…é¡»å…ˆç»Ÿä¸€ç½‘æ ¼æ‹“æ‰‘")
        
        # è·å–éª¨éª¼çˆ¶èŠ‚ç‚¹æ•°æ®
        rest_data = self.all_mesh_data[self.rest_pose_idx]
        self.parents = sanitize_parents(rest_data['parents'])
        
        F, N, _ = self.unified_vertices.shape
        K = len(self.parents)
        
        print(f"éª¨éª¼: {K} ä¸ªå…³èŠ‚")
        print(f"åŠ¨ç”»: {F} å¸§, {N} ä¸ªé¡¶ç‚¹")
        
        # æ™ºèƒ½æ•°æ®å­é‡‡æ ·ä»¥ç¡®ä¿DemBonesèƒ½æˆåŠŸè¿è¡Œ
        processed_vertices, vertex_indices, frame_indices = self._prepare_demBones_data()
        
        F_sub, N_sub, _ = processed_vertices.shape
        print(f"DemBonesè¾“å…¥: {F_sub} å¸§, {N_sub} é¡¶ç‚¹ (å­é‡‡æ ·), {frame_indices} frame_indices")
        
        try:
            # ä½¿ç”¨ä¿®å¤åçš„DemBones API
            rest_pose_sub, weights_sub, transforms_sub = self._compute_skinning_weights_fixed(
                processed_vertices, self.parents
            )
            
            print(f"âœ“ DemBoneså­é‡‡æ ·æ•°æ®æˆåŠŸ:")
            print(f"  Rest pose: {rest_pose_sub.shape}")
            print(f"  è’™çš®æƒé‡: {weights_sub.shape}")
            print(f"  éª¨éª¼å˜æ¢: {transforms_sub.shape}")
            
            # æ‰©å±•ç»“æœåˆ°å®Œæ•´åˆ†è¾¨ç‡
            self.skinning_weights, self.bone_transforms = self._expand_demBones_results(
                weights_sub, transforms_sub, vertex_indices, frame_indices, N, F
            )
            
            print(f"âœ“ æ‰©å±•åˆ°å®Œæ•´åˆ†è¾¨ç‡:")
            print(f"  å®Œæ•´è’™çš®æƒé‡: {self.skinning_weights.shape}")
            print(f"  å®Œæ•´éª¨éª¼å˜æ¢: {self.bone_transforms.shape}")
            print(f"  æƒé‡èŒƒå›´: [{self.skinning_weights.min():.4f}, {self.skinning_weights.max():.4f}]")
                
        except Exception as e:
            print(f"âŒ DemBoneså¤±è´¥: {e}")
            raise RuntimeError(f"DemBonesè®¡ç®—å¤±è´¥: {e}")
        
        # ä¿å­˜ç»“æœ
        skinning_results = {
            'rest_pose': self.unified_vertices[self.rest_pose_idx],
            'skinning_weights': self.skinning_weights,
            'bone_transforms': self.bone_transforms,
            'parents': self.parents,
            'rest_pose_idx': self.rest_pose_idx,
            'unified_vertices': self.unified_vertices
        }
        
        results_path = os.path.join(self.output_dir, 'skinning_results.pkl')
        with open(results_path, 'wb') as f:
            pickle.dump(skinning_results, f)
        
        print(f"âœ“ è’™çš®ç»“æœå·²ä¿å­˜åˆ° {results_path}")
    
    def _prepare_demBones_data(self):
        """æ™ºèƒ½å­é‡‡æ ·æ•°æ®ä»¥ç¡®ä¿DemBonesæˆåŠŸè¿è¡Œ"""
        F, N, _ = self.unified_vertices.shape
        
        # ç›®æ ‡é™åˆ¶å€¼ - åŸºäºæ€§èƒ½æµ‹è¯•ï¼š50ä¸ªé¡¶ç‚¹å¾ˆå¿«ï¼Œ100ä¸ªé¡¶ç‚¹è¾ƒæ…¢
        MAX_VERTICES = 80  # åœ¨50-100ä¹‹é—´é€‰æ‹©ä¸€ä¸ªå®‰å…¨å€¼
        MAX_FRAMES = 10
        
        # é¡¶ç‚¹å­é‡‡æ ·
        if N > MAX_VERTICES:
            vertex_ratio = MAX_VERTICES / N
            vertex_indices = self._sample_vertices_intelligently(vertex_ratio)
            print(f"  é¡¶ç‚¹å­é‡‡æ ·: {N} â†’ {len(vertex_indices)} ({vertex_ratio:.2%})")
        else:
            vertex_indices = np.arange(N)
            print(f"  æ— éœ€é¡¶ç‚¹å­é‡‡æ ·: {N} é¡¶ç‚¹")
        
        # å¸§å­é‡‡æ ·
        if F > MAX_FRAMES:
            frame_indices = np.linspace(0, F-1, MAX_FRAMES, dtype=int)
            if self.rest_pose_idx not in frame_indices:
                frame_indices[0] = self.rest_pose_idx  # ç¡®ä¿åŒ…å«rest pose
            frame_indices = np.sort(frame_indices)
            print(f"  å¸§å­é‡‡æ ·: {F} â†’ {len(frame_indices)} å¸§")
        else:
            frame_indices = np.arange(F)
            print(f"  æ— éœ€å¸§å­é‡‡æ ·: {F} å¸§")
        
        # åˆ›å»ºå­é‡‡æ ·æ•°æ®
        processed_vertices = self.unified_vertices[frame_indices][:, vertex_indices]
        
        return processed_vertices, vertex_indices, frame_indices
    
    def _sample_vertices_intelligently(self, ratio):
        """æ™ºèƒ½é¡¶ç‚¹é‡‡æ ·ä»¥ä¿æŒç½‘æ ¼ç»“æ„ - ä¼˜åŒ–ç‰ˆæœ¬é¿å…å¡æ­»"""
        N = self.unified_vertices.shape[1]
        n_samples = int(N * ratio)
        
        print(f"    æ™ºèƒ½é‡‡æ ·: {N} â†’ {n_samples} é¡¶ç‚¹")
        
        # ä½¿ç”¨rest poseä½œä¸ºå‚è€ƒ
        rest_vertices = self.unified_vertices[self.rest_pose_idx]
        
        # å¯¹äºå¤§å‹ç½‘æ ¼ï¼Œä½¿ç”¨æ›´é«˜æ•ˆçš„é‡‡æ ·ç­–ç•¥
        if N > 20000:
            print(f"    å¤§å‹ç½‘æ ¼æ£€æµ‹ï¼Œä½¿ç”¨å¿«é€Ÿå‡åŒ€é‡‡æ ·")
            # ç®€å•å‡åŒ€é‡‡æ ·é¿å…å¤æ‚è®¡ç®—
            step = N // n_samples
            indices = np.arange(0, N, step)[:n_samples]
            return np.sort(indices)
        
        # ä¸­ç­‰å¤§å°ç½‘æ ¼ï¼šä½¿ç”¨æ”¹è¿›çš„æœ€è¿œç‚¹é‡‡æ ·
        if N > 5000:
            print(f"    ä¸­ç­‰ç½‘æ ¼ï¼Œä½¿ç”¨æ‰¹é‡æœ€è¿œç‚¹é‡‡æ ·")
            # æ‰¹é‡å¤„ç†ï¼Œæ¯æ¬¡å¤„ç†ä¸€æ‰¹å€™é€‰ç‚¹
            indices = [0]
            remaining = np.arange(1, N)
            batch_size = min(1000, len(remaining))
            
            while len(indices) < n_samples and len(remaining) > 0:
                if len(remaining) <= batch_size:
                    # å¤„ç†å‰©ä½™æ‰€æœ‰ç‚¹
                    candidates = remaining
                else:
                    # éšæœºé€‰æ‹©ä¸€æ‰¹å€™é€‰ç‚¹
                    candidates = np.random.choice(remaining, batch_size, replace=False)
                
                # åœ¨å€™é€‰ç‚¹ä¸­æ‰¾æœ€è¿œçš„
                max_dist = -1
                best_idx = None
                
                for idx in candidates:
                    min_dist = min(np.linalg.norm(rest_vertices[idx] - rest_vertices[selected]) 
                                 for selected in indices[-min(10, len(indices)):])  # åªæ¯”è¾ƒæœ€è¿‘çš„10ä¸ªç‚¹
                    if min_dist > max_dist:
                        max_dist = min_dist
                        best_idx = idx
                
                if best_idx is not None:
                    indices.append(best_idx)
                    remaining = remaining[remaining != best_idx]
                else:
                    break
            
            # å¦‚æœè¿˜ä¸å¤Ÿï¼Œéšæœºè¡¥å……
            if len(indices) < n_samples and len(remaining) > 0:
                needed = n_samples - len(indices)
                additional = np.random.choice(remaining, min(needed, len(remaining)), replace=False)
                indices.extend(additional)
            
            return np.sort(indices[:n_samples])
        
        # å°å‹ç½‘æ ¼ï¼šä½¿ç”¨å®Œæ•´æœ€è¿œç‚¹é‡‡æ ·
        else:
            print(f"    å°å‹ç½‘æ ¼ï¼Œä½¿ç”¨å®Œæ•´æœ€è¿œç‚¹é‡‡æ ·")
            indices = [0]
            remaining = set(range(1, N))
            
            for i in range(n_samples - 1):
                if not remaining:
                    break
                    
                max_dist = -1
                best_idx = None
                
                # éšæœºé‡‡æ ·ä¸€éƒ¨åˆ†å€™é€‰ç‚¹ä»¥åŠ é€Ÿ
                candidates = list(remaining)
                if len(candidates) > 500:
                    candidates = np.random.choice(candidates, 500, replace=False)
                
                for idx in candidates:
                    min_dist = min(np.linalg.norm(rest_vertices[idx] - rest_vertices[selected]) 
                                 for selected in indices[-min(5, len(indices)):])  # åªæ¯”è¾ƒæœ€è¿‘çš„5ä¸ªç‚¹
                    if min_dist > max_dist:
                        max_dist = min_dist
                        best_idx = idx
                
                if best_idx is not None:
                    indices.append(best_idx)
                    remaining.remove(best_idx)
                
                # æ¯100ä¸ªç‚¹æ˜¾ç¤ºè¿›åº¦
                if i % 100 == 0:
                    print(f"      é‡‡æ ·è¿›åº¦: {i+1}/{n_samples-1}")
            
            return np.sort(indices[:n_samples])
    
    def _compute_skinning_weights_fixed(self, frames_vertices, parents):
        """ä½¿ç”¨ä¿®å¤åçš„DemBones APIè®¡ç®—è’™çš®æƒé‡ - å¸¦è¶…æ—¶å’Œå›é€€æœºåˆ¶"""
        print("ä½¿ç”¨ä¿®å¤åçš„DemBones API...")
        
        F, N, _ = frames_vertices.shape
        K = len(parents)
        
        # æ£€æŸ¥æ•°æ®åˆç†æ€§
        if F < 2:
            print("âš ï¸ å¸§æ•°ä¸è¶³ï¼Œä½¿ç”¨ç®€åŒ–è’™çš®æƒé‡")
            return self._create_simple_skinning_weights(frames_vertices[0], K)
        
        if N > 8000:
            print("âš ï¸ é¡¶ç‚¹æ•°è¿‡å¤šï¼Œè¿›ä¸€æ­¥å­é‡‡æ ·")
            # è¿›ä¸€æ­¥å‡å°‘é¡¶ç‚¹æ•°
            subsample_ratio = 6000 / N
            subsample_indices = np.linspace(0, N-1, 6000, dtype=int)
            frames_vertices = frames_vertices[:, subsample_indices]
            N = 6000
            print(f"    è¿›ä¸€æ­¥å­é‡‡æ ·åˆ° {N} é¡¶ç‚¹")
        
        # å°è¯•å¤šç§é…ç½®çš„DemBones
        configs = [
            # é…ç½®1ï¼šæœ€ç®€å•è®¾ç½®
            {
                'nIters': 10, 'nInitIters': 2, 'nTransIters': 1, 
                'nWeightsIters': 1, 'nnz': 4, 'weightsSmooth': 1e-3,
                'timeout': 60, 'name': 'æœ€ç®€é…ç½®'
            },
            # é…ç½®2ï¼šä¸­ç­‰è®¾ç½®
            {
                'nIters': 15, 'nInitIters': 3, 'nTransIters': 2, 
                'nWeightsIters': 1, 'nnz': 6, 'weightsSmooth': 1e-4,
                'timeout': 120, 'name': 'ä¸­ç­‰é…ç½®'
            },
            # é…ç½®3ï¼šåŸå§‹è®¾ç½®ï¼ˆä½†è¶…æ—¶æ—¶é—´æ›´çŸ­ï¼‰
            {
                'nIters': 20, 'nInitIters': 5, 'nTransIters': 3, 
                'nWeightsIters': 2, 'nnz': 8, 'weightsSmooth': 1e-4,
                'timeout': 180, 'name': 'å®Œæ•´é…ç½®'
            }
        ]
        
        for i, config in enumerate(configs):
            print(f"\nå°è¯•DemBones {config['name']} (é…ç½® {i+1}/{len(configs)})")
            
            try:
                result = self._try_demBones_with_timeout(frames_vertices, parents, config)
                if result is not None:
                    print(f"âœ“ {config['name']} æˆåŠŸï¼")
                    return result
                else:
                    print(f"âŒ {config['name']} è¶…æ—¶æˆ–å¤±è´¥")
                    
            except Exception as e:
                print(f"âŒ {config['name']} å¼‚å¸¸: {e}")
                continue
        
        # æ‰€æœ‰DemBonesé…ç½®éƒ½å¤±è´¥ï¼Œä½¿ç”¨å›é€€æ–¹æ¡ˆ
        print("âš ï¸ æ‰€æœ‰DemBonesé…ç½®éƒ½å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–è’™çš®æƒé‡")
        return self._create_simple_skinning_weights(frames_vertices[0], K)
    
    def _try_demBones_with_timeout(self, frames_vertices, parents, config):
        """è¿è¡ŒDemBonesï¼Œæ— è¶…æ—¶é™åˆ¶ç‰ˆæœ¬ï¼ˆæµ‹è¯•å®é™…è¿è¡Œæ—¶é—´ï¼‰"""
        F, N, _ = frames_vertices.shape
        K = len(parents)
        
        print(f"    Rest pose: {frames_vertices[0].shape}, Animated: {frames_vertices[1:].shape}")
        print(f"    å‚æ•°: iters={config['nIters']}, nnz={config['nnz']}, æ— è¶…æ—¶é™åˆ¶")
        
        try:
            # åˆ›å»ºDemBoneså®ä¾‹

            dem_bones = pdb.DemBones()
            # è®¾ç½®å‚æ•°
            dem_bones.nIters = config['nIters']
            dem_bones.nInitIters = config['nInitIters']
            dem_bones.nTransIters = config['nTransIters']
            dem_bones.nWeightsIters = config['nWeightsIters']
            dem_bones.nnz = config['nnz']
            dem_bones.weightsSmooth = config['weightsSmooth']
            
            # å‡†å¤‡æ•°æ®
            rest_pose = frames_vertices[0]  # (N, 3)
            animated_poses = frames_vertices[1:].reshape(-1, 3)  # ((F-1)*N, 3)
            
            # è®¾ç½®DemBonesæ•°æ®
            dem_bones.nV = N
            dem_bones.nB = K
            dem_bones.nF = F - 1
            dem_bones.nS = 1
            dem_bones.fStart = np.array([0], dtype=np.int32)
            dem_bones.subjectID = np.zeros(F - 1, dtype=np.int32)
            dem_bones.u = rest_pose
            dem_bones.v = animated_poses
            
            # make DemBones print debug info
            assert np.isfinite(rest_pose).all() and np.isfinite(animated_poses).all()
            assert animated_poses.shape[0] % rest_pose.shape[0] == 0          # å¸§æ•°æ•´æ•°å€
            assert parents[0] == -1 and (parents[1:] < np.arange(1,len(parents))).all()

            print(f"    å¼€å§‹è®¡ç®—... (æ•°æ®: {N} é¡¶ç‚¹, {K} éª¨éª¼, {F-1} åŠ¨ç”»å¸§)")
            start_time = time.time()

            # è®¡ç®—ï¼ˆæ— è¶…æ—¶ï¼‰
            dem_bones.compute()
            
            # è·å–ç»“æœ
            weights = dem_bones.get_weights()  # (K, N)
            transformations = dem_bones.get_transformations()
            
            elapsed_time = time.time() - start_time
            print(f"    âœ… è®¡ç®—å®Œæˆï¼è€—æ—¶ {elapsed_time:.2f} ç§’")
            
            # å®‰å…¨æ£€æŸ¥transformations
            if transformations is not None:
                print(f"    æƒé‡çŸ©é˜µ: {weights.shape}, å˜æ¢: {len(transformations)}")
            else:
                print(f"    æƒé‡çŸ©é˜µ: {weights.shape}, å˜æ¢: None")
            
            # å¤„ç†æƒé‡
            weights = weights.T.copy()  # è½¬ç½®ä¸º(N, K)
            
            # å½’ä¸€åŒ–æƒé‡
            row_sums = weights.sum(axis=1, keepdims=True)
            row_sums[row_sums < 1e-8] = 1.0
            weights = weights / row_sums
            
            # åˆ›å»ºå˜æ¢çŸ©é˜µ
            T_all = np.zeros((F, K, 4, 4), dtype=np.float32)
            for f in range(F):
                for b in range(K):
                    T_all[f, b] = np.eye(4)
            
            return (rest_pose, weights, T_all)
            
        except Exception as e:
            print(f"    âŒ DemBoneså¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def _create_simple_skinning_weights(self, rest_pose, K):
        """åˆ›å»ºç®€åŒ–çš„è’™çš®æƒé‡ï¼ˆå½“DemBoneså¤±è´¥æ—¶çš„å›é€€æ–¹æ¡ˆï¼‰"""
        print("åˆ›å»ºç®€åŒ–è’™çš®æƒé‡...")
        N = len(rest_pose)
        
        # åˆ›å»ºåŸºäºè·ç¦»çš„è’™çš®æƒé‡
        rest_data = self.all_mesh_data[self.rest_pose_idx]
        joints = rest_data['joints']
        
        # å°†jointsä»å½’ä¸€åŒ–åæ ‡è½¬æ¢ä¸ºä¸rest_poseç›¸åŒçš„åæ ‡ç³»
        joints_scaled = joints  # å‡è®¾å·²ç»åœ¨æ­£ç¡®åæ ‡ç³»ä¸­
        
        weights = np.zeros((N, K), dtype=np.float32)
        
        # ä¸ºæ¯ä¸ªé¡¶ç‚¹è®¡ç®—åˆ°æ¯ä¸ªå…³èŠ‚çš„è·ç¦»
        for v in range(N):
            vertex = rest_pose[v]
            distances = np.array([np.linalg.norm(vertex - joints_scaled[j]) for j in range(min(K, len(joints_scaled)))])
            
            # è½¬æ¢è·ç¦»ä¸ºæƒé‡ï¼ˆè·ç¦»è¶Šè¿‘æƒé‡è¶Šå¤§ï¼‰
            inv_distances = 1.0 / (distances + 1e-3)
            
            # åªä¿ç•™æœ€è¿‘çš„å‡ ä¸ªå…³èŠ‚
            top_k = min(4, len(inv_distances))
            top_indices = np.argsort(inv_distances)[-top_k:]
            
            for idx in top_indices:
                if idx < K:
                    weights[v, idx] = inv_distances[idx]
            
            # å½’ä¸€åŒ–
            weight_sum = weights[v].sum()
            if weight_sum > 1e-8:
                weights[v] /= weight_sum
            else:
                # å¦‚æœæ‰€æœ‰æƒé‡éƒ½æ˜¯0ï¼Œç»™ç¬¬ä¸€ä¸ªå…³èŠ‚è®¾ç½®æƒé‡
                weights[v, 0] = 1.0
        
        # åˆ›å»ºå•ä½å˜æ¢çŸ©é˜µ
        F = len(self.all_mesh_data)
        T_all = np.zeros((F, K, 4, 4), dtype=np.float32)
        for f in range(F):
            for b in range(K):
                T_all[f, b] = np.eye(4)
        
        print(f"âœ“ ç®€åŒ–è’™çš®æƒé‡åˆ›å»ºå®Œæˆ: {weights.shape}")
        print(f"  æƒé‡èŒƒå›´: [{weights.min():.4f}, {weights.max():.4f}]")
        
        return rest_pose, weights, T_all
    
    def _expand_demBones_results(self, weights_sub, transforms_sub, vertex_indices, frame_indices, N_full, F_full):
        """å°†DemBonesç»“æœä»å­é‡‡æ ·æ•°æ®æ‰©å±•åˆ°å®Œæ•´åˆ†è¾¨ç‡"""
        K = len(self.parents)
        
        # æ‰©å±•è’™çš®æƒé‡
        full_weights = np.zeros((N_full, K), dtype=np.float32)
        
        # ç›´æ¥åˆ†é…å­é‡‡æ ·æƒé‡
        full_weights[vertex_indices] = weights_sub
        
        # å¯¹æœªé‡‡æ ·é¡¶ç‚¹è¿›è¡Œæ’å€¼
        rest_vertices_full = self.unified_vertices[self.rest_pose_idx]
        rest_vertices_sub = rest_vertices_full[vertex_indices]
        
        tree = cKDTree(rest_vertices_sub)
        unsampled_indices = np.setdiff1d(np.arange(N_full), vertex_indices)
        
        if len(unsampled_indices) > 0:
            distances, nearest_idx = tree.query(rest_vertices_full[unsampled_indices], k=3)
            
            for i, orig_idx in enumerate(unsampled_indices):
                dists = distances[i]
                neighs = nearest_idx[i]
                
                weights_dists = 1.0 / (dists + 1e-8)
                weights_dists /= weights_dists.sum()
                
                for j in range(len(neighs)):
                    full_weights[orig_idx] += weights_dists[j] * weights_sub[neighs[j]]
        
        # æ‰©å±•éª¨éª¼å˜æ¢ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        full_transforms = np.zeros((F_full, K, 4, 4), dtype=np.float32)
        for f in range(F_full):
            for b in range(K):
                full_transforms[f, b] = np.eye(4)
        
        return full_weights, full_transforms
    
    def step5_generate_interpolation(self, start_frame_idx, end_frame_idx, num_interp):
        """
        æ­¥éª¤5ï¼šåœ¨ä»»æ„ä¸¤å¸§ä¹‹é—´ç”ŸæˆæŒ‡å®šæ•°é‡çš„æ’å€¼
        """
        print(f"\n=== æ­¥éª¤5ï¼šç”Ÿæˆæ’å€¼ (å¸§{start_frame_idx} â†’ å¸§{end_frame_idx}, {num_interp}ä¸ªæ’å€¼) ===")
        
        if self.bone_transforms is None:
            raise RuntimeError("å¿…é¡»å…ˆè®¡ç®—è’™çš®æƒé‡")
        
        if start_frame_idx >= len(self.all_mesh_data) or end_frame_idx >= len(self.all_mesh_data):
            raise ValueError(f"å¸§ç´¢å¼•è¶…å‡ºèŒƒå›´ (æœ€å¤§: {len(self.all_mesh_data)-1})")
        
        # è·å–èµ·å§‹å’Œç»“æŸå¸§çš„éª¨éª¼å˜æ¢
        T_from = self.bone_transforms[start_frame_idx]  # (K, 4, 4)
        T_to = self.bone_transforms[end_frame_idx]      # (K, 4, 4)
        
        # åˆ›å»ºæ’å€¼æƒé‡
        alphas = np.linspace(0, 1, num_interp + 2)[1:-1]  # æ’é™¤ç«¯ç‚¹
        
        interpolated_meshes = []
        rest_data = self.all_mesh_data[self.rest_pose_idx]
        
        for i, alpha in enumerate(alphas):
            print(f"  ç”Ÿæˆæ’å€¼å¸§ {i+1}/{num_interp} (alpha={alpha:.3f})")
            
            # æ’å€¼éª¨éª¼å˜æ¢
            T_interp = self._interpolate_bone_transforms(T_from, T_to, alpha)
            
            # åº”ç”¨çº¿æ€§æ··åˆè’™çš®
            vertices_interp = self._apply_linear_blend_skinning(
                self.unified_vertices[self.rest_pose_idx],  # Rest poseé¡¶ç‚¹
                T_interp
            )
            
            # è½¬æ¢å›ä¸–ç•Œåæ ‡
            vertices_world = (vertices_interp + 1) * 0.5 * rest_data['blen'] + rest_data['bmin']
            
            # åˆ›å»ºç½‘æ ¼
            mesh_interp = o3d.geometry.TriangleMesh(
                vertices=o3d.utility.Vector3dVector(vertices_world),
                triangles=o3d.utility.Vector3iVector(rest_data['mesh_triangles'])
            )
            mesh_interp.compute_vertex_normals()
            
            # ä¿å­˜ç½‘æ ¼
            output_path = os.path.join(self.output_dir, f'interpolated_{start_frame_idx:03d}_{end_frame_idx:03d}_{i:03d}.obj')
            o3d.io.write_triangle_mesh(output_path, mesh_interp)
            
            interpolated_meshes.append(vertices_world)
        
        print(f"âœ“ ç”Ÿæˆäº† {len(interpolated_meshes)} ä¸ªæ’å€¼å¸§")
        print(f"âœ“ ä¿å­˜åˆ°: {self.output_dir}/interpolated_{start_frame_idx:03d}_{end_frame_idx:03d}_*.obj")
        
        return interpolated_meshes
    
    def _interpolate_bone_transforms(self, T_from, T_to, alpha):
        """ä½¿ç”¨SLERPæ’å€¼éª¨éª¼å˜æ¢"""
        T_interp = np.zeros_like(T_from)
        
        for k in range(len(T_from)):
            # æå–æ—‹è½¬å’Œå¹³ç§»
            R_from = T_from[k, :3, :3]
            R_to = T_to[k, :3, :3]
            t_from = T_from[k, :3, 3]
            t_to = T_to[k, :3, 3]
            
            # æ—‹è½¬çš„SLERPæ’å€¼
            try:
                rot_from = Rotation.from_matrix(R_from)
                rot_to = Rotation.from_matrix(R_to)
                slerp = Slerp([0, 1], Rotation.concatenate([rot_from, rot_to]))
                R_interp = slerp([alpha]).as_matrix()[0]
            except:
                # å›é€€åˆ°çº¿æ€§æ’å€¼
                R_interp = (1 - alpha) * R_from + alpha * R_to
            
            # å¹³ç§»çš„çº¿æ€§æ’å€¼
            t_interp = (1 - alpha) * t_from + alpha * t_to
            
            # é‡æ„å˜æ¢çŸ©é˜µ
            T_interp[k, :3, :3] = R_interp
            T_interp[k, :3, 3] = t_interp
            T_interp[k, 3, 3] = 1.0
        
        return T_interp
    
    def _apply_linear_blend_skinning(self, rest_vertices, bone_transforms):
        """åº”ç”¨çº¿æ€§æ··åˆè’™çš®å˜å½¢rest poseé¡¶ç‚¹"""
        N = len(rest_vertices)
        K = len(bone_transforms)
        
        # è½¬æ¢ä¸ºé½æ¬¡åæ ‡
        rest_h = np.hstack([rest_vertices, np.ones((N, 1))])
        
        # åº”ç”¨è’™çš®
        deformed_vertices = np.zeros((N, 3))
        
        for v in range(N):
            blended_transform = np.zeros((4, 4))
            
            for k in range(K):
                weight = self.skinning_weights[v, k]
                if weight > 1e-6:
                    blended_transform += weight * bone_transforms[k]
            
            # åº”ç”¨æ··åˆå˜æ¢
            deformed_h = blended_transform @ rest_h[v]
            deformed_vertices[v] = deformed_h[:3]
        
        return deformed_vertices


def main():
    parser = argparse.ArgumentParser(description="å®Œæ•´çš„ä½“ç§¯è§†é¢‘æ’å€¼ç®¡é“")
    parser.add_argument('folder_path', type=str, help='åŒ…å«.objæ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„')
    parser.add_argument('--start_frame', type=int, default=0, help='å¤„ç†èµ·å§‹å¸§ç´¢å¼•')
    parser.add_argument('--end_frame', type=int, default=None, help='å¤„ç†ç»“æŸå¸§ç´¢å¼•')
    parser.add_argument('--interp_from', type=int, default=None, help='æ’å€¼èµ·å§‹å¸§ç´¢å¼•')
    parser.add_argument('--interp_to', type=int, default=None, help='æ’å€¼ç»“æŸå¸§ç´¢å¼•')
    parser.add_argument('--num_interp', type=int, default=5, help='æ’å€¼å¸§æ•°')
    parser.add_argument('--output_dir', type=str, default=None, help='è¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.folder_path):
        print(f"âŒ é”™è¯¯: æ–‡ä»¶å¤¹ {args.folder_path} ä¸å­˜åœ¨")
        return
    
    # åˆå§‹åŒ–ç®¡é“
    pipeline = CompleteVVPipeline(args.folder_path, args.output_dir)
    
    try:
        # æ­¥éª¤1ï¼šå¤„ç†å¸§æ•°æ®
        pipeline.step1_process_frames(args.start_frame, args.end_frame)
        
        # æ­¥éª¤2ï¼šæ£€æµ‹rest pose
        pipeline.step2_detect_rest_pose()
        
        # æ­¥éª¤3ï¼šç»Ÿä¸€ç½‘æ ¼æ‹“æ‰‘
        pipeline.step3_unify_mesh_topology()
        
        # æ­¥éª¤4ï¼šè®¡ç®—è’™çš®æƒé‡
        pipeline.step4_compute_skinning()
        
        # æ­¥éª¤5ï¼šç”Ÿæˆæ’å€¼
        if args.interp_from is not None and args.interp_to is not None:
            pipeline.step5_generate_interpolation(args.start_frame, args.end_frame, args.num_interp)
        else:
            # é»˜è®¤åœ¨å‰ä¸¤å¸§ä¹‹é—´æ’å€¼
            pipeline.step5_generate_interpolation(0, min(1, len(pipeline.all_mesh_data)-1), args.num_interp)
        
        print("\nğŸ‰ å®Œæ•´ç®¡é“æ‰§è¡ŒæˆåŠŸï¼")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {pipeline.output_dir}")
        
    except Exception as e:
        print(f"\nâŒ ç®¡é“æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
