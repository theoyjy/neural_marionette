#!/usr/bin/env python3
"""
å®Œæ•´çš„ä½“ç§¯è§†é¢‘æ’å€¼ç®¡é“ - æœ€ç»ˆç‰ˆæœ¬
=================================

åŠŸèƒ½ï¼š
1. åŠ è½½æ–‡ä»¶å¤¹ä¸­çš„.objæ–‡ä»¶ï¼Œæ¯å¸§é€šè¿‡voxelåŒ–åäº¤ç»™NeuralMarionetteé¢„æµ‹skeleton
2. è‡ªåŠ¨æ£€æµ‹æœ€ä½³rest poseï¼ŒåŸºäºskeletonè¿›è¡Œç½‘æ ¼æ‹“æ‰‘ç»Ÿä¸€
3. ä½¿ç”¨ C++ CLI ç‰ˆæœ¬çš„ DemBones è¿›è¡Œè’™çš®æƒé‡é¢„æµ‹
4. ç”Ÿæˆä»»æ„ä¸¤å¸§ä¹‹é—´çš„æŒ‡å®šæ•°é‡æ’å€¼

ä½¿ç”¨æ–¹æ³•ï¼š
python complete_vv_pipeline.py <folder_path> --start_frame 0 --end_frame 10 --num_interp 5

å‰ç½®è¦æ±‚ï¼š
- éœ€è¦ DemBones C++ å¯æ‰§è¡Œæ–‡ä»¶åœ¨ PATH ä¸­æˆ–å½“å‰ç›®å½•
- å¯ä» https://github.com/electronicarts/dem-bones ä¸‹è½½æºç ç¼–è¯‘
"""

import argparse
import os
import glob
import time
import pickle
import numpy as np
import torch
import open3d as o3d
import threading
import queue
from copy import deepcopy
from scipy.spatial.transform import Rotation, Slerp
from scipy.spatial import cKDTree

# å¯¼å…¥å¿…è¦çš„æ¨¡å—
from model.neural_marionette import NeuralMarionette
from utils.dataset_utils import voxelize
import subprocess
import tempfile

# å¯¼å…¥GenerateSkelçš„å‡½æ•°
from GenerateSkel import (
    process_single_mesh,
    sanitize_parents,
    draw_skeleton,
    _as_colmajor,
    _as_rowmajor
)

class CompleteVVPipeline:
    """å®Œæ•´çš„ä½“ç§¯è§†é¢‘æ’å€¼ç®¡é“"""
    
    def __init__(self, folder_path, output_dir=None):
        self.folder_path = folder_path
        self.output_dir = output_dir or os.path.join(folder_path, 'vv_complete_output')
        os.makedirs(self.output_dir, exist_ok=True)
        
        # åŠ è½½NeuralMarionette
        self._load_neural_marionette()
        
        # ç®¡é“æ•°æ®
        self.all_mesh_data = []
        self.rest_pose_idx = None
        self.unified_vertices = None
        self.skinning_weights = None
        self.bone_transforms = None
        self.parents = None


    def points_to_voxel(self, pts_norm, grid_size):
        occ = voxelize(pts_norm, (grid_size, grid_size, grid_size), is_binarized=True)  # (1,D,H,W) bool
        occ = torch.from_numpy(occ).float() # (1, 64, 64, 64) float32
        return occ

    def read_mesh_verts(self, path: str):
        mesh = o3d.io.read_triangle_mesh(path)
        if not mesh.has_vertices():
            raise ValueError(f"Failed to load mesh from {path}")
        return np.asarray(mesh.vertices, np.float32)

    def load_voxel_from_mesh(self, file, opt, is_bind=False,
                         scale=1.0, x_trans=0.0, z_trans=0.0):
        """
        Read mesh, normalize and voxelize for network input.
        Returns: vox (N=1, C=4, D, H, W), raw points, mesh, bmin, blen
        """
        mesh = o3d.io.read_triangle_mesh(file, True)
        points = np.asarray(mesh.vertices)

        if is_bind:
            points = np.stack([points[:, 0], -points[:, 2], points[:, 1]], axis=-1)

        # ---------- å½’ä¸€åŒ– ----------
        bmin = points.min(axis=0)
        bmax = points.max(axis=0)
        blen = (bmax - bmin).max()

        pts_norm = ((points - bmin) * scale / (blen + 1e-5)) * 2 - 1 \
                + np.array([x_trans, 0, z_trans])
        
        # ---------- ä½“ç´ åŒ– ----------
        vox = self.points_to_voxel(pts_norm, self.opt.grid_size, is_binarized=True)

        return vox, points, mesh, bmin, blen

        
    def _load_neural_marionette(self):
        """åŠ è½½é¢„è®­ç»ƒçš„NeuralMarionetteç½‘ç»œ"""
        exp_dir = 'pretrained/aist'
        opt_path = os.path.join(exp_dir, 'opt.pickle')
        with open(opt_path, 'rb') as f:
            self.opt = pickle.load(f)
        self.opt.Ttot = 1

        ckpt_path = os.path.join(exp_dir, 'aist_pretrained.pth')
        checkpoint = torch.load(ckpt_path)
        self.network = NeuralMarionette(self.opt).cuda()
        self.network.load_state_dict(checkpoint)
        self.network.eval()
        self.network.anneal(1)
        
        print("âœ“ NeuralMarionette loaded successfully")
    
    def step1_process_frames(self, start_frame=0, end_frame=None):
        """
        æ­¥éª¤1ï¼šå¤šå¸§ä¸€èµ·å¤„ç†ï¼Œæå–ä¸€è‡´çš„skeletonæ•°æ®
        å‚è€ƒNeural Marionetteçš„å¤šå¸§å¤„ç†é€»è¾‘
        """
        print(f"\n=== æ­¥éª¤1ï¼šå¤šå¸§è”åˆå¤„ç† ({start_frame} åˆ° {end_frame}) ===")
        
        obj_files = sorted(glob.glob(os.path.join(self.folder_path, "*.obj")))
        if not obj_files:
            raise ValueError(f"åœ¨ {self.folder_path} ä¸­æœªæ‰¾åˆ°.objæ–‡ä»¶")
        
        # ç¡®å®šå¤„ç†èŒƒå›´
        assert 0 <= start_frame < len(obj_files)
        assert 0 <= end_frame < len(obj_files)

        self.all_mesh_data = []

        selected_files = obj_files[start_frame:end_frame+1]
        print(f"å¤„ç† {len(selected_files)} ä¸ªæ–‡ä»¶")
        
        # ç¬¬ä¸€æ­¥ï¼šåŠ è½½æ‰€æœ‰å¸§çš„voxelæ•°æ®
        all_pts = []
        all_voxels = []
        

        for i, obj_file in enumerate(selected_files):
            print(f"åŠ è½½ {i+1}/{len(selected_files)}: {os.path.basename(obj_file)}")

            # mesh_info_path = os.path.join(mesh_info_folder, f"mesh_info_{i:03d}.pkl")
            # if os.path.exists(mesh_info_path):
            #     print(f"  âœ“ å·²å­˜åœ¨meshä¿¡æ¯: {mesh_info_path}")
            #     with open(mesh_info_path, 'rb') as f:
            #         mesh_info = pickle.load(f)
            #     all_pts.append(mesh_info['pts_raw'])
            #     # print(f"  voxå½¢çŠ¶: {tuple(vox.shape)}")
            #     # all_voxels.append(vox[0])
            #     continue

            try:
                # åŠ è½½å¹¶ä½“ç´ åŒ–mesh
                mesh = self.read_mesh_verts(obj_file)  # ç¡®ä¿meshåŠ è½½æˆåŠŸ
                pts_raw = np.asarray(mesh.vertices)
                all_pts.append(pts_raw)
                # all_voxels.append(vox[0])

                # with open(mesh_info_path, 'wb') as f:
                #     pickle.dump(mesh_info, f)
                # print(f"  âœ“ æˆåŠŸåŠ è½½å¹¶ä¿å­˜meshä¿¡æ¯: {mesh_info_path}")
                
            except Exception as e:
                print(f"  âŒ åŠ è½½ {obj_file} å¤±è´¥: {e}")
                continue
        
        all_pts = np.vstack(all_pts)  # (N,3) all vertices from all meshes
        print(f"shape: {all_pts.shape}")

        bmin = all_pts.min(axis=0)  # (3,) min corner
        blen = (all_pts.max(0) - bmin).max()

        for i, obj_file in enumerate(selected_files):
            print(f"å¤„ç† {i+1}/{len(selected_files)}: {os.path.basename(obj_file)}")
            pts_norm = (all_pts[i] - bmin) / (blen + 1e-5) * 2 - 1 + np.array([0, 0, 0])
            vox = self.points_to_voxel(pts_norm, self.opt.grid_size, is_binarized=True)
            all_voxels.append(vox)

        # ç¬¬äºŒæ­¥ï¼šå¤šå¸§è”åˆå¤„ç†è·å¾—éª¨éª¼
        print(f"\nå¤šå¸§è”åˆéª¨éª¼æ£€æµ‹...")
        device = next(self.network.parameters()).device
        print(f"ä½¿ç”¨è®¾å¤‡: {device}")
        
        # å°†æ‰€æœ‰voxelå †å æˆåºåˆ—
        print(f"å †å æ‰€æœ‰voxelå¸§...")
        voxel_seq = torch.stack(all_voxels, dim=0).to(device) 
        voxel_seq = voxel_seq.unsqueeze(0)  # (1, N, 1, 64, 64, 64)

        frame_data_folder = os.path.join(self.output_dir, 'frame_data')
        os.makedirs(frame_data_folder, exist_ok=True)

        # clear memory
        all_pts.clear()
        all_voxels.clear()

        with torch.no_grad():
            # ä½¿ç”¨æ‰€æœ‰å¸§è¿›è¡Œéª¨éª¼æ£€æµ‹ï¼Œä¿è¯æ—¶é—´ä¸€è‡´æ€§
            detector_log = self.network.kypt_detector(voxel_seq)  # (1, T, D, H, W)
            keypoints = detector_log['keypoints']    # (1, T, K, 4)
            first_feature = detector_log['first_feature']  # (1, C, G, G, G)
            
            B, T, K, _ = keypoints.shape
            print(f"æ£€æµ‹åˆ°å…³é”®ç‚¹: Batch={B}, Time={T}, Joints={K}")
            
            # è·å–çˆ¶èŠ‚ç‚¹å…³ç³»
            parents = self.network.dyna_module.parents.cpu().numpy()
            
            # å¯¹æ¯ä¸€å¸§è¿›è¡Œè§£ç ä»¥è·å¾—è¯¦ç»†çš„éª¨éª¼ä¿¡æ¯
            for t in range(T):
                frame_data_path = os.path.join(frame_data_folder, f"frame_{t:03d}.pkl")

                if os.path.exists(frame_data_path):
                    print(f"  âœ“ å·²å­˜åœ¨å¸§æ•°æ®: {frame_data_path}")
                    with open(frame_data_path, 'rb') as f:
                        frame_data = pickle.load(f)
                        self.all_mesh_data.append(frame_data)
                    continue


                # æ„é€ å½“å‰å¸§çš„keypoints
                selected = torch.zeros(B, 2, K, 4, device=device, dtype=keypoints.dtype)
                selected[:, 0] = keypoints[:, t]     # å½“å‰å¸§
                selected[:, 1] = keypoints[:, min(t+1, T-1)]  # ä¸‹ä¸€å¸§æˆ–æœ€åä¸€å¸§
                selected[:, :, :, 3] = keypoints[:, t, :, 3].unsqueeze(1)  # ä¿æŒç½®ä¿¡åº¦
                
                first_frame = voxel_seq[t:t+1].unsqueeze(0)  # (1, 1, D, H, W)
                
                # è§£ç è·å¾—æ›´è¯¦ç»†çš„éª¨éª¼ä¿¡æ¯
                decode_log = self.network.kypt_detector.decode_from_dyna(selected, first_feature, first_frame)
                
                # æå–å½“å‰å¸§çš„éª¨éª¼ä¿¡æ¯
                frame_kps = keypoints[0, t].cpu().numpy()  # (K, 4)
                joints = frame_kps[:, :3]  # (K, 3) joint positions
                
                # è·å–æ—‹è½¬ä¿¡æ¯
                affinity = detector_log['affinity'] if 'affinity' in detector_log else None
                if affinity is not None:
                    R = decode_log['R'][0, 0].cpu().numpy()  # (K, 3, 3)
                else:
                    # å¦‚æœæ²¡æœ‰affinityï¼Œä½¿ç”¨å•ä½æ—‹è½¬çŸ©é˜µ
                    R = np.tile(np.eye(3), (K, 1, 1))
                
                # å½’ä¸€åŒ–é¡¶ç‚¹åæ ‡
                mesh_info = all_mesh_info[t]
                pts_norm = ((mesh_info['pts_raw'] - mesh_info['bmin']) / 
                           (mesh_info['blen'] + 1e-5)) * 2 - 1
                
                # ä¿å­˜å¸§æ•°æ®
                frame_data = {
                    'base_name': mesh_info['base_name'],
                    'parents': parents,
                    'kps': frame_kps,
                    'joints': joints,
                    'R': R,
                    'bmin': mesh_info['bmin'],
                    'blen': mesh_info['blen'],
                    'pts_raw': mesh_info['pts_raw'],
                    'pts_norm': pts_norm,
                    'mesh_vertices': mesh_info['mesh_vertices'],
                    'mesh_triangles': mesh_info['mesh_triangles'],
                }
                
                with open(frame_data_path, 'wb') as f:
                    pickle.dump(frame_data, f)
                    frame_visualization = draw_skeleton(joints, parents)
                    o3d.visualization.draw_geometries([frame_visualization])
                    print(f"  âœ“ ä¿å­˜å¸§æ•°æ®: {frame_data_path}")

                self.all_mesh_data.append(frame_data)
                
                if t < 3:  # åªæ˜¾ç¤ºå‰3ä¸ªçš„è¯¦ç»†ä¿¡æ¯
                    joints_world = (joints + 1) * 0.5 * mesh_info['blen'] + mesh_info['bmin']
                    print(f"  âœ“ å¸§{t}: {len(mesh_info['pts_raw'])} é¡¶ç‚¹, {K} å…³èŠ‚")
        
        if not self.all_mesh_data:
            raise RuntimeError("æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•mesh")
        
        print(f"âœ“ å¤šå¸§è”åˆå¤„ç†å®Œæˆ: {len(self.all_mesh_data)} å¸§")
        print(f"âœ“ éª¨éª¼ç»“æ„ä¸€è‡´æ€§: {K} ä¸ªå…³èŠ‚ï¼Œç›¸åŒçš„çˆ¶èŠ‚ç‚¹å…³ç³»")
        return len(self.all_mesh_data)
    
    def step2_detect_rest_pose(self):
        """
        æ­¥éª¤2ï¼šè‡ªåŠ¨æ£€æµ‹æœ€ä½³rest pose
        åŸºäºç½‘æ ¼å’Œéª¨éª¼çš„å‡ ä½•ç‰¹æ€§ï¼Œä¸ä¾èµ–è¯­ä¹‰å…³èŠ‚
        """
        print("\n=== æ­¥éª¤2ï¼šæ£€æµ‹æœ€ä½³Rest Pose (åŸºäºå‡ ä½•ç‰¹æ€§) ===")
        
        scores = []
        
        for i, data in enumerate(self.all_mesh_data):
            joints = data['joints']  # å½’ä¸€åŒ–åæ ‡
            mesh_vertices = data['pts_norm']
            parents = sanitize_parents(data['parents'])
            R_rotations = data['R']  # æ—‹è½¬çŸ©é˜µ
            
            # æŒ‡æ ‡1ï¼šéª¨éª¼ç»“æ„ç¨³å®šæ€§ï¼ˆéª¨é•¿å˜åŒ–å°ï¼‰
            bone_lengths = []
            for j in range(len(joints)):
                if parents[j] >= 0:
                    bone_length = np.linalg.norm(joints[j] - joints[parents[j]])
                    bone_lengths.append(bone_length)
            
            if bone_lengths:
                bone_length_std = np.std(bone_lengths)
                bone_length_mean = np.mean(bone_lengths)
                bone_stability = 1.0 / (bone_length_std / (bone_length_mean + 1e-6) + 0.01)  # å˜å¼‚ç³»æ•°å€’æ•°
            else:
                bone_stability = 0
            
            # æŒ‡æ ‡2ï¼šå…³èŠ‚åˆ†å¸ƒå‡åŒ€æ€§ï¼ˆå…³èŠ‚åœ¨ç©ºé—´ä¸­åˆ†å¸ƒå‡åŒ€ï¼‰
            if len(joints) > 1:
                joint_center = joints.mean(axis=0)
                joint_distances = np.linalg.norm(joints - joint_center, axis=1)
                joint_spread = np.std(joint_distances)  # åˆ†å¸ƒæ ‡å‡†å·®
                joint_coverage = np.ptp(joints, axis=0).mean()  # è¦†ç›–èŒƒå›´
                distribution_score = joint_spread * joint_coverage  # æ—¢è¦åˆ†æ•£åˆè¦è¦†ç›–èŒƒå›´å¤§
            else:
                distribution_score = 0
            
            # æŒ‡æ ‡3ï¼šæ—‹è½¬çŸ©é˜µæ¥è¿‘å•ä½çŸ©é˜µï¼ˆminimal rotationï¼‰
            rotation_deviations = []
            for R in R_rotations:
                deviation = np.linalg.norm(R - np.eye(3), 'fro')  # FrobeniusèŒƒæ•°
                rotation_deviations.append(deviation)
            
            avg_rotation_deviation = np.mean(rotation_deviations)
            rotation_minimality = 1.0 / (avg_rotation_deviation + 0.1)  # åå·®è¶Šå°è¶Šå¥½
            
            # æŒ‡æ ‡4ï¼šç½‘æ ¼ç´§å‡‘æ€§å’Œä¸­å¿ƒæ€§
            mesh_center = mesh_vertices.mean(axis=0)
            mesh_bounds = mesh_vertices.max(axis=0) - mesh_vertices.min(axis=0)
            mesh_compactness = 1.0 / (np.prod(mesh_bounds) + 1e-6)  # ä½“ç§¯è¶Šå°è¶Šç´§å‡‘
            
            # å…³èŠ‚-ç½‘æ ¼ä¸­å¿ƒå¯¹é½
            if len(joints) > 0:
                joint_center = joints.mean(axis=0)
                center_alignment = 1.0 / (np.linalg.norm(joint_center - mesh_center) + 0.1)
            else:
                center_alignment = 0
            
            # æŒ‡æ ‡5ï¼šéª¨éª¼å±‚æ¬¡ç»“æ„è´¨é‡
            # æ£€æŸ¥parentå…³ç³»çš„åˆç†æ€§
            hierarchy_score = 0
            for j in range(len(joints)):
                if parents[j] >= 0:
                    parent_pos = joints[parents[j]]
                    child_pos = joints[j]
                    # å¥½çš„å±‚æ¬¡ç»“æ„ä¸­ï¼Œå­å…³èŠ‚ä¸åº”è¯¥ç¦»æ ¹éƒ¨å¤ªè¿œ
                    distance_to_parent = np.linalg.norm(child_pos - parent_pos)
                    hierarchy_score += 1.0 / (distance_to_parent + 0.1)
            
            hierarchy_score = hierarchy_score / max(1, len(joints))
            
            # ç»„åˆåŠ æƒå¾—åˆ† - æ›´æ³¨é‡å‡ ä½•ç‰¹æ€§è€Œä¸æ˜¯è¯­ä¹‰
            score = (
                3.0 * bone_stability +          # éª¨éª¼ç¨³å®šæ€§æœ€é‡è¦
                2.0 * rotation_minimality +     # æœ€å°æ—‹è½¬å¾ˆé‡è¦
                1.5 * distribution_score +      # å…³èŠ‚åˆ†å¸ƒ
                1.0 * center_alignment +        # ä¸­å¿ƒå¯¹é½
                1.0 * hierarchy_score +         # å±‚æ¬¡ç»“æ„
                0.5 * mesh_compactness          # ç½‘æ ¼ç´§å‡‘æ€§
            )
            
            scores.append(score)
            print(f"  å¸§ {i:2d}: éª¨é•¿ç¨³å®š={bone_stability:.3f}, æ—‹è½¬æœ€å°={rotation_minimality:.3f}, "
                  f"å…³èŠ‚åˆ†å¸ƒ={distribution_score:.3f}, ä¸­å¿ƒå¯¹é½={center_alignment:.3f}, "
                  f"å±‚æ¬¡={hierarchy_score:.3f}, æ€»åˆ†={score:.3f}")
        
        # é€‰æ‹©å¾—åˆ†æœ€é«˜çš„å¸§
        self.rest_pose_idx = np.argmax(scores)
        rest_data = self.all_mesh_data[self.rest_pose_idx]
        
        print(f"âœ“ åŸºäºå‡ ä½•ç‰¹æ€§é€‰æ‹©å¸§ {self.rest_pose_idx} ä½œä¸ºrest pose: {rest_data['base_name']}")
        print(f"  å«æœ‰ {len(rest_data['pts_raw'])} é¡¶ç‚¹, {len(rest_data['joints'])} å…³èŠ‚")
        print(f"  å‡ ä½•å¾—åˆ†: {scores[self.rest_pose_idx]:.3f}")
        
        return self.rest_pose_idx
    
    def step3_unify_mesh_topology(self):
        """
        æ­¥éª¤3ï¼šåŸºäºéª¨éª¼ç»“æ„çš„ç½‘æ ¼æ‹“æ‰‘ç»Ÿä¸€
        ä»rest poseå¼€å§‹å‘ä¸¤è¾¹è¿›è¡Œremapï¼Œä¿è¯æ›´å¥½çš„æ—¶é—´ä¸€è‡´æ€§
        """
        print("\n=== æ­¥éª¤3ï¼šåŸºäºéª¨éª¼çš„ç½‘æ ¼æ‹“æ‰‘ç»Ÿä¸€ (ä»rest poseå‘ä¸¤è¾¹) ===")
        
        if self.rest_pose_idx is None:
            raise RuntimeError("å¿…é¡»å…ˆæ£€æµ‹rest pose")
        
        template_data = self.all_mesh_data[self.rest_pose_idx]
        template_pts = template_data['pts_norm']
        template_joints = template_data['joints']
        target_vertex_count = len(template_pts)
        
        print(f"ä½¿ç”¨å¸§{self.rest_pose_idx}çš„ {target_vertex_count} é¡¶ç‚¹ä½œä¸ºæ¨¡æ¿")
        print(f"ä»rest poseå‘å‰åä¸¤ä¸ªæ–¹å‘è¿›è¡Œæ‹“æ‰‘ç»Ÿä¸€")
        
        unified_frames = [None] * len(self.all_mesh_data)
        
        # é¦–å…ˆè®¾ç½®rest pose
        unified_frames[self.rest_pose_idx] = template_pts
        print(f"  å¸§ {self.rest_pose_idx}: Rest poseè®¾ç½®å®Œæˆ")
        
        # å‘åå¤„ç† (rest_pose_idx + 1 åˆ° end)
        print(f"å‘åå¤„ç†: å¸§ {self.rest_pose_idx+1} åˆ° {len(self.all_mesh_data)-1}")
        prev_pts = template_pts
        prev_joints = template_joints
        
        for i in range(self.rest_pose_idx + 1, len(self.all_mesh_data)):
            current_data = self.all_mesh_data[i]
            current_pts = current_data['pts_norm']
            current_joints = current_data['joints']
            
            # ä½¿ç”¨å‰ä¸€å¸§ä½œä¸ºå‚è€ƒè¿›è¡Œæ˜ å°„
            if len(current_pts) == target_vertex_count:
                correspondence_quality = self._check_correspondence_quality(
                    prev_pts, current_pts, prev_joints, current_joints
                )
                
                if correspondence_quality > 0.8:
                    unified_frames[i] = current_pts
                    print(f"  å¸§ {i}: è‰¯å¥½å¯¹åº”å…³ç³» (è´¨é‡={correspondence_quality:.3f})")
                else:
                    remapped_pts = self._bone_guided_remapping(
                        prev_pts, current_pts, prev_joints, current_joints
                    )
                    unified_frames[i] = remapped_pts
                    print(f"  å¸§ {i}: éª¨éª¼å¼•å¯¼é‡æ˜ å°„ (è´¨é‡={correspondence_quality:.3f})")
            else:
                remapped_pts = self._bone_guided_remapping(
                    prev_pts, current_pts, prev_joints, current_joints
                )
                unified_frames[i] = remapped_pts
                print(f"  å¸§ {i}: é¡¶ç‚¹æ•°æ˜ å°„ {len(current_pts)} â†’ {target_vertex_count}")
            
            # æ›´æ–°å‚è€ƒå¸§
            prev_pts = unified_frames[i]
            prev_joints = current_joints
        
        # å‘å‰å¤„ç† (rest_pose_idx - 1 åˆ° 0)
        print(f"å‘å‰å¤„ç†: å¸§ {self.rest_pose_idx-1} åˆ° 0")
        prev_pts = template_pts
        prev_joints = template_joints
        
        for i in range(self.rest_pose_idx - 1, -1, -1):
            current_data = self.all_mesh_data[i]
            current_pts = current_data['pts_norm']
            current_joints = current_data['joints']
            
            # ä½¿ç”¨åä¸€å¸§ä½œä¸ºå‚è€ƒè¿›è¡Œæ˜ å°„
            if len(current_pts) == target_vertex_count:
                correspondence_quality = self._check_correspondence_quality(
                    prev_pts, current_pts, prev_joints, current_joints
                )
                
                if correspondence_quality > 0.8:
                    unified_frames[i] = current_pts
                    print(f"  å¸§ {i}: è‰¯å¥½å¯¹åº”å…³ç³» (è´¨é‡={correspondence_quality:.3f})")
                else:
                    remapped_pts = self._bone_guided_remapping(
                        prev_pts, current_pts, prev_joints, current_joints
                    )
                    unified_frames[i] = remapped_pts
                    print(f"  å¸§ {i}: éª¨éª¼å¼•å¯¼é‡æ˜ å°„ (è´¨é‡={correspondence_quality:.3f})")
            else:
                remapped_pts = self._bone_guided_remapping(
                    prev_pts, current_pts, prev_joints, current_joints
                )
                unified_frames[i] = remapped_pts
                print(f"  å¸§ {i}: é¡¶ç‚¹æ•°æ˜ å°„ {len(current_pts)} â†’ {target_vertex_count}")
            
            # æ›´æ–°å‚è€ƒå¸§
            prev_pts = unified_frames[i]
            prev_joints = current_joints
        
        self.unified_vertices = np.stack(unified_frames, axis=0)
        print(f"âœ“ åŒå‘ç½‘æ ¼æ‹“æ‰‘ç»Ÿä¸€å®Œæˆ: {self.unified_vertices.shape}")
        print(f"  æ—¶é—´ä¸€è‡´æ€§åº”è¯¥æ›´å¥½ï¼Œå› ä¸ºç›¸é‚»å¸§ä¹‹é—´çš„æ˜ å°„æ›´ç¨³å®š")
        
        return self.unified_vertices.shape
    
    def _check_correspondence_quality(self, template_pts, current_pts, template_joints, current_joints):
        """æ£€æŸ¥é¡¶ç‚¹å¯¹åº”å…³ç³»è´¨é‡"""
        if len(template_pts) != len(current_pts):
            return 0.0
        
        # å…³èŠ‚å¯¹é½æ£€æŸ¥
        joint_distances = np.linalg.norm(template_joints - current_joints, axis=1)
        joint_alignment = np.exp(-joint_distances.mean())
        
        # ç½‘æ ¼ä¸­å¿ƒå¯¹é½æ£€æŸ¥
        template_center = template_pts.mean(axis=0)
        current_center = current_pts.mean(axis=0)
        center_distance = np.linalg.norm(template_center - current_center)
        center_alignment = np.exp(-center_distance * 5)
        
        # ç»„åˆè´¨é‡å¾—åˆ†
        quality = 0.7 * joint_alignment + 0.3 * center_alignment
        return quality
    
    def _bone_guided_remapping(self, template_pts, current_pts, template_joints, current_joints):
        """åŸºäºéª¨éª¼å¼•å¯¼çš„é¡¶ç‚¹é‡æ˜ å°„"""
        n_template = len(template_pts)
        n_current = len(current_pts)
        
        # ä¸ºå¤§å‹ç½‘æ ¼ä½¿ç”¨ç®€åŒ–é‡æ˜ å°„
        if n_template > 8000:
            print(f"    å¤§å‹ç½‘æ ¼ ({n_template} é¡¶ç‚¹), ä½¿ç”¨ç®€åŒ–é‡æ˜ å°„")
            tree = cKDTree(current_pts)
            distances, indices = tree.query(template_pts, k=1)
            return current_pts[indices]
        
        # åˆ›å»ºéª¨éª¼å½±å“åæ ‡ç³»
        template_coords = self._compute_bone_coordinates(template_pts, template_joints)
        current_coords = self._compute_bone_coordinates(current_pts, current_joints)
        
        # ä½¿ç”¨k-dæ ‘è¿›è¡Œé«˜æ•ˆæœ€è¿‘é‚»æœç´¢
        tree = cKDTree(current_coords)
        k = min(3, n_current)
        distances, indices = tree.query(template_coords, k=k)
        
        remapped_pts = np.zeros_like(template_pts)
        
        if k == 1:
            remapped_pts = current_pts[indices.flatten()]
        else:
            # åŠ æƒå¹³å‡
            safe_distances = distances + 1e-8
            weights = 1.0 / safe_distances
            weights = weights / weights.sum(axis=1, keepdims=True)
            
            for i in range(n_template):
                vertex_indices = indices[i]
                vertex_weights = weights[i]
                remapped_pts[i] = np.sum(
                    vertex_weights.reshape(-1, 1) * current_pts[vertex_indices], axis=0
                )
        
        return remapped_pts
    
    def _compute_bone_coordinates(self, vertices, joints):
        """è®¡ç®—éª¨éª¼å½±å“åæ ‡ç³» - ä¼˜åŒ–ç‰ˆæœ¬"""
        n_vertices = len(vertices)
        n_joints = len(joints)
        
        # é¢„è®¡ç®—ç½‘æ ¼å°ºåº¦
        mesh_bounds = vertices.max(axis=0) - vertices.min(axis=0)
        mesh_scale = np.linalg.norm(mesh_bounds)
        
        # å¯¹å¤§å‹ç½‘æ ¼é™åˆ¶å…³èŠ‚å½±å“ç‰¹å¾
        if n_vertices > 5000:
            # åªä½¿ç”¨å‰8ä¸ªæœ€é‡è¦çš„å…³èŠ‚
            joint_subset = joints[:min(8, n_joints)]
            bone_coords = np.zeros((n_vertices, 3 + len(joint_subset)))
        else:
            joint_subset = joints
            bone_coords = np.zeros((n_vertices, 3 + n_joints))
        
        bone_coords[:, :3] = vertices
        
        # å‘é‡åŒ–è·ç¦»è®¡ç®—
        vertices_expanded = vertices[:, np.newaxis, :]  # (N, 1, 3)
        joints_expanded = joint_subset[np.newaxis, :, :]  # (1, K, 3)
        
        distances = np.linalg.norm(vertices_expanded - joints_expanded, axis=2)
        normalized_distances = distances / (mesh_scale + 1e-8)
        influences = np.exp(-normalized_distances * 3.0)
        
        bone_coords[:, 3:] = influences
        
        return bone_coords
    
    def step4_compute_skinning(self):
        """
        æ­¥éª¤4ï¼šä½¿ç”¨ C++ CLI ç‰ˆæœ¬çš„ DemBones è®¡ç®—è’™çš®æƒé‡
        """
        print("\n=== æ­¥éª¤4ï¼šDemBonesè’™çš®æƒé‡è®¡ç®— (C++ CLIç‰ˆæœ¬) ===")
        
        if self.unified_vertices is None:
            raise RuntimeError("å¿…é¡»å…ˆç»Ÿä¸€ç½‘æ ¼æ‹“æ‰‘")
        
        # è·å–éª¨éª¼çˆ¶èŠ‚ç‚¹æ•°æ®
        rest_data = self.all_mesh_data[self.rest_pose_idx]
        self.parents = sanitize_parents(rest_data['parents'])
        
        F, N, _ = self.unified_vertices.shape
        K = len(self.parents)
        
        print(f"éª¨éª¼: {K} ä¸ªå…³èŠ‚")
        print(f"åŠ¨ç”»: {F} å¸§, {N} ä¸ªé¡¶ç‚¹")
        
        # æ™ºèƒ½æ•°æ®å­é‡‡æ ·ä»¥ç¡®ä¿DemBonesèƒ½æˆåŠŸè¿è¡Œ
        processed_vertices, vertex_indices, frame_indices = self._prepare_demBones_data()
        
        F_sub, N_sub, _ = processed_vertices.shape
        print(f"DemBonesè¾“å…¥: {F_sub} å¸§, {N_sub} é¡¶ç‚¹ (å­é‡‡æ ·), {frame_indices} frame_indices")
        
        try:
            # ä½¿ç”¨ä¿®å¤åçš„DemBones API
            rest_pose_sub, weights_sub, transforms_sub = self._compute_skinning_weights_fixed(
                processed_vertices, self.parents
            )
            
            print(f"âœ“ DemBoneså­é‡‡æ ·æ•°æ®æˆåŠŸ:")
            print(f"  Rest pose: {rest_pose_sub.shape}")
            print(f"  è’™çš®æƒé‡: {weights_sub.shape}")
            print(f"  éª¨éª¼å˜æ¢: {transforms_sub.shape}")
            
            # æ‰©å±•ç»“æœåˆ°å®Œæ•´åˆ†è¾¨ç‡
            self.skinning_weights, self.bone_transforms = self._expand_demBones_results(
                weights_sub, transforms_sub, vertex_indices, frame_indices, N, F
            )
            
            print(f"âœ“ æ‰©å±•åˆ°å®Œæ•´åˆ†è¾¨ç‡:")
            print(f"  å®Œæ•´è’™çš®æƒé‡: {self.skinning_weights.shape}")
            print(f"  å®Œæ•´éª¨éª¼å˜æ¢: {self.bone_transforms.shape}")
            print(f"  æƒé‡èŒƒå›´: [{self.skinning_weights.min():.4f}, {self.skinning_weights.max():.4f}]")
                
        except Exception as e:
            print(f"âŒ DemBoneså¤±è´¥: {e}")
            raise RuntimeError(f"DemBonesè®¡ç®—å¤±è´¥: {e}")
        
        # ä¿å­˜ç»“æœ
        skinning_results = {
            'rest_pose': self.unified_vertices[self.rest_pose_idx],
            'skinning_weights': self.skinning_weights,
            'bone_transforms': self.bone_transforms,
            'parents': self.parents,
            'rest_pose_idx': self.rest_pose_idx,
            'unified_vertices': self.unified_vertices
        }
        
        results_path = os.path.join(self.output_dir, 'skinning_results.pkl')
        with open(results_path, 'wb') as f:
            pickle.dump(skinning_results, f)
        
        print(f"âœ“ è’™çš®ç»“æœå·²ä¿å­˜åˆ° {results_path}")
    
    def _prepare_demBones_data(self):
        """æ™ºèƒ½å­é‡‡æ ·æ•°æ®ä»¥ç¡®ä¿DemBonesæˆåŠŸè¿è¡Œ"""
        F, N, _ = self.unified_vertices.shape
        
        # ç›®æ ‡é™åˆ¶å€¼ - åŸºäºæ€§èƒ½æµ‹è¯•ï¼š50ä¸ªé¡¶ç‚¹å¾ˆå¿«ï¼Œ100ä¸ªé¡¶ç‚¹è¾ƒæ…¢
        MAX_VERTICES = 80  # åœ¨50-100ä¹‹é—´é€‰æ‹©ä¸€ä¸ªå®‰å…¨å€¼
        MAX_FRAMES = 10
        
        # é¡¶ç‚¹å­é‡‡æ ·
        if N > MAX_VERTICES:
            vertex_ratio = MAX_VERTICES / N
            vertex_indices = self._sample_vertices_intelligently(vertex_ratio)
            print(f"  é¡¶ç‚¹å­é‡‡æ ·: {N} â†’ {len(vertex_indices)} ({vertex_ratio:.2%})")
        else:
            vertex_indices = np.arange(N)
            print(f"  æ— éœ€é¡¶ç‚¹å­é‡‡æ ·: {N} é¡¶ç‚¹")
        
        # å¸§å­é‡‡æ ·
        if F > MAX_FRAMES:
            frame_indices = np.linspace(0, F-1, MAX_FRAMES, dtype=int)
            if self.rest_pose_idx not in frame_indices:
                frame_indices[0] = self.rest_pose_idx  # ç¡®ä¿åŒ…å«rest pose
            frame_indices = np.sort(frame_indices)
            print(f"  å¸§å­é‡‡æ ·: {F} â†’ {len(frame_indices)} å¸§")
        else:
            frame_indices = np.arange(F)
            print(f"  æ— éœ€å¸§å­é‡‡æ ·: {F} å¸§")
        
        # åˆ›å»ºå­é‡‡æ ·æ•°æ®
        processed_vertices = self.unified_vertices[frame_indices][:, vertex_indices]
        
        return processed_vertices, vertex_indices, frame_indices
    
    def _sample_vertices_intelligently(self, ratio):
        """æ™ºèƒ½é¡¶ç‚¹é‡‡æ ·ä»¥ä¿æŒç½‘æ ¼ç»“æ„ - ä¼˜åŒ–ç‰ˆæœ¬é¿å…å¡æ­»"""
        N = self.unified_vertices.shape[1]
        n_samples = int(N * ratio)
        
        print(f"    æ™ºèƒ½é‡‡æ ·: {N} â†’ {n_samples} é¡¶ç‚¹")
        
        # ä½¿ç”¨rest poseä½œä¸ºå‚è€ƒ
        rest_vertices = self.unified_vertices[self.rest_pose_idx]
        
        # å¯¹äºå¤§å‹ç½‘æ ¼ï¼Œä½¿ç”¨æ›´é«˜æ•ˆçš„é‡‡æ ·ç­–ç•¥
        if N > 20000:
            print(f"    å¤§å‹ç½‘æ ¼æ£€æµ‹ï¼Œä½¿ç”¨å¿«é€Ÿå‡åŒ€é‡‡æ ·")
            # ç®€å•å‡åŒ€é‡‡æ ·é¿å…å¤æ‚è®¡ç®—
            step = N // n_samples
            indices = np.arange(0, N, step)[:n_samples]
            return np.sort(indices)
        
        # ä¸­ç­‰å¤§å°ç½‘æ ¼ï¼šä½¿ç”¨æ”¹è¿›çš„æœ€è¿œç‚¹é‡‡æ ·
        if N > 5000:
            print(f"    ä¸­ç­‰ç½‘æ ¼ï¼Œä½¿ç”¨æ‰¹é‡æœ€è¿œç‚¹é‡‡æ ·")
            # æ‰¹é‡å¤„ç†ï¼Œæ¯æ¬¡å¤„ç†ä¸€æ‰¹å€™é€‰ç‚¹
            indices = [0]
            remaining = np.arange(1, N)
            batch_size = min(1000, len(remaining))
            
            while len(indices) < n_samples and len(remaining) > 0:
                if len(remaining) <= batch_size:
                    # å¤„ç†å‰©ä½™æ‰€æœ‰ç‚¹
                    candidates = remaining
                else:
                    # éšæœºé€‰æ‹©ä¸€æ‰¹å€™é€‰ç‚¹
                    candidates = np.random.choice(remaining, batch_size, replace=False)
                
                # åœ¨å€™é€‰ç‚¹ä¸­æ‰¾æœ€è¿œçš„
                max_dist = -1
                best_idx = None
                
                for idx in candidates:
                    min_dist = min(np.linalg.norm(rest_vertices[idx] - rest_vertices[selected]) 
                                 for selected in indices[-min(10, len(indices)):])  # åªæ¯”è¾ƒæœ€è¿‘çš„10ä¸ªç‚¹
                    if min_dist > max_dist:
                        max_dist = min_dist
                        best_idx = idx
                
                if best_idx is not None:
                    indices.append(best_idx)
                    remaining = remaining[remaining != best_idx]
                else:
                    break
            
            # å¦‚æœè¿˜ä¸å¤Ÿï¼Œéšæœºè¡¥å……
            if len(indices) < n_samples and len(remaining) > 0:
                needed = n_samples - len(indices)
                additional = np.random.choice(remaining, min(needed, len(remaining)), replace=False)
                indices.extend(additional)
            
            return np.sort(indices[:n_samples])
        
        # å°å‹ç½‘æ ¼ï¼šä½¿ç”¨å®Œæ•´æœ€è¿œç‚¹é‡‡æ ·
        else:
            print(f"    å°å‹ç½‘æ ¼ï¼Œä½¿ç”¨å®Œæ•´æœ€è¿œç‚¹é‡‡æ ·")
            indices = [0]
            remaining = set(range(1, N))
            
            for i in range(n_samples - 1):
                if not remaining:
                    break
                    
                max_dist = -1
                best_idx = None
                
                # éšæœºé‡‡æ ·ä¸€éƒ¨åˆ†å€™é€‰ç‚¹ä»¥åŠ é€Ÿ
                candidates = list(remaining)
                if len(candidates) > 500:
                    candidates = np.random.choice(candidates, 500, replace=False)
                
                for idx in candidates:
                    min_dist = min(np.linalg.norm(rest_vertices[idx] - rest_vertices[selected]) 
                                 for selected in indices[-min(5, len(indices)):])  # åªæ¯”è¾ƒæœ€è¿‘çš„5ä¸ªç‚¹
                    if min_dist > max_dist:
                        max_dist = min_dist
                        best_idx = idx
                
                if best_idx is not None:
                    indices.append(best_idx)
                    remaining.remove(best_idx)
                
                # æ¯100ä¸ªç‚¹æ˜¾ç¤ºè¿›åº¦
                if i % 100 == 0:
                    print(f"      é‡‡æ ·è¿›åº¦: {i+1}/{n_samples-1}")
            
            return np.sort(indices[:n_samples])
    
    def _compute_skinning_weights_fixed(self, frames_vertices, parents):
        """ä½¿ç”¨ä¿®å¤åçš„DemBones APIè®¡ç®—è’™çš®æƒé‡ - å¸¦è¶…æ—¶å’Œå›é€€æœºåˆ¶"""
        print("ä½¿ç”¨ä¿®å¤åçš„DemBones API...")
        
        F, N, _ = frames_vertices.shape
        K = len(parents)
        
        # æ£€æŸ¥æ•°æ®åˆç†æ€§
        if F < 2:
            print("âš ï¸ å¸§æ•°ä¸è¶³ï¼Œä½¿ç”¨ç®€åŒ–è’™çš®æƒé‡")
            return self._create_simple_skinning_weights(frames_vertices[0], K)
        
        if N > 8000:
            print("âš ï¸ é¡¶ç‚¹æ•°è¿‡å¤šï¼Œè¿›ä¸€æ­¥å­é‡‡æ ·")
            # è¿›ä¸€æ­¥å‡å°‘é¡¶ç‚¹æ•°
            subsample_ratio = 6000 / N
            subsample_indices = np.linspace(0, N-1, 6000, dtype=int)
            frames_vertices = frames_vertices[:, subsample_indices]
            N = 6000
            print(f"    è¿›ä¸€æ­¥å­é‡‡æ ·åˆ° {N} é¡¶ç‚¹")
        
        # å°è¯•å¤šç§é…ç½®çš„DemBones
        configs = [
            # é…ç½®1ï¼šæœ€ç®€å•è®¾ç½®
            {
                'nIters': 10, 'nInitIters': 2, 'nTransIters': 1, 
                'nWeightsIters': 1, 'nnz': 4, 'weightsSmooth': 1e-3,
                'timeout': 60, 'name': 'æœ€ç®€é…ç½®'
            },
            # é…ç½®2ï¼šä¸­ç­‰è®¾ç½®
            {
                'nIters': 15, 'nInitIters': 3, 'nTransIters': 2, 
                'nWeightsIters': 1, 'nnz': 6, 'weightsSmooth': 1e-4,
                'timeout': 120, 'name': 'ä¸­ç­‰é…ç½®'
            },
            # é…ç½®3ï¼šåŸå§‹è®¾ç½®ï¼ˆä½†è¶…æ—¶æ—¶é—´æ›´çŸ­ï¼‰
            {
                'nIters': 20, 'nInitIters': 5, 'nTransIters': 3, 
                'nWeightsIters': 2, 'nnz': 8, 'weightsSmooth': 1e-4,
                'timeout': 180, 'name': 'å®Œæ•´é…ç½®'
            }
        ]
        
        for i, config in enumerate(configs):
            print(f"\nå°è¯•DemBones {config['name']} (é…ç½® {i+1}/{len(configs)})")
            
            try:
                result = self._try_demBones_with_timeout(frames_vertices, parents, config)
                if result is not None:
                    print(f"âœ“ {config['name']} æˆåŠŸï¼")
                    return result
                else:
                    print(f"âŒ {config['name']} è¶…æ—¶æˆ–å¤±è´¥")
                    
            except Exception as e:
                print(f"âŒ {config['name']} å¼‚å¸¸: {e}")
                continue
        
        # æ‰€æœ‰DemBonesé…ç½®éƒ½å¤±è´¥ï¼Œä½¿ç”¨å›é€€æ–¹æ¡ˆ
        print("âš ï¸ æ‰€æœ‰DemBonesé…ç½®éƒ½å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–è’™çš®æƒé‡")
        return self._create_simple_skinning_weights(frames_vertices[0], K)
    
    def _try_demBones_with_timeout(self, frames_vertices, parents, config):
        """ä½¿ç”¨ C++ CLI ç‰ˆæœ¬è¿è¡Œ DemBones"""
        F, N, _ = frames_vertices.shape
        K = len(parents)
        
        print(f"    Rest pose: {frames_vertices[0].shape}, Animated: {frames_vertices[1:].shape}")
        print(f"    å‚æ•°: iters={config['nIters']}, nnz={config['nnz']}")
        
        # æŸ¥æ‰¾ DemBones å¯æ‰§è¡Œæ–‡ä»¶
        demBones_exe = self._find_demBones_executable()
        if demBones_exe is None:
            print("    âš ï¸ æœªæ‰¾åˆ° DemBones å¯æ‰§è¡Œæ–‡ä»¶ï¼Œä½¿ç”¨ç®€åŒ–è’™çš®æƒé‡")
            return None
        
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        with tempfile.TemporaryDirectory() as temp_dir:
            try:
                # å‡†å¤‡æ•°æ®æ–‡ä»¶
                input_file = os.path.join(temp_dir, 'input.dembones')
                output_file = os.path.join(temp_dir, 'output.dembones')
                
                # å†™å…¥è¾“å…¥æ•°æ®
                self._write_demBones_input(input_file, frames_vertices, parents, config)
                
                # è¿è¡Œ DemBones CLI
                print(f"    è¿è¡Œå‘½ä»¤: {demBones_exe}")
                start_time = time.time()
                
                # DemBones CLI å‘½ä»¤æ ¼å¼: demBones input.dembones output.dembones
                result = subprocess.run(
                    [demBones_exe, input_file, output_file],
                    capture_output=True,
                    text=True,
                    timeout=config.get('timeout', 300)
                )
                
                elapsed_time = time.time() - start_time
                
                if result.returncode == 0:
                    print(f"    âœ… DemBones CLI æ‰§è¡ŒæˆåŠŸï¼è€—æ—¶ {elapsed_time:.2f} ç§’")
                    
                    # è¯»å–ç»“æœ
                    if os.path.exists(output_file):
                        return self._read_demBones_output(output_file, frames_vertices[0], K, F)
                    else:
                        print("    âŒ è¾“å‡ºæ–‡ä»¶æœªç”Ÿæˆ")
                        return None
                else:
                    print(f"    âŒ DemBones CLI æ‰§è¡Œå¤±è´¥ (è¿”å›ç : {result.returncode})")
                    if result.stdout:
                        print(f"    æ ‡å‡†è¾“å‡º: {result.stdout[:500]}...")
                    if result.stderr:
                        print(f"    æ ‡å‡†é”™è¯¯: {result.stderr[:500]}...")
                    return None
                
            except subprocess.TimeoutExpired:
                print(f"    âŒ DemBones CLI è¶…æ—¶ ({config.get('timeout', 300)} ç§’)")
                return None
            except Exception as e:
                print(f"    âŒ DemBones CLI å¼‚å¸¸: {e}")
                return None
    
    def _find_demBones_executable(self):
        """æŸ¥æ‰¾ DemBones å¯æ‰§è¡Œæ–‡ä»¶"""
        # å¸¸è§çš„å¯èƒ½ä½ç½®
        possible_paths = [
            'demBones.exe',  # åœ¨ PATH ä¸­
            'DemBones.exe',
            'demBones.bat',  # Windows æ‰¹å¤„ç†æ–‡ä»¶
            './demBones.exe',  # å½“å‰ç›®å½•
            './DemBones.exe',
            './demBones.bat',
            './bin/demBones.exe',  # bin ç›®å½•
            './bin/DemBones.exe',
            './bin/demBones.bat',
            'C:/Program Files/DemBones/demBones.exe',  # ç³»ç»Ÿå®‰è£…
            'C:/Program Files/DemBones/DemBones.exe',
            '../demBones/bin/demBones.exe',  # ç›¸é‚»ç›®å½•
            '../demBones/bin/DemBones.exe',
            # Linux è·¯å¾„
            'demBones',
            './demBones',
            './bin/demBones',
            '/usr/local/bin/demBones',
            '/usr/bin/demBones',
        ]
        
        for path in possible_paths:
            try:
                # æµ‹è¯•æ˜¯å¦å¯ä»¥æ‰§è¡Œ
                result = subprocess.run([path, '--help'], 
                                      capture_output=True, timeout=5, text=True)
                if result.returncode == 0 or 'dembones' in result.stdout.lower() or 'usage' in result.stdout.lower():
                    print(f"    âœ“ æ‰¾åˆ° DemBones: {path}")
                    return path
            except:
                continue
        
        print("    âš ï¸ æœªæ‰¾åˆ° DemBones å¯æ‰§è¡Œæ–‡ä»¶")
        print("    ğŸ“¥ å»ºè®®ä¸‹è½½å¹¶ç¼–è¯‘: https://github.com/electronicarts/dem-bones")
        print("    ğŸ”„ å°†ä½¿ç”¨ç®€åŒ–è’™çš®æƒé‡ç®—æ³•")
        return None
    
    def _write_demBones_input(self, input_file, frames_vertices, parents, config):
        """å†™å…¥ DemBones è¾“å…¥æ–‡ä»¶ï¼ˆåŸºäºå®˜æ–¹æ ¼å¼ï¼‰"""
        F, N, _ = frames_vertices.shape
        K = len(parents)
        
        with open(input_file, 'w') as f:
            # å†™å…¥åŸºæœ¬ä¿¡æ¯
            f.write(f"# DemBones Input File\n")
            f.write(f"nV {N}\n")  # é¡¶ç‚¹æ•°
            f.write(f"nB {K}\n")  # éª¨éª¼æ•°
            f.write(f"nF {F-1}\n")  # åŠ¨ç”»å¸§æ•° (ä¸åŒ…æ‹¬rest pose)
            f.write(f"nS 1\n")  # subjectæ•°é‡
            
            # å†™å…¥ç®—æ³•å‚æ•°
            f.write(f"nIters {config['nIters']}\n")
            f.write(f"nInitIters {config['nInitIters']}\n") 
            f.write(f"nTransIters {config['nTransIters']}\n")
            f.write(f"nWeightsIters {config['nWeightsIters']}\n")
            f.write(f"nnz {config['nnz']}\n")
            f.write(f"weightsSmooth {config['weightsSmooth']}\n")
            
            # å†™å…¥éª¨éª¼å±‚æ¬¡ç»“æ„
            f.write("# Bone hierarchy (parents)\n")
            for i, parent in enumerate(parents):
                f.write(f"parent {i} {parent}\n")
            
            # å†™å…¥frameèµ·å§‹ç´¢å¼•å’Œsubject ID
            f.write("fStart 0\n")
            f.write("subjectID 0\n")
            
            # å†™å…¥rest poseé¡¶ç‚¹
            f.write("# Rest pose vertices\n")
            rest_pose = frames_vertices[0]
            for i in range(N):
                f.write(f"v {rest_pose[i, 0]:.6f} {rest_pose[i, 1]:.6f} {rest_pose[i, 2]:.6f}\n")
            
            # å†™å…¥åŠ¨ç”»é¡¶ç‚¹
            f.write("# Animated vertices\n")
            for frame_idx in range(1, F):
                frame_vertices = frames_vertices[frame_idx]
                for i in range(N):
                    f.write(f"a {frame_vertices[i, 0]:.6f} {frame_vertices[i, 1]:.6f} {frame_vertices[i, 2]:.6f}\n")
    
    def _read_demBones_output(self, output_file, rest_pose, K, F):
        """è¯»å– DemBones è¾“å‡ºæ–‡ä»¶"""
        try:
            weights = None
            N = len(rest_pose)
            
            with open(output_file, 'r') as f:
                lines = f.readlines()
            
            # è§£ææƒé‡çŸ©é˜µ
            # DemBones é€šå¸¸è¾“å‡ºæ ¼å¼ä¸ºæ¯è¡Œä¸€ä¸ªé¡¶ç‚¹çš„æƒé‡
            weights = np.zeros((N, K), dtype=np.float32)
            
            reading_weights = False
            vertex_idx = 0
            
            for line in lines:
                line = line.strip()
                if not line or line.startswith('#'):
                    continue
                
                # æ£€æŸ¥æ˜¯å¦å¼€å§‹è¯»å–æƒé‡
                if 'weight' in line.lower() or reading_weights:
                    reading_weights = True
                    
                    # å°è¯•è§£ææƒé‡æ•°æ®
                    try:
                        if line.startswith('w ') or ' ' in line:
                            values = line.replace('w ', '').split()
                            if len(values) >= K and vertex_idx < N:
                                for k in range(K):
                                    weights[vertex_idx, k] = float(values[k])
                                vertex_idx += 1
                    except:
                        continue
            
            # å¦‚æœæ²¡æœ‰è¯»å–åˆ°æƒé‡ï¼Œåˆ›å»ºç®€å•æƒé‡
            if vertex_idx == 0:
                print("    âš ï¸ æ— æ³•è§£æDemBonesè¾“å‡ºï¼Œåˆ›å»ºç®€åŒ–æƒé‡")
                return self._create_simple_skinning_weights(rest_pose, K)
            
            # å½’ä¸€åŒ–æƒé‡
            row_sums = weights.sum(axis=1, keepdims=True)
            row_sums[row_sums < 1e-8] = 1.0
            weights = weights / row_sums
            
            # åˆ›å»ºå•ä½å˜æ¢çŸ©é˜µï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            T_all = np.zeros((F, K, 4, 4), dtype=np.float32)
            for f in range(F):
                for b in range(K):
                    T_all[f, b] = np.eye(4)
            
            print(f"    âœ“ è¯»å–æƒé‡çŸ©é˜µ: {weights.shape}")
            print(f"    æƒé‡èŒƒå›´: [{weights.min():.4f}, {weights.max():.4f}]")
            
            return (rest_pose, weights, T_all)
                
        except Exception as e:
            print(f"    âŒ è¯»å–è¾“å‡ºæ–‡ä»¶å¤±è´¥: {e}")
            return None
    
    def _create_simple_skinning_weights(self, rest_pose, K):
        """åˆ›å»ºç®€åŒ–çš„è’™çš®æƒé‡ï¼ˆå½“DemBoneså¤±è´¥æ—¶çš„å›é€€æ–¹æ¡ˆï¼‰"""
        print("åˆ›å»ºç®€åŒ–è’™çš®æƒé‡...")
        N = len(rest_pose)
        
        # åˆ›å»ºåŸºäºè·ç¦»çš„è’™çš®æƒé‡
        rest_data = self.all_mesh_data[self.rest_pose_idx]
        joints = rest_data['joints']
        
        # å°†jointsä»å½’ä¸€åŒ–åæ ‡è½¬æ¢ä¸ºä¸rest_poseç›¸åŒçš„åæ ‡ç³»
        joints_scaled = joints  # å‡è®¾å·²ç»åœ¨æ­£ç¡®åæ ‡ç³»ä¸­
        
        weights = np.zeros((N, K), dtype=np.float32)
        
        # ä¸ºæ¯ä¸ªé¡¶ç‚¹è®¡ç®—åˆ°æ¯ä¸ªå…³èŠ‚çš„è·ç¦»
        for v in range(N):
            vertex = rest_pose[v]
            distances = np.array([np.linalg.norm(vertex - joints_scaled[j]) for j in range(min(K, len(joints_scaled)))])
            
            # è½¬æ¢è·ç¦»ä¸ºæƒé‡ï¼ˆè·ç¦»è¶Šè¿‘æƒé‡è¶Šå¤§ï¼‰
            inv_distances = 1.0 / (distances + 1e-3)
            
            # åªä¿ç•™æœ€è¿‘çš„å‡ ä¸ªå…³èŠ‚
            top_k = min(4, len(inv_distances))
            top_indices = np.argsort(inv_distances)[-top_k:]
            
            for idx in top_indices:
                if idx < K:
                    weights[v, idx] = inv_distances[idx]
            
            # å½’ä¸€åŒ–
            weight_sum = weights[v].sum()
            if weight_sum > 1e-8:
                weights[v] /= weight_sum
            else:
                # å¦‚æœæ‰€æœ‰æƒé‡éƒ½æ˜¯0ï¼Œç»™ç¬¬ä¸€ä¸ªå…³èŠ‚è®¾ç½®æƒé‡
                weights[v, 0] = 1.0
        
        # åˆ›å»ºå•ä½å˜æ¢çŸ©é˜µ
        F = len(self.all_mesh_data)
        T_all = np.zeros((F, K, 4, 4), dtype=np.float32)
        for f in range(F):
            for b in range(K):
                T_all[f, b] = np.eye(4)
        
        print(f"âœ“ ç®€åŒ–è’™çš®æƒé‡åˆ›å»ºå®Œæˆ: {weights.shape}")
        print(f"  æƒé‡èŒƒå›´: [{weights.min():.4f}, {weights.max():.4f}]")
        
        return rest_pose, weights, T_all
    
    def _expand_demBones_results(self, weights_sub, transforms_sub, vertex_indices, frame_indices, N_full, F_full):
        """å°†DemBonesç»“æœä»å­é‡‡æ ·æ•°æ®æ‰©å±•åˆ°å®Œæ•´åˆ†è¾¨ç‡"""
        K = len(self.parents)
        
        # æ‰©å±•è’™çš®æƒé‡
        full_weights = np.zeros((N_full, K), dtype=np.float32)
        
        # ç›´æ¥åˆ†é…å­é‡‡æ ·æƒé‡
        full_weights[vertex_indices] = weights_sub
        
        # å¯¹æœªé‡‡æ ·é¡¶ç‚¹è¿›è¡Œæ’å€¼
        rest_vertices_full = self.unified_vertices[self.rest_pose_idx]
        rest_vertices_sub = rest_vertices_full[vertex_indices]
        
        tree = cKDTree(rest_vertices_sub)
        unsampled_indices = np.setdiff1d(np.arange(N_full), vertex_indices)
        
        if len(unsampled_indices) > 0:
            distances, nearest_idx = tree.query(rest_vertices_full[unsampled_indices], k=3)
            
            for i, orig_idx in enumerate(unsampled_indices):
                dists = distances[i]
                neighs = nearest_idx[i]
                
                weights_dists = 1.0 / (dists + 1e-8)
                weights_dists /= weights_dists.sum()
                
                for j in range(len(neighs)):
                    full_weights[orig_idx] += weights_dists[j] * weights_sub[neighs[j]]
        
        # æ‰©å±•éª¨éª¼å˜æ¢ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        full_transforms = np.zeros((F_full, K, 4, 4), dtype=np.float32)
        for f in range(F_full):
            for b in range(K):
                full_transforms[f, b] = np.eye(4)
        
        return full_weights, full_transforms
    
    def step5_generate_interpolation(self, start_frame_idx, end_frame_idx, num_interp):
        """
        æ­¥éª¤5ï¼šåœ¨ä»»æ„ä¸¤å¸§ä¹‹é—´ç”ŸæˆæŒ‡å®šæ•°é‡çš„æ’å€¼
        """
        print(f"\n=== æ­¥éª¤5ï¼šç”Ÿæˆæ’å€¼ (å¸§{start_frame_idx} â†’ å¸§{end_frame_idx}, {num_interp}ä¸ªæ’å€¼) ===")
        
        if self.bone_transforms is None:
            raise RuntimeError("å¿…é¡»å…ˆè®¡ç®—è’™çš®æƒé‡")
        
        if start_frame_idx >= len(self.all_mesh_data) or end_frame_idx >= len(self.all_mesh_data):
            raise ValueError(f"å¸§ç´¢å¼•è¶…å‡ºèŒƒå›´ (æœ€å¤§: {len(self.all_mesh_data)-1})")
        
        # è·å–èµ·å§‹å’Œç»“æŸå¸§çš„éª¨éª¼å˜æ¢
        T_from = self.bone_transforms[start_frame_idx]  # (K, 4, 4)
        T_to = self.bone_transforms[end_frame_idx]      # (K, 4, 4)
        
        # åˆ›å»ºæ’å€¼æƒé‡
        alphas = np.linspace(0, 1, num_interp + 2)[1:-1]  # æ’é™¤ç«¯ç‚¹
        
        interpolated_meshes = []
        rest_data = self.all_mesh_data[self.rest_pose_idx]
        
        for i, alpha in enumerate(alphas):
            print(f"  ç”Ÿæˆæ’å€¼å¸§ {i+1}/{num_interp} (alpha={alpha:.3f})")
            
            # æ’å€¼éª¨éª¼å˜æ¢
            T_interp = self._interpolate_bone_transforms(T_from, T_to, alpha)
            
            # åº”ç”¨çº¿æ€§æ··åˆè’™çš®
            vertices_interp = self._apply_linear_blend_skinning(
                self.unified_vertices[self.rest_pose_idx],  # Rest poseé¡¶ç‚¹
                T_interp
            )
            
            # è½¬æ¢å›ä¸–ç•Œåæ ‡
            vertices_world = (vertices_interp + 1) * 0.5 * rest_data['blen'] + rest_data['bmin']
            
            # åˆ›å»ºç½‘æ ¼
            mesh_interp = o3d.geometry.TriangleMesh(
                vertices=o3d.utility.Vector3dVector(vertices_world),
                triangles=o3d.utility.Vector3iVector(rest_data['mesh_triangles'])
            )
            mesh_interp.compute_vertex_normals()
            
            # ä¿å­˜ç½‘æ ¼
            output_path = os.path.join(self.output_dir, f'interpolated_{start_frame_idx:03d}_{end_frame_idx:03d}_{i:03d}.obj')
            o3d.io.write_triangle_mesh(output_path, mesh_interp)
            
            interpolated_meshes.append(vertices_world)
        
        print(f"âœ“ ç”Ÿæˆäº† {len(interpolated_meshes)} ä¸ªæ’å€¼å¸§")
        print(f"âœ“ ä¿å­˜åˆ°: {self.output_dir}/interpolated_{start_frame_idx:03d}_{end_frame_idx:03d}_*.obj")
        
        return interpolated_meshes
    
    def _interpolate_bone_transforms(self, T_from, T_to, alpha):
        """ä½¿ç”¨SLERPæ’å€¼éª¨éª¼å˜æ¢"""
        T_interp = np.zeros_like(T_from)
        
        for k in range(len(T_from)):
            # æå–æ—‹è½¬å’Œå¹³ç§»
            R_from = T_from[k, :3, :3]
            R_to = T_to[k, :3, :3]
            t_from = T_from[k, :3, 3]
            t_to = T_to[k, :3, 3]
            
            # æ—‹è½¬çš„SLERPæ’å€¼
            try:
                rot_from = Rotation.from_matrix(R_from)
                rot_to = Rotation.from_matrix(R_to)
                slerp = Slerp([0, 1], Rotation.concatenate([rot_from, rot_to]))
                R_interp = slerp([alpha]).as_matrix()[0]
            except:
                # å›é€€åˆ°çº¿æ€§æ’å€¼
                R_interp = (1 - alpha) * R_from + alpha * R_to
            
            # å¹³ç§»çš„çº¿æ€§æ’å€¼
            t_interp = (1 - alpha) * t_from + alpha * t_to
            
            # é‡æ„å˜æ¢çŸ©é˜µ
            T_interp[k, :3, :3] = R_interp
            T_interp[k, :3, 3] = t_interp
            T_interp[k, 3, 3] = 1.0
        
        return T_interp
    
    def _apply_linear_blend_skinning(self, rest_vertices, bone_transforms):
        """åº”ç”¨çº¿æ€§æ··åˆè’™çš®å˜å½¢rest poseé¡¶ç‚¹"""
        N = len(rest_vertices)
        K = len(bone_transforms)
        
        # è½¬æ¢ä¸ºé½æ¬¡åæ ‡
        rest_h = np.hstack([rest_vertices, np.ones((N, 1))])
        
        # åº”ç”¨è’™çš®
        deformed_vertices = np.zeros((N, 3))
        
        for v in range(N):
            blended_transform = np.zeros((4, 4))
            
            for k in range(K):
                weight = self.skinning_weights[v, k]
                if weight > 1e-6:
                    blended_transform += weight * bone_transforms[k]
            
            # åº”ç”¨æ··åˆå˜æ¢
            deformed_h = blended_transform @ rest_h[v]
            deformed_vertices[v] = deformed_h[:3]
        
        return deformed_vertices


def main():
    parser = argparse.ArgumentParser(description="å®Œæ•´çš„ä½“ç§¯è§†é¢‘æ’å€¼ç®¡é“")
    parser.add_argument('folder_path', type=str, help='åŒ…å«.objæ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„')
    parser.add_argument('--start_frame', type=int, default=0, help='å¤„ç†èµ·å§‹å¸§ç´¢å¼•')
    parser.add_argument('--end_frame', type=int, default=None, help='å¤„ç†ç»“æŸå¸§ç´¢å¼•')
    parser.add_argument('--interp_from', type=int, default=None, help='æ’å€¼èµ·å§‹å¸§ç´¢å¼•')
    parser.add_argument('--interp_to', type=int, default=None, help='æ’å€¼ç»“æŸå¸§ç´¢å¼•')
    parser.add_argument('--num_interp', type=int, default=5, help='æ’å€¼å¸§æ•°')
    parser.add_argument('--output_dir', type=str, default=None, help='è¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    if not os.path.exists(args.folder_path):
        print(f"âŒ é”™è¯¯: æ–‡ä»¶å¤¹ {args.folder_path} ä¸å­˜åœ¨")
        return
    
    # åˆå§‹åŒ–ç®¡é“
    pipeline = CompleteVVPipeline(args.folder_path, args.output_dir)
    
    try:
        # æ­¥éª¤1ï¼šå¤„ç†å¸§æ•°æ®
        pipeline.step1_process_frames(args.start_frame, args.end_frame)
        
        # æ­¥éª¤2ï¼šæ£€æµ‹rest pose
        # pipeline.step2_detect_rest_pose()
        
        # # æ­¥éª¤3ï¼šç»Ÿä¸€ç½‘æ ¼æ‹“æ‰‘
        # pipeline.step3_unify_mesh_topology()
        
        # # æ­¥éª¤4ï¼šè®¡ç®—è’™çš®æƒé‡
        # pipeline.step4_compute_skinning()
        
        # # æ­¥éª¤5ï¼šç”Ÿæˆæ’å€¼
        # if args.interp_from is not None and args.interp_to is not None:
        #     pipeline.step5_generate_interpolation(args.start_frame, args.end_frame, args.num_interp)
        # else:
        #     # é»˜è®¤åœ¨å‰ä¸¤å¸§ä¹‹é—´æ’å€¼
        #     pipeline.step5_generate_interpolation(0, min(1, len(pipeline.all_mesh_data)-1), args.num_interp)
        
        print("\nğŸ‰ å®Œæ•´ç®¡é“æ‰§è¡ŒæˆåŠŸï¼")
        print(f"ğŸ“ ç»“æœä¿å­˜åœ¨: {pipeline.output_dir}")
        
    except Exception as e:
        print(f"\nâŒ ç®¡é“æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
