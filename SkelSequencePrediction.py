import torch
import numpy as np
import os
import pickle
import open3d as o3d
from model.neural_marionette import NeuralMarionette
from utils.dataset_utils import crop_sequence, voxelize, episodic_normalization
import glob
from pathlib import Path
from SkelVisualizer import visualize_skeleton
import json
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from threading import Lock

class SequenceSkeletonPredictor:
    def __init__(self, checkpoint_path, opt_path):
        """
        åˆå§‹åŒ–Neural Marionetteæ¨¡å‹
        
        Args:
            checkpoint_path: é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„
            opt_path: é…ç½®æ–‡ä»¶è·¯å¾„
        """
        start_time = time.time()
        
        # åŠ è½½é…ç½®
        with open(opt_path, 'rb') as f:
            self.opt = pickle.load(f)
        
        # åŠ è½½æ¨¡å‹
        checkpoint = torch.load(checkpoint_path)
        self.network = NeuralMarionette(self.opt).cuda()
        self.network.load_state_dict(checkpoint)
        self.network.eval()
        self.network.anneal(1)  # å¯ç”¨affinityæå–
        
        model_load_time = time.time() - start_time
        print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼Œå…³é”®ç‚¹æ•°é‡: {self.opt.nkeypoints}")
        print(f"â±ï¸  æ¨¡å‹åŠ è½½è€—æ—¶: {model_load_time:.2f}ç§’")
    
    def process_single_mesh(self, mesh_file, frame_idx, total_frames):
        """
        å¤„ç†å•ä¸ªç½‘æ ¼æ–‡ä»¶ï¼ˆç”¨äºå¤šçº¿ç¨‹ï¼‰
        
        Args:
            mesh_file: ç½‘æ ¼æ–‡ä»¶è·¯å¾„
            frame_idx: å¸§ç´¢å¼•
            total_frames: æ€»å¸§æ•°
            
        Returns:
            dict: åŒ…å«å¤„ç†ç»“æœçš„å­—å…¸
        """
        try:
            print(f"ğŸ”„ å¤„ç†ç¬¬ {frame_idx+1}/{total_frames} ä¸ªæ–‡ä»¶: {os.path.basename(mesh_file)}")
            
            # åŠ è½½ç½‘æ ¼
            if mesh_file.endswith('.obj') or mesh_file.endswith('.ply'):
                mesh = o3d.io.read_triangle_mesh(mesh_file)
            else:
                # å°è¯•ä½œä¸ºç‚¹äº‘åŠ è½½
                pcd = o3d.io.read_point_cloud(mesh_file)
                points = np.asarray(pcd.points)
            
            if 'mesh' in locals() and len(mesh.vertices) > 0:
                points = np.asarray(mesh.vertices)
                mesh_data = mesh
            elif 'pcd' in locals() and len(pcd.points) > 0:
                points = np.asarray(pcd.points)
                mesh_data = pcd
            else:
                raise ValueError(f"æ— æ³•åŠ è½½æ–‡ä»¶: {mesh_file}")
            
            # å½’ä¸€åŒ–ç‚¹äº‘ï¼ˆæ¨¡ä»¿åŸä»£ç çš„å¤„ç†æ–¹å¼ï¼‰
            points_norm = episodic_normalization(points[None], scale=1.0, x_trans=0.0, z_trans=0.0)[0]
            
            # ä½“ç´ åŒ–
            try:
                voxel = voxelize(points_norm, (self.opt.grid_size,) * 3, is_binarized=True)
            except Exception as e:
                print(f"âŒ ä½“ç´ åŒ–å¤±è´¥: {e}")
                raise
            
            return {
                'frame_idx': frame_idx,
                'mesh': mesh_data,
                'points_norm': points_norm,
                'voxel': voxel,
                'success': True
            }
            
        except Exception as e:
            print(f"âŒ å¤„ç†æ–‡ä»¶å¤±è´¥ {mesh_file}: {e}")
            return {
                'frame_idx': frame_idx,
                'mesh': None,
                'points_norm': None,
                'voxel': None,
                'success': False,
                'error': str(e)
            }
    
    def load_mesh_sequence(self, mesh_folder, file_pattern="*.obj", max_frames=None):
        """
        åŠ è½½ç½‘æ ¼åºåˆ—å¹¶è½¬æ¢ä¸ºä½“ç´ ï¼ˆå¤šçº¿ç¨‹ç‰ˆæœ¬ï¼‰
        
        Args:
            mesh_folder: åŒ…å«ç½‘æ ¼æ–‡ä»¶çš„æ–‡ä»¶å¤¹è·¯å¾„
            file_pattern: æ–‡ä»¶åŒ¹é…æ¨¡å¼ï¼Œå¦‚ "*.obj", "frame_*.ply"
            max_frames: æœ€å¤§å¸§æ•°é™åˆ¶
        
        Returns:
            voxel_sequence: (T, grid_size, grid_size, grid_size)
            mesh_sequence: åŸå§‹ç½‘æ ¼æ•°æ®åˆ—è¡¨
        """
        start_time = time.time()
        
        mesh_files = sorted(glob.glob(os.path.join(mesh_folder, file_pattern)))
        
        if max_frames:
            mesh_files = mesh_files[:max_frames]
        
        if len(mesh_files) == 0:
            raise ValueError(f"åœ¨ {mesh_folder} ä¸­æœªæ‰¾åˆ°åŒ¹é… {file_pattern} çš„æ–‡ä»¶")
        
        print(f"ğŸ“ æ‰¾åˆ° {len(mesh_files)} ä¸ªç½‘æ ¼æ–‡ä»¶")
        print(f"ğŸ”„ å¼€å§‹å¤šçº¿ç¨‹å¤„ç†...")
        
        # å¤šçº¿ç¨‹å¤„ç†
        max_workers = min(8, len(mesh_files))  # é™åˆ¶æœ€å¤§çº¿ç¨‹æ•°
        print(f"  - ä½¿ç”¨ {max_workers} ä¸ªçº¿ç¨‹")
        
        voxel_sequence = []
        mesh_sequence = []
        points_sequence = []
        
        # ç”¨äºå­˜å‚¨ç»“æœçš„åˆ—è¡¨ï¼ˆæŒ‰å¸§ç´¢å¼•æ’åºï¼‰
        results = [None] * len(mesh_files)
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            # æäº¤æ‰€æœ‰ä»»åŠ¡
            future_to_idx = {
                executor.submit(self.process_single_mesh, mesh_file, i, len(mesh_files)): i 
                for i, mesh_file in enumerate(mesh_files)
            }
            
            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_idx):
                result = future.result()
                if result['success']:
                    results[result['frame_idx']] = result
                    print(f"âœ… å®Œæˆç¬¬ {result['frame_idx']+1}/{len(mesh_files)} ä¸ªæ–‡ä»¶")
                else:
                    print(f"âŒ ç¬¬ {result['frame_idx']+1} ä¸ªæ–‡ä»¶å¤„ç†å¤±è´¥: {result.get('error', 'æœªçŸ¥é”™è¯¯')}")
        
        # æŒ‰é¡ºåºæ•´ç†ç»“æœ
        for i, result in enumerate(results):
            if result is None or not result['success']:
                raise ValueError(f"ç¬¬ {i+1} ä¸ªæ–‡ä»¶å¤„ç†å¤±è´¥")
            
            mesh_sequence.append(result['mesh'])
            points_sequence.append(result['points_norm'])
            voxel_sequence.append(result['voxel'])
        
        # è½¬æ¢ä¸ºtorch tensor
        voxel_sequence = torch.from_numpy(np.stack(voxel_sequence, axis=0)).float().cuda()
        
        processing_time = time.time() - start_time
        print(f"âœ… å¤šçº¿ç¨‹å¤„ç†å®Œæˆï¼")
        print(f"  - ä½“ç´ åºåˆ—å½¢çŠ¶: {voxel_sequence.shape}")
        print(f"  - å¤„ç†è€—æ—¶: {processing_time:.2f}ç§’")
        print(f"  - å¹³å‡æ¯å¸§: {processing_time/len(mesh_files):.3f}ç§’")
        
        return voxel_sequence, mesh_sequence, points_sequence

    def predict_skeleton_sequence(self, voxel_sequence):
        """
        é¢„æµ‹æ•´ä¸ªåºåˆ—çš„éª¨éª¼
        
        Args:
            voxel_sequence: (T, grid_size, grid_size, grid_size)
        
        Returns:
            keypoints: (1, T, K, 4) - joints åæ ‡å’Œç½®ä¿¡åº¦
            transforms: (T, K, 4, 4) - å˜æ¢çŸ©é˜µ,æ¯ä¸ªå…³èŠ‚çš„å±€éƒ¨åæ ‡ç³»
            affinity: éª¨éª¼è¿æ¥å…³ç³»
            parents: çˆ¶å­å…³ç³»
        """
        start_time = time.time()
        print(f"ğŸ§  å¼€å§‹ç¥ç»ç½‘ç»œé¢„æµ‹...")
        print(f"  - è¾“å…¥å½¢çŠ¶: {voxel_sequence.shape}")
        
        with torch.no_grad():
            # ä¸€æ¬¡æ€§å¤„ç†æ•´ä¸ªåºåˆ—
            detector_log = self.network.kypt_detector(voxel_sequence[None])  # æ·»åŠ batchç»´åº¦
            keypoints = detector_log['keypoints']
            affinity = detector_log['affinity']
            
            # ä¿æŒä¸€è‡´çš„å¯è§æ€§ï¼ˆç±»ä¼¼åŸä»£ç ï¼‰
            keypoints[:, 1:, :, -1] = keypoints[:, :1, :, -1].expand(-1, voxel_sequence.size(0) - 1, -1)
            
            # ç¼–ç åŠ¨åŠ›å­¦
            dyna_log = self.network.dyna_module.encode(keypoints, affinity)
            R = dyna_log['R'][0]  # (T, K, 3, 3)
            
            # è·å–ç»“æ„ä¿¡æ¯
            A = self.network.dyna_module.A
            priority = self.network.dyna_module.priority
            parents = self.network.dyna_module.parents
            
            # æ„å»º4x4å˜æ¢çŸ©é˜µ
            pos = keypoints[0, :, :, :3][..., None]  # (T, K, 3, 1)
            T4x4 = torch.cat([R, pos], dim=-1)  # (T, K, 3, 4)
            homo = torch.tensor([0.0, 0.0, 0.0, 1.0]).to(R.device)[None, None, None].expand(
                R.size(0), R.size(1), -1, -1)
            T4x4 = torch.cat([T4x4, homo], dim=-2)  # (T, K, 4, 4)
            
            prediction_time = time.time() - start_time
            print(f"âœ… ç¥ç»ç½‘ç»œé¢„æµ‹å®Œæˆï¼")
            print(f"  - é¢„æµ‹è€—æ—¶: {prediction_time:.2f}ç§’")
            print(f"  - å…³é”®ç‚¹å½¢çŠ¶: {keypoints.shape}")
            print(f"  - å˜æ¢çŸ©é˜µå½¢çŠ¶: {T4x4.shape}")
            
            return {
                'keypoints': keypoints,
                'transforms': T4x4,
                'affinity': affinity,
                'parents': parents.cpu().numpy(),
                'priority_values': priority.values.cpu().numpy(),  # Extract values
                'priority_indices': priority.indices.cpu().numpy(),  # Extract indices
                'A': A,
                'rotations': R
            }
    
    def save_skeleton_results(self, results, output_dir, points_sequence=None):
        """
        ä¿å­˜éª¨éª¼é¢„æµ‹ç»“æœ
        
        Args:
            results: predict_skeleton_sequenceçš„è¾“å‡º
            output_dir: è¾“å‡ºç›®å½•
            points_sequence: åŸå§‹ç‚¹äº‘åºåˆ—ï¼ˆç”¨äºå¯è§†åŒ–ï¼‰
        """
        os.makedirs(output_dir, exist_ok=True)
        
        # ä¿å­˜æ•°å€¼ç»“æœ
        np.save(os.path.join(output_dir, 'keypoints.npy'), results['keypoints'][0].cpu().numpy())
        np.save(os.path.join(output_dir, 'transforms.npy'), results['transforms'].cpu().numpy())
        np.save(os.path.join(output_dir, 'parents.npy'), results['parents'])
        np.save(os.path.join(output_dir, 'affinity.npy'), results['affinity'].cpu().numpy())
        np.save(os.path.join(output_dir, 'priority_values.npy'), results['priority_values'])
        np.save(os.path.join(output_dir, 'priority_indices.npy'), results['priority_indices'])
        np.save(os.path.join(output_dir, 'A.npy'), results['A'].cpu().numpy())
        np.save(os.path.join(output_dir, 'rotations.npy'), results['rotations'].cpu().numpy())

        # save normalized points
        if points_sequence is not None:
            # np.save(os.path.join(output_dir, 'points_sequence.npy'), np.stack(points_sequence, axis=0))
            self.visualize_skeleton_sequence(results, output_dir, points_sequence)
    
    def visualize_skeleton_sequence(self, results, output_dir, points_sequence, 
                                  vis_threshold=0.2, save_frames=True):
        """
        å¯è§†åŒ–éª¨éª¼åºåˆ—
        """
        keypoints = results['keypoints'][0].cpu().numpy()  # (T, K, 4)
        parents = results['parents']
        
        # ç”Ÿæˆå…³èŠ‚é¢œè‰²
        np.random.seed(42)
        joint_colors = np.random.rand(keypoints.shape[1], 3)
        
        if save_frames:
            frames_dir = os.path.join(output_dir, 'skeleton_frames')
            os.makedirs(frames_dir, exist_ok=True)
        
        # åˆ›å»ºå¯è§†åŒ–å™¨
        vis = o3d.visualization.Visualizer()
        vis.create_window(width=800, height=600, visible=not save_frames)
        
        for t in range(keypoints.shape[0]):
            vis.clear_geometries()
            print(f'å¤„ç†å¸§ {t+1}/{keypoints.shape[0]}')

            # æ·»åŠ åŸå§‹ç‚¹äº‘
            if points_sequence:
                pcd = o3d.geometry.PointCloud()
                pcd.points = o3d.utility.Vector3dVector(points_sequence[t])
                pcd.paint_uniform_color([0.7, 0.7, 0.7])
                vis.add_geometry(pcd)
                # print(f'min={np.min(points_sequence[t], axis=0)}, max={np.max(points_sequence[t], axis=0)}')
            
            # æ·»åŠ å…³èŠ‚å’Œéª¨éª¼
            kypts = keypoints[t, :, :3]
            alphas = keypoints[t, :, -1]
            print(f'joints num = {kypts.shape[0]} min={np.min(kypts, axis=0)}, max={np.max(kypts, axis=0)}')
            print(f'parents: {parents}')
            draw_count = 0
            for k in range(keypoints.shape[1]):
                if alphas[k] < vis_threshold:
                    continue
                draw_count += 1
                # æ·»åŠ å…³èŠ‚çƒ
                sphere = o3d.geometry.TriangleMesh.create_sphere(radius=0.03)
                sphere.translate(kypts[k])
                sphere.paint_uniform_color(joint_colors[k])
                vis.add_geometry(sphere)
                
                # æ·»åŠ éª¨éª¼è¿æ¥
                parent = parents[k]
                if parent != k and alphas[parent] >= vis_threshold:
                    # åˆ›å»ºéª¨éª¼çº¿
                    line_points = [kypts[parent], kypts[k]]
                    lines = [[0, 1]]
                    line_set = o3d.geometry.LineSet()
                    line_set.points = o3d.utility.Vector3dVector(line_points)
                    line_set.lines = o3d.utility.Vector2iVector(lines)
                    line_set.paint_uniform_color([0, 0.8, 0])
                    vis.add_geometry(line_set)

            print(f'ç»˜åˆ¶å…³èŠ‚æ•°é‡: {draw_count}')
            if save_frames:
                # ä¿å­˜å¸§å›¾åƒ
                img = vis.capture_screen_float_buffer(True)
                img = (np.asarray(img) * 255).astype(np.uint8)
                o3d.io.write_image(os.path.join(frames_dir, f'frame_{t:04d}.png'), 
                                 o3d.geometry.Image(img))
            else:
                # äº¤äº’å¼æ˜¾ç¤º
                vis.poll_events()
                vis.update_renderer()
        
        vis.destroy_window()
        print(f"å¯è§†åŒ–å®Œæˆï¼Œå…±å¤„ç† {keypoints.shape[0]} å¸§")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="éª¨éª¼åºåˆ—é¢„æµ‹")
    parser.add_argument("--mesh_folder", type=str, default="D:/Code/VVEditor/Rafa_Approves_hd_4k", 
                       help="è¾“å…¥ç½‘æ ¼æ–‡ä»¶å¤¹è·¯å¾„")
    parser.add_argument("--output_dir", type=str, default="output/skeleton_prediction", 
                       help="è¾“å‡ºç›®å½•")
    parser.add_argument("--max_frames", type=int, default=160, 
                       help="æœ€å¤§å¤„ç†å¸§æ•°")
    parser.add_argument("--visualization", action="store_true", 
                       help="å¯ç”¨å¯è§†åŒ–")
    
    args = parser.parse_args()
    
    # é…ç½®è·¯å¾„
    exp_dir = 'pretrained/aist'
    checkpoint_path = os.path.join(exp_dir, 'aist_pretrained.pth')
    opt_path = os.path.join(exp_dir, 'opt.pickle')
    
    # è¾“å…¥åºåˆ—æ–‡ä»¶å¤¹
    mesh_folder = args.mesh_folder
    skel_data_dir = args.output_dir
    visualize_dir = os.path.join(args.output_dir, 'visualization')

    # åˆ›å»ºé¢„æµ‹å™¨
    predictor = SequenceSkeletonPredictor(checkpoint_path, opt_path)
    
    # åŠ è½½ç½‘æ ¼åºåˆ—
    voxel_sequence, mesh_sequence, points_sequence = predictor.load_mesh_sequence(
        mesh_folder, file_pattern="*.obj", max_frames=args.max_frames
    )
    
    # é¢„æµ‹éª¨éª¼
    print("å¼€å§‹é¢„æµ‹éª¨éª¼...")
    results = predictor.predict_skeleton_sequence(voxel_sequence)
    print("éª¨éª¼é¢„æµ‹å®Œæˆ!")
    
    # ä¿å­˜ç»“æœ
    predictor.save_skeleton_results(results, skel_data_dir, points_sequence)

    if args.visualization:
        from SkelVisualizer import visualize_skeleton
        visualize_skeleton(skel_data_dir, visualize_dir)

    print("å¤„ç†å®Œæˆ!")

if __name__ == "__main__":
    main()